[{"path":"https://robindenz1.github.io/adjustedCurves/CONRTIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to adjustedCurves","title":"Contributing to adjustedCurves","text":"First , thanks considering contributing adjustedCurves! adjustedCurves open source project, maintained people care. directly funded .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/CONRTIBUTING.html","id":"how-you-can-contribute","dir":"","previous_headings":"","what":"How you can contribute","title":"Contributing to adjustedCurves","text":"several ways can contribute project. want know contribute open source projects like one, see Open Source Guide.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/CONRTIBUTING.html","id":"share-the-love","dir":"","previous_headings":"How you can contribute","what":"Share the love","title":"Contributing to adjustedCurves","text":"Think adjustedCurves useful? Let others discover , telling person, via Twitter blog post. Using adjustedCurves paper writing? Consider citing .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/CONRTIBUTING.html","id":"ask-a-question","dir":"","previous_headings":"How you can contribute","what":"Ask a question","title":"Contributing to adjustedCurves","text":"Using adjustedCurves got stuck? Browse documentation vignettes see can find solution. Still stuck? Post question issue GitHub. offer user support, ’ll try best address , questions often lead better documentation discovery bugs. Want ask question private? Contact package maintainer [email][mailto:email].","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/CONRTIBUTING.html","id":"propose-an-idea","dir":"","previous_headings":"How you can contribute","what":"Propose an idea","title":"Contributing to adjustedCurves","text":"idea new adjustedCurves feature? Take look documentation issue list see isn’t included suggested yet. , suggest idea issue GitHub. can’t promise implement idea, helps : Explain detail work. Keep scope narrow possible. See want contribute code idea well.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/CONRTIBUTING.html","id":"report-a-bug","dir":"","previous_headings":"How you can contribute","what":"Report a bug","title":"Contributing to adjustedCurves","text":"Using adjustedCurves discovered bug? ’s annoying! Don’t let others experience report issue GitHub can fix . good bug report makes easier us , please include: operating system name version (e.g. Mac OS 10.13.6). details local setup might helpful troubleshooting. Detailed steps reproduce bug. important minimal reproducible example included. Otherwise hard us fix problem.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/CONRTIBUTING.html","id":"improve-the-documentation","dir":"","previous_headings":"How you can contribute","what":"Improve the documentation","title":"Contributing to adjustedCurves","text":"Noticed typo website? Think function use better example? Good documentation makes difference, help improve welcome!","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/CONRTIBUTING.html","id":"contribute-code","dir":"","previous_headings":"How you can contribute","what":"Contribute code","title":"Contributing to adjustedCurves","text":"Care fix bugs implement new functionality adjustedCurves? Awesome! look issue list leave comment things want work . See also development guidelines .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/CONRTIBUTING.html","id":"development-guidelines","dir":"","previous_headings":"","what":"Development guidelines","title":"Contributing to adjustedCurves","text":"submitting code recommended communicate package maintainer proposal. can done via github via e-mail. general, try follow GitHub flow development. Fork repo clone computer. learn process, see guide. forked cloned project since worked , pull changes original repo clone using git pull upstream master. Open RStudio project file (.Rproj). Write code. Test code (bonus points adding unit tests). Document code (see function documentation ). Check code devtools::check() aim 0 errors warnings. Commit push changes. Submit pull request.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"An Introduction to the 'adjustedCurves' Package","text":"R-Package currently available CRAN, can installed easily using devtools package: remotes package: packages might installed, depending specified method.","code":"library(devtools) devtools::install_github(\"RobinDenz1/adjustedCurves\") library(remotes) remotes::install_github(\"RobinDenz1/adjustedCurves\")"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"adjusted-survival-curves","dir":"Articles","previous_headings":"","what":"Adjusted Survival Curves","title":"An Introduction to the 'adjustedCurves' Package","text":"Let’s start standard survival setting. Using sim_confounded_surv function, simulate survival data (Chatton et al. 2020): Using default arguments, function outputs data.frame 6 independently drawn covariates (x1 - x6), binary group variable (group), observed event time (time) event indicator (event). setting, one type event (1). observations right-censored indicator set 0. standard data format used standard time--event analysis.","code":"library(survival) library(ggplot2) library(riskRegression) library(pammtools) library(adjustedCurves)  # set random number generator seed to make this reproducible set.seed(44)  # simulate standard survival data with 300 rows data_1 <- sim_confounded_surv(n=300, max_t=1.1, group_beta=-0.6) # code the grouping variable as a factor data_1$group <- as.factor(data_1$group)  # take a look at the first few rows head(data_1) ##   x1 x2 x3          x4          x5          x6 group       time event ## 1  1  0  0 -0.52520986  0.22776621 -0.05319665     1 0.37181297     1 ## 2  0  1  1  0.02441988 -2.16818274  0.58097459     0 0.65649863     1 ## 3  1  1  1  0.05159071  0.07329185  1.18737651     1 0.08156474     0 ## 4  1  0  0  0.01956631 -1.27205270  1.16594437     0 0.34161603     1 ## 5  0  1  0  0.33793112  1.32447922 -1.28991227     0 0.52472847     1 ## 6  0  1  0 -2.96505672  2.19434272  0.00528396     1 0.87274894     1"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"direct-standardization","dir":"Articles","previous_headings":"Adjusted Survival Curves","what":"Direct Standardization","title":"An Introduction to the 'adjustedCurves' Package","text":"calculate confounder-adjusted survival curves fo group dataset using Direct Standardization (also known G-Computation Corrected Group Prognosis method, see Makuch (1982) Chang et al. (1982)), first fit coxph model: model can used call adjustedsurv function, shown : argument data simply refers data.frame, argument variable specifies grouping variable interest ev_time event variable specify time--event variables data.frame. Setting method \"direct\" result G-Computation estimates, based previously fit cox-regression model supplied using outcome_model argument. returns list needed output objects. important however adjsurv data.frame , containing adjusted survival curves corresponding confidence intervals (used conf_int=TRUE original function call). can take look object using following code: importantly however, can plot survival curves directly using plot method:  plot function comes many options listed documentation. plot point-wise confidence intervals, can set argument conf_int TRUE:  Instead using colors differentiate curves can also use different linetypes, setting linetype argument TRUE color argument FALSE:  can also add small indicator lines censored observations using censoring_ind=\"lines\":  Indicator lines median survival time can added using median_surv_lines=TRUE:  Many custom settings available. details examples see ?plot.adjustedsurv.","code":"# it is important to use X=TRUE in the coxph function call outcome_model <- survival::coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 + x5 +                                     x6 + group, data=data_1, x=TRUE) adjsurv <- adjustedsurv(data=data_1,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=outcome_model,                         conf_int=TRUE) head(adjsurv$adjsurv) ##         time      surv group          se  ci_lower  ci_upper ## 1 0.00000000 1.0000000     0 0.000000000 1.0000000 1.0000000 ## 2 0.01457659 0.9959356     0 0.004039858 0.9880177 1.0000000 ## 3 0.04062032 0.9917639     0 0.005767859 0.9804591 1.0000000 ## 4 0.04232678 0.9876128     0 0.007034862 0.9738247 1.0000000 ## 5 0.06129069 0.9834495     0 0.008123567 0.9675276 0.9993714 ## 6 0.06271999 0.9792709     0 0.009066121 0.9615017 0.9970402 plot(adjsurv) plot(adjsurv, conf_int=TRUE) plot(adjsurv, linetype=TRUE, color=FALSE) plot(adjsurv, color=TRUE, censoring_ind=\"lines\") plot(adjsurv, color=TRUE, median_surv_lines=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"inverse-probability-of-treatment-weighting","dir":"Articles","previous_headings":"Adjusted Survival Curves","what":"Inverse Probability of Treatment Weighting","title":"An Introduction to the 'adjustedCurves' Package","text":"adjustedsurv function essentially works every available method. Since methods however vastly different nature, additional arguments supplied user. example, using Inverse Probability Treatment Weighting method (IPTW), need model treatment assignment mechanism instead outcome mechanism (see Xie Liu (2005)). can done using logistic regression model follows: resulting curves can plotted :  Since methods used correctly , slight differences results. Big differences two methods usually indicate either cox-regression model logistic regression model incorrectly specified.","code":"treatment_model <- glm(group ~ x1 + x2 + x3 + x4 + x5 + x6,                        data=data_1, family=\"binomial\"(link=\"logit\"))  adjsurv <- adjustedsurv(data=data_1,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=treatment_model,                         conf_int=TRUE) plot(adjsurv)"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"augmented-inverse-probability-of-treatment-weighting","dir":"Articles","previous_headings":"Adjusted Survival Curves","what":"Augmented Inverse Probability of Treatment Weighting","title":"An Introduction to the 'adjustedCurves' Package","text":"Doubly-Robust methods can helpful cases (see Robins Rotnitzky (1992) Ozenne et al. (2020)). standard Augmented Inverse Probability Treatment Weighting estimator utilized kinds models time. either models correctly specified, resulting estimates unbiased. can used way methods, time models supplied:","code":"adjsurv <- adjustedsurv(data=data_1,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"aiptw\",                         treatment_model=treatment_model,                         outcome_model=outcome_model,                         conf_int=TRUE)  plot(adjsurv, conf_int=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"adjusted-cumulative-incidence-functions","dir":"Articles","previous_headings":"","what":"Adjusted Cumulative Incidence Functions","title":"An Introduction to the 'adjustedCurves' Package","text":"many situations multiple mutually exclusive types events instead just one event. formally known competing risks situation. situations, survival curves can estimated anymore. However, cumulative incidence function can used instead. Without randomization, CIFs face problems due confounding survival curves . Many methods adjust survival curves confounders can used adjust CIFs similar fashion. computational details underlying theory slightly different (see Ozenne et al. (2020)), syntax R-Package stays pretty much exactly . major difference instead using adjustedsurv function, adjustedcif function utilized. Additionally, user now also specify event-type interest (argument cause). First need new example data, mirroring competing risks situation. going use sim_confounded_crisk function, thing sim_confounded_surv function, competing risks data:","code":"# simulate the data data_2 <- sim_confounded_crisk(n=300) data_2$group <- as.factor(data_2$group)  head(data_2) ##   x1 x2 x3          x4          x5          x6 group       time event ## 1  1  1  0  0.96216812 -0.66375234  0.65527293     1 0.02085406     0 ## 2  1  1  0 -0.58477811  1.73696566 -0.18714061     1 0.18924205     0 ## 3  1  0  0 -0.33549773  0.52008044  0.08290031     0 0.26288996     2 ## 4  0  1  1 -0.04008865  0.19841348  0.38858944     1 0.08210559     2 ## 5  0  0  1  0.78936972 -0.27545174  0.49322272     1 1.67993934     2 ## 6  0  0  0  0.26001387 -0.03590098  0.86231143     1 1.70000000     0"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"direct-standardization-1","dir":"Articles","previous_headings":"Adjusted Cumulative Incidence Functions","what":"Direct Standardization","title":"An Introduction to the 'adjustedCurves' Package","text":"Let’s start Direct Standardization method. Instead using simple coxph method, need use model time--event process takes multiple event-types account. One method Cause-Specific Cox-Regression model. simple implementation model contained riskRegression R-Package. model can used call adjustedcif function, shown :  shows confounder-adjusted CIFs cause = 1. setting cause 2 get confounder-adjusted CIFs cause:","code":"outcome_model <- riskRegression::CSC(Hist(time, event) ~ x1 + x2 + x3 + x4 +                                         x5 + x6 + group, data=data_2) adjcif <- adjustedcif(data=data_2,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       method=\"direct\",                       outcome_model=outcome_model,                       cause=1,                       conf_int=TRUE) plot(adjcif, conf_int=TRUE) adjcif <- adjustedcif(data=data_2,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       method=\"direct\",                       outcome_model=outcome_model,                       cause=2,                       conf_int=TRUE) plot(adjcif, conf_int=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"inverse-probability-of-treatment-weighting-1","dir":"Articles","previous_headings":"Adjusted Cumulative Incidence Functions","what":"Inverse Probability of Treatment Weighting","title":"An Introduction to the 'adjustedCurves' Package","text":"IPTW estimator can used exactly way adjustedsurv function:  estimators can used using essentially syntax. used bootstrap=TRUE last example, use functionality relying comparing groups later.","code":"treatment_model <- glm(group ~ x1 + x2 + x3 + x4 + x5 + x6,                        data=data_2, family=\"binomial\"(link=\"logit\"))  adjcif <- adjustedcif(data=data_2,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       method=\"iptw\",                       treatment_model=treatment_model,                       cause=1,                       conf_int=TRUE) plot(adjcif, conf_int=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"adjusted-curves-with-more-than-two-groups","dir":"Articles","previous_headings":"","what":"Adjusted Curves with More than Two Groups","title":"An Introduction to the 'adjustedCurves' Package","text":"many applications two treatments. methods included R-Package allow calculations arbitrary number treatments. cases code change can used exactly way . difference occurs using IPTW methods. user use multinomial logistic regression model instead regular logistic regression model outcome. illustrated . First create simulated data set (single event survival data). function able create binary treatment variables, can simply resample occurrences 1 1 2, creating 3 treatments, 1 2 identical treatment effect selection process: Direct Adjusted survival curves can calculated exactly :  IPTW based estimates first fit multinomial logistic regression model using multinom function nnet R-Package use code :  use bootstrap=TRUE need next section. practice, however, 50 bootstrap samples definitely enough guarantee convergence. choose low number due speed considerations enforced CRAN.","code":"# add another group # NOTE: this is done only to showcase the method and does not #       reflect what should be done in real situations data_1$group <- factor(data_1$group, levels=c(\"0\", \"1\", \"2\")) data_1$group[data_1$group==\"1\"] <- sample(c(\"1\", \"2\"), replace=TRUE,                                           size=nrow(data_1[data_1$group==\"1\",])) outcome_model <- survival::coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 +                                     x5 + x6 + group, data=data_1, x=TRUE)  adjsurv <- adjustedsurv(data=data_1,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=outcome_model,                         conf_int=TRUE) plot(adjsurv) treatment_model <- nnet::multinom(group ~ x1 + x2 + x3 + x4 + x5 + x6,                                   data=data_1) ## # weights:  24 (14 variable) ## initial  value 329.583687  ## iter  10 value 286.543657 ## iter  20 value 283.765460 ## final  value 283.765313  ## converged adjsurv <- adjustedsurv(data=data_1,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=treatment_model,                         conf_int=TRUE,                         bootstrap=TRUE,                         n_boot=50) plot(adjsurv, conf_int=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"comparing-groups","dir":"Articles","previous_headings":"","what":"Comparing Groups","title":"An Introduction to the 'adjustedCurves' Package","text":"estimated adjusted curves can subsequently used compare treatment groups using additional plots statistics.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"adjusted-differences-in-probabilities","dir":"Articles","previous_headings":"Comparing Groups","what":"Adjusted Differences in Probabilities","title":"An Introduction to the 'adjustedCurves' Package","text":"One simple way compare groups pick point time simply calculate differences survival failure probability point. adjusted_curve_diff function automates process. following example calculate difference adjusted survival probability group 0 1 time = 0.4: confidence interval include 0, suggesting difference statistically significant. can also seen associated p-value. Instead focusing single point time, can also plot entire difference curve using plot_curve_diff function:  kind curves great way visualize group effect time. two groups present, function can called multiple times changing group_1 group_2 values.","code":"adjusted_curve_diff(adjsurv, times=0.4, group_1=\"0\", group_2=\"1\", conf_int=TRUE) ##   time         diff         se   ci_lower  ci_upper   p_value ## 1  0.4 -0.008257592 0.09049062 -0.1856159 0.1691008 0.9272911 plot_curve_diff(adjsurv, group_1=\"0\", group_2=\"1\", conf_int=TRUE, color=\"blue\")"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"adjusted-survival-time-quantiles","dir":"Articles","previous_headings":"Comparing Groups","what":"Adjusted Survival Time Quantiles","title":"An Introduction to the 'adjustedCurves' Package","text":"Similarly, can calculate adjusted survival time quantiles using adjusted_surv_quantile function. example, adjusted median survival time given : case, similar.","code":"adjusted_surv_quantile(adjsurv, p=0.5, conf_int=TRUE) ##     p group    q_surv  ci_lower  ci_upper ## 1 0.5     0 0.5067310 0.4487885 0.5657139 ## 2 0.5     1 0.8014008 0.4068963        NA ## 3 0.5     2 0.4835157 0.4311141 0.6283029"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"adjusted-restricted-mean-survival-time","dir":"Articles","previous_headings":"Comparing Groups","what":"Adjusted Restricted Mean Survival Time","title":"An Introduction to the 'adjustedCurves' Package","text":"alternative measure restricted mean survival time, denotes integral survival curve time 0 specified point time (see Royston et al. 2013). confounder adjusted version statistic can calculated simply integrating confounder adjusted survival curves instead normal Kaplan-Meier curve (Conner et al. 2019). adjustedCurves package allows user simply calling adjusted_rmst function previously created adjustedsurv object: function returns adjusted RMST every level \"group\" variable. bootstrapping performed calling adjustedsurv function, standard errors confidence intervals can also calculated using function well setting conf_int argument TRUE: Similar adjusted_curve_diff function, can perform test difference two RMST values: seems statistically significant difference two RMSTs. However, due low number bootstrap replications used results trusted. practice one use much higher number, 500 1000 replications. Instead focusing single point time, also possible plot RMST evolves time using plot_rmst_curve function:  Bootstrap confidence intervals also added plot using conf_int=TRUE.","code":"adjusted_rmst(adjsurv, to=0.4) ##   group      rmst ## 1     0 0.3485056 ## 2     1 0.3415740 ## 3     2 0.3547187 adjusted_rmst(adjsurv, to=0.4, conf_int=TRUE) ##   group      rmst          se  ci_lower  ci_upper n_boot ## 1     0 0.3485056 0.009156084 0.3305600 0.3664512     50 ## 2     1 0.3415740 0.019812278 0.3027427 0.3804054     50 ## 3     2 0.3547187 0.009117535 0.3368487 0.3725888     50 adjusted_rmst(adjsurv, to=0.4, conf_int=TRUE, difference=TRUE,               group_1=\"0\", group_2=\"1\") ##          diff         se    ci_lower   ci_upper   p_value ## 1 0.006931522 0.02182568 -0.03584602 0.04970907 0.7507993 plot_rmst_curve(adjsurv)"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"adjusted-restricted-mean-time-lost","dir":"Articles","previous_headings":"Comparing Groups","what":"Adjusted Restricted Mean Time Lost","title":"An Introduction to the 'adjustedCurves' Package","text":"similar statistic adjusted Restricted Mean Time Lost (RMTL), defined area cause-specific confounder adjusted CIF. can calculated way RMST, using adjusted_rmtl function: contrast adjusted_rmst function, works adjustedsurv adjustedcif objects survival curve can easily transformed CIF. also allows difference tests, just like adjusted_rmtl function. can also plot RMTL time, time using plot_rmtl_curve function:","code":"adjusted_rmtl(adjcif, to=0.4, conf_int=FALSE) ##   group       rmtl ## 1     0 0.05621035 ## 2     1 0.04968113 plot_rmtl_curve(adjcif)"},{"path":"https://robindenz1.github.io/adjustedCurves/articles/introduction.html","id":"literature","dir":"Articles","previous_headings":"","what":"Literature","title":"An Introduction to the 'adjustedCurves' Package","text":"Robin Denz, Renate Klaaßen-Mielke, Nina Timmesfeld (2023). “Comparison Different Methods Adjust Survival Curves Confounders”. : Statistics Medicine 42.10, pp. 1461-1479 Donald B. Rubin (1974). “Estimating Causal Effects Treatments Randomized Nonrandomized Studies”. : Journal Educational Psychology 66.5, pp. 688-701 Judea Pearl (2009). Causality: Models, Reasoning Inference. 2nd ed. Cambridge: Cambridge University Press Arthur Chatton, Florent Le Borgne, Clemence Leyrat, Yohann Foucher (2020). G-Computation Inverse Probability Weighting Time--Event Outcomes: Comparative Study. arXiv:2006.16859v1 Robert W. Makuch (1982). “Adjusted Survival Curve Estimation Using Covariates”. : Journal Chronic Diseases 35.6, pp. 437-443 -Ming Chang, Rebecca Gelman, Marcello Pagano (1982). “Corrected Group Prognostic Curves Summary Statistics”. : Journal Chronic Diseases 35, pp. 669-674 Jun Xie Chaofeng Liu (2005). “Adjusted Kaplan-Meier Estimator Log-Rank Test Inverse Probability Treatment Weighting Survival Data”. : Statistics Medicine 24, pp. 3089-3110 James M. Robins Andrea Rotnitzky (1992). “Recovery Information Adjustment Dependent Censoring Using Surrogate Markers”. : AIDS Epidemiology: Methodological Issues. Ed. Nicholas P. Jewell, Klaus Dietz, Vernon T. Farewell. New York: Springer Science + Business Media, pp. 297-331 Brice Maxime Hugues Ozenne, Thomas Harder Scheike, Laila Staerk (2020). “Estimation Average Treatment Effects Right-Censored Time Event Outcome Competing Risks”. : Biometrical Journal 62, pp. 751-763 Weixin Cai Mark J. van der Laan (2020). “One-Step Targeted Maximum Likelihood Estimation Time--Event Outcomes”. : Biometrics 76, pp. 722-733 Patrick Royston Mahesh K. B. Parmar (2013). “Restricted Mean Survival Time: Alternative Hazard Ratio Design Analysis Randomized Trials Time--Event Outcome”. : BMC Medical Research Methodology 13.152 Sarah C. Conner, Lisa M. Sullivan, Emelia J. Benjamin, Michael P. LaValley, Sandro Galea, Ludovic Trinquart (2019). “Adjusted Restricted Mean Survival Times Observational Studies”. : Statistics Medicine 38, pp. 3832-3860","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/articles/method_overview.html","id":"methods-in-adjustedsurv","dir":"Articles","previous_headings":"","what":"Methods in adjustedsurv()","title":"Overview of methods in adjustedCurves","text":"following table gives general overview supported methods adjustedsurv(): methods \"iptw_km\" \"iptw_cox\" wrote “()” whether support dependent censoring, direct implementation handle package. supplying inverse probability censoring weights treatment_model argument , however, possible use estimators adjust dependent censoring well. inverse probability treatment (general covariate balancing weights) inverse probability censoring weights used, user can simply multiply subject-level weights supply results treatment_model argument. following table gives overview supported input treatment_model argument methods require : created adjustedsurv object using adjustedsurv() function, following functions can used create plots, transform output calculate statistics: plot(): Plots estimated adjusted survival curves adjusted_curve_diff(): Calculates differences survival probabilities adjusted_curve_ratio(): Calculates ratios survival probabilities plot_curve_diff(): Plots differences survival probabilities adjusted_surv_quantile(): Calculates adjusted survival time quantiles adjusted_rmst(): Calculates adjusted restricted mean survival times plot_rmst_curve(): Plots adjusted restricted mean survival time curves adjusted_rmtl(): Calculates adjusted restricted mean time lost plot_rmtl_curve(): Plots adjusted restricted mean time lost curves adjusted_curve_test(): Performs test adjusted survival curve equality interval as_ggsurvplot_df(): Transforms output concise data.frame","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/articles/method_overview.html","id":"methods-in-adjustedcif","dir":"Articles","previous_headings":"","what":"Methods in adjustedcif()","title":"Overview of methods in adjustedCurves","text":"following table gives general overview supported methods adjustedcif(): following table gives overview supported input treatment_model argument methods require : Note method \"iptw\" currently support directly supplying weights propensity scores. due relying ate function riskRegression package, accepts glm multinom objects. may changed future. created adjustedcif object using adjustedcif() function, following functions can used create plots, transform output calculate statistics: plot(): Plots estimated adjusted CIFs adjusted_curve_diff(): Calculates differences CIFs adjusted_curve_ratio(): Calculates ratios CIFs plot_curve_diff(): Plots differences CIFs time adjusted_rmtl(): Calculates adjusted restricted mean time lost plot_rmtl_curve(): Plots adjusted restricted mean time lost curves adjusted_curve_test(): Performs test adjusted CIF equality interval","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/articles/method_overview.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Overview of methods in adjustedCurves","text":"Robin Denz, Renate Klaaßen-Mielke, Nina Timmesfeld (2023). “Comparison Different Methods Adjust Survival Curves Confounders”. : Statistics Medicine 42.10, pp. 1461-1479","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Robin Denz. Author, maintainer.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Denz R, Klaaßen-Mielke R, Timmesfeld N (2023). “comparison different methods adjust survival curves confounders.” Statistics Medicine, 42(10), 1461-1479. https://doi.org/10.1002/sim.9681.","code":"@Article{,   title = {A comparison of different methods to adjust survival curves for confounders},   author = {Robin Denz and Renate Klaaßen-Mielke and Nina Timmesfeld},   journal = {Statistics in Medicine},   year = {2023},   volume = {42},   number = {10},   pages = {1461-1479},   url = {https://doi.org/10.1002/sim.9681}, }"},{"path":"https://robindenz1.github.io/adjustedCurves/index.html","id":"adjustedcurves-","dir":"","previous_headings":"","what":"Confounder-Adjusted Survival Curves and Cumulative Incidence\n    Functions","title":"Confounder-Adjusted Survival Curves and Cumulative Incidence\n    Functions","text":"Author: Robin Denz","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/index.html","id":"description","dir":"","previous_headings":"","what":"Description","title":"Confounder-Adjusted Survival Curves and Cumulative Incidence\n    Functions","text":"adjustedCurves R-Package can used estimate plot confounder-adjusted survival curves + confidence intervals well cause-specific confounder-adjusted cumulative incidence functions + confidence intervals using variety methods. provides convenient wrapper around existing R-Packages topic adds additional methods functionality top . additional features include calculation adjusted restricted mean survival times testing whether two confounder-adjusted survival curves different given interval. Detailed descriptions method can found literature cited documentation.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Confounder-Adjusted Survival Curves and Cumulative Incidence\n    Functions","text":"stable version can installed directly CRAN using: developmental version can installed using devtools R-Package:","code":"install.packages(\"adjustedCurves\") library(devtools)  devtools::install_github(\"https://github.com/RobinDenz1/adjustedCurves\")"},{"path":"https://robindenz1.github.io/adjustedCurves/index.html","id":"bug-reports-and-feature-requests","dir":"","previous_headings":"","what":"Bug Reports and Feature Requests","title":"Confounder-Adjusted Survival Curves and Cumulative Incidence\n    Functions","text":"encounter bugs specific feature requests, please file Issue.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Confounder-Adjusted Survival Curves and Cumulative Incidence\n    Functions","text":"minimal example shows estimate plot adjusted survival curves using Direct Adjustment package:  example estimate plot adjusted survival curves using Inverse Probability Treatment Weighting:  also possible plot difference two curves using plot_curve_diff() function:  test whether two adjusted survival curves different specified interval (0 0.75), adjustedsurv call made bootstrap=TRUE: examples can found documentation vignettes.","code":"library(adjustedCurves) library(survival)  # simulate some data as example set.seed(31) sim_dat <- sim_confounded_surv(n=250, max_t=1.2, group_beta=0) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cox-regression for the outcome cox_mod <- coxph(Surv(time, event) ~ x1 + x2 + x4 + x5 + group,                  data=sim_dat, x=TRUE)  # use it to estimate adjusted survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=TRUE)  # plot with confidence intervals plot(adjsurv, conf_int=TRUE) # estimate a treatment assignment model glm_mod <- glm(group ~ x2 + x3 + x5 + x6, data=sim_dat,                family=\"binomial\"(link=\"logit\"))  # use it to estimate adjusted survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=glm_mod,                         conf_int=TRUE)  # plot with confidence intervals plot(adjsurv, conf_int=TRUE) plot_curve_diff(adjsurv, conf_int=TRUE, color=\"blue\") adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=TRUE,                         bootstrap=TRUE,                         n_boot=1000)  adj_test <- adjusted_curve_test(adjsurv, from=0, to=0.75) summary(adj_test)"},{"path":"https://robindenz1.github.io/adjustedCurves/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Confounder-Adjusted Survival Curves and Cumulative Incidence\n    Functions","text":"main paper associated R-Package : Robin Denz, Renate Klaaßen-Mielke, Nina Timmesfeld (2023). comparison different methods adjust survival curves confounders. Statistics Medicine. 42.10, pp. 1461-1479. doi:10.1002/sim.9681 addition, relevant primary literature respective method cited. can found documentation method.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Confounder-Adjusted Survival Curves and Cumulative Incidence\n    Functions","text":"© 2021 Robin Denz contents repository distributed GNU General Public License. can find full text License github repository. Alternatively, see http://www.gnu.org/licenses/.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/CSC_MI.html","id":null,"dir":"Reference","previous_headings":"","what":"Cause-Specific Cox Regression with Multiple Imputation — CSC_MI","title":"Cause-Specific Cox Regression with Multiple Imputation — CSC_MI","text":"function can utilized perform Cause-Specific Cox Regression multiply imputed datasets.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/CSC_MI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cause-Specific Cox Regression with Multiple Imputation — CSC_MI","text":"","code":"CSC_MI(mids, formula, ...)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/CSC_MI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cause-Specific Cox Regression with Multiple Imputation — CSC_MI","text":"mids mids object created using mice function. replaces data argument original function call. formula formula object passed CSC function riskRegression package. ... arguments passed CSC function riskRegression package.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/CSC_MI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cause-Specific Cox Regression with Multiple Imputation — CSC_MI","text":"small convenience function perform CSC regression multiply imputed data. simply wrapper around CSC function riskRegression package, usual use supported directly. returns mira object, can passed outcome_model argument inside adjustedcif function needed. pool method functionality available.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/CSC_MI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cause-Specific Cox Regression with Multiple Imputation — CSC_MI","text":"mira object containing CSC regression every imputed dataset.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/CSC_MI.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cause-Specific Cox Regression with Multiple Imputation — CSC_MI","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/CSC_MI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cause-Specific Cox Regression with Multiple Imputation — CSC_MI","text":"","code":"# not run because it would be too slow # \\donttest{ library(adjustedCurves) library(survival) library(riskRegression) #> riskRegression version 2023.12.21 library(mice) #>  #> Attaching package: ‘mice’ #> The following object is masked from ‘package:stats’: #>  #>     filter #> The following objects are masked from ‘package:base’: #>  #>     cbind, rbind  # simulate some data as example sim_dat <- sim_confounded_crisk(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # introduce random missingness in x1 as example sim_dat$x1 <- ifelse(runif(n=50) < 0.5, sim_dat$x1, NA)  # perform multiple imputation mids <- mice::mice(data=sim_dat, method=\"pmm\", m=5) #>  #>  iter imp variable #>   1   1  x1 #>   1   2  x1 #>   1   3  x1 #>   1   4  x1 #>   1   5  x1 #>   2   1  x1 #>   2   2  x1 #>   2   3  x1 #>   2   4  x1 #>   2   5  x1 #>   3   1  x1 #>   3   2  x1 #>   3   3  x1 #>   3   4  x1 #>   3   5  x1 #>   4   1  x1 #>   4   2  x1 #>   4   3  x1 #>   4   4  x1 #>   4   5  x1 #>   5   1  x1 #>   5   2  x1 #>   5   3  x1 #>   5   4  x1 #>   5   5  x1  # use the function csc_mods <- CSC_MI(mids=mids,                    formula=Hist(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group                    ) # }"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/FGR_MI.html","id":null,"dir":"Reference","previous_headings":"","what":"Fine & Gray Model with Multiple Imputation — FGR_MI","title":"Fine & Gray Model with Multiple Imputation — FGR_MI","text":"function can utilized calculate Fine & Gray models multiply imputed datasets.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/FGR_MI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fine & Gray Model with Multiple Imputation — FGR_MI","text":"","code":"FGR_MI(mids, formula, cause=1, ...)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/FGR_MI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fine & Gray Model with Multiple Imputation — FGR_MI","text":"mids mids object created using mice function. replaces data argument original function call. formula formula object passed FGR function riskRegression package. cause failure type interest. Defaults 1. ... arguments passed FGR function riskRegression package.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/FGR_MI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fine & Gray Model with Multiple Imputation — FGR_MI","text":"small convenience function calculate Fine & Gray models multiply imputed data. simply wrapper around FGR function riskRegression package, usual use supported directly. returns mira object, can passed outcome_model argument inside adjustedcif function needed. pool method functionality available.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/FGR_MI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fine & Gray Model with Multiple Imputation — FGR_MI","text":"mira object containing FGR regression every imputed dataset.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/FGR_MI.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fine & Gray Model with Multiple Imputation — FGR_MI","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/FGR_MI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fine & Gray Model with Multiple Imputation — FGR_MI","text":"","code":"# not run because it would be too slow # \\donttest{ library(adjustedCurves) library(survival) library(riskRegression) library(mice) library(prodlim)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # introduce random missingness in x1 as example sim_dat$x1 <- ifelse(runif(n=50) < 0.5, sim_dat$x1, NA)  # perform multiple imputation mids <- mice::mice(data=sim_dat, method=\"pmm\", m=5, printFlag=FALSE)  # use the function fgr_mods <- FGR_MI(mids=mids,                    formula=Hist(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                    cause=1) # }"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedCurves.html","id":null,"dir":"Reference","previous_headings":"","what":"Confounder-Adjusted Survival Curves and Cumulative Incidence Functions — adjustedCurves-package","title":"Confounder-Adjusted Survival Curves and Cumulative Incidence Functions — adjustedCurves-package","text":"package ? package aims unite available adjustments methods estimate confounder-adjusted survival curves cause-specific confounder-adjusted cumulative incidence functions one consistent framework. try make usage methods calculation associated statistics easy possible user, still providing substantial functionality. exactly adjusted survival curves / adjusted cumulative incidence functions? well known confounding serious problem analyzing data non-randomized studies. also true estimating survival curves cumulative incidence functions. aim estimate population averaged survival probability cumulative incidence group \\(z\\), observed every individual assigned group \\(z\\). example, formal definition causal survival curve : $$S_{z}(t) = E((T_z > t))$$ \\(T_z\\) survival time observed treatment \\(z\\) actually administered. See Denz et al. (2023) Cai Van der Laan (2020) details features included package? package includes 16 methods estimate confounder-adjusted survival curves (single event) 8 methods estimate confounder adjusted cumulative incidence functions (possibly multiple competing events). provides plot functions easily produce highly customizable publication-ready graphics. also allows user easily calculate relevant statistics, confidence intervals, p-values, adjusted restricted mean survival time estimates. Multiple Imputation directly supported. typical workflow using package look like? design package based design WeightIt package. includes two main functions: adjustedsurv adjustedcif. Every implemented adjustment method documentation page including small description, code examples, relevant literature references. typical workflow using package follows (1) estimate confounder-adjusted curves (survival curves CIFs) using either adjustedsurv adjustedcif, (2) plot using S3 plot method sometimes (3) calculate statistics using adjusted_rmst, adjusted_rmtl adjusted_curve_test. use adjustedsurv adjustedcif? standard time--event data one type event possible confounder-adjusted survival curves confounder-adjusted cumulative incidence function can estimated using adjustedsurv function. adjustedsurv function estimates survival, CIF can simply calculated \\(1 - S(t)\\). transformation survival curves CIFs directly implemented plot function (argument cif). competing risks present, cause-specific confounder-adjusted survival curves can estimated unbiased way (see example Satagopan et al. (2004) explanation). cause-specific confounder-adjusted cumulative incidence functions however can estimated using adjustedcif function. features missing package? former version, package included two targeted maximum likelihood based methods estimation adjusted survival curves one estimation adjusted cumulative incidence functions based discrete-time data. methods removed survtmle package removed CRAN currently available implementation estimators CRAN. However, since version 0.10.2 package contains implementation targeted maximum likelihood estimation continuous time--event data (wrapper function concrete package). package also currently support time-varying treatments covariates. also support left-censoring, interval-censoring left-truncation. features may added future releases. variable interest continuous? methods package designed strictly categorical variables interest. variable interest continuous user manually categorize variable save factor first. , however, generally discouraged artificial categorization may lead bias misleading results. face issue developed contsurvplot R package implements multiple plotting methods visualize (causal) effect continuous variable analyzing survival data (Denz & Timmesfeld 2023). can get information? documentation pages contain lot information, relevant examples literature references. Additional examples can found vignette package, can accessed using vignette(topic=\"introduction\", package=\"adjustedCurves\") main paper associated package (Denz et al. 2023). also working separate article package going published peer-reviewed journal. want suggest new feature / want report bug. can ? Bug reports, suggestions feature requests highly welcome. Please file issue official github page contact author directly using supplied e-mail address.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedCurves.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Confounder-Adjusted Survival Curves and Cumulative Incidence Functions — adjustedCurves-package","text":"Robin Denz, Renate Klaaßen-Mielke, Nina Timmesfeld (2023). \"Comparison Different Methods Adjust Survival Curves Confounders\". : Statistics Medicine 42.10, pp. 1461-1479. Robin Denz, Nina Timmesfeld (2023). \"Visualizing (Causal) Effect Continuous Variable Time--Event Outcome\". : Epidemiology 34.5, pp. 652-660. Weixin Cai Mark J. van der Laan (2020). \"One-Step Targeted Maximum Likelihood Estimation Time--Event Outcomes\". : Biometrics 76, pp. 722-733 J. M. Satagopan, L. Ben-Porat, M. Berwick, M. Robson, D. Kutler, . D. Auerbach (2004). \"Note Competing Risks Survival Data Analysis\". : British Journal Cancer 91, pp. 1229-1235.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedCurves.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Confounder-Adjusted Survival Curves and Cumulative Incidence Functions — adjustedCurves-package","text":"Robin Denz, <robin.denz@rub.de>","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the difference between or the ratio of two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_diff","title":"Estimate the difference between or the ratio of two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_diff","text":"Given previously created adjustedsurv adjustedcif object, calculate difference ratio two variable specific curves. Can either calculate whole difference / ratio curve estimates specified points time.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the difference between or the ratio of two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_diff","text":"","code":"adjusted_curve_diff(adj, group_1=NULL, group_2=NULL,                     times=NULL, conf_int=FALSE, conf_level=0.95,                     use_boot=FALSE, interpolation=\"steps\")  adjusted_curve_ratio(adj, group_1=NULL, group_2=NULL,                      times=NULL, conf_int=FALSE, conf_level=0.95,                      use_boot=FALSE, interpolation=\"steps\")"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the difference between or the ratio of two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_diff","text":"adj adjustedsurv object created using adjustedsurv function, adjustedcif object created using adjustedcif function. group_1 Optional argument get specific difference ratio. argument takes single character string specifying one levels variable used original adjustedsurv adjustedcif function call. group subtracted . example group_1=\"\" group_2=\"B\" difference - B ratio / B used. NULL, order factor levels original data determines order. NULL, group_2 argument also needs specified. group_2 Also single character string specifying one levels variable. corresponds right side difference equation. See argument group_1. times optional numeric vector points time difference ratio estimated. NULL (default) differences ratios estimated whole curve. conf_int Whether standard errors, confidence intervals p-values calculated. possible either conf_int=TRUE bootstap=TRUE used original function call. See details estimated. conf_level number specifying confidence level confidence intervals. use_boot Whether use standard errors estimated using bootstrapping confidence interval p-value calculation. Can used bootstrap=TRUE used original adjustedsurv adjustedcif function call. Ignored conf_int=FALSE. interpolation Either \"steps\" (default) \"linear\". parameter controls interpolation performed. argument set \"steps\", curves treated step functions. set \"linear\", curves wil treated straight lines point estimates instead. Points lie estimated points interpolated accordingly. usually kept \"steps\". See Details.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_diff.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate the difference between or the ratio of two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_diff","text":"Confidence Intervals & P-Values differences, standard error difference estimated using pooled standard error two probability estimates, given : $$SE_{group_1 - group_2} = \\sqrt{SE_{group_1}^2 + SE_{group_2}^2}$$ Confidence intervals calculated using pooled standard error normal approximation. P-Values also obtained using standard error combined two-sided one-sample t-test. null-hypothesis difference equal 0, alternative hypothesis difference equal 0. ratios, confidence intervals calculated according method given Fieller (1954), assuming probabilities independent. P-values calculated using one-sample two-sided t-test test-statistic Fieller (1954). p-values calculated multiple points time simultaneously, user adjust . See ?p.adjust information. Overall Difference Test function perform test overall difference two functions. calculate integral difference given interval plot_curve_diff function can used. Additionally, test whether integral equal zero adjusted_curve_test function can used. test available ratios, unclear entail. Two Groups two groups present variable, comparisons except group_1 vs. group_2 ignored. multiple comparisons desired, user needs call function multiple times adjust group_1 group_2 arguments accordingly. Graphical Displays directly associated plot method function. However, function used internally calling plot_curve_diff function. order get plot difference curve point estimates, function can used. Multiple Imputation function works exactly way adjusted survival curves adjusted CIFs estimated using multiple imputation without missing values. multiple imputation used previously, function simply uses pooled estimates calculate differences ratios. Computational Details estimating difference ratios point time direct point estimates available, function needs interpolate curves. interpolation method can controlled using interpolation function. cases, estimated curves step functions default (interpolation=\"steps\") therefore appropriate. However, parametric survival models used estimation process might preferable use linear interpolation instead.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the difference between or the ratio of two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_diff","text":"Returns data.frame containing columns time (points time difference ratios estimated) diff ratio (estimated difference ratio). conf_int=TRUE used function call, additionally contains columns se (estimated standard error difference, included ratios), ci_lower (lower limit confidence interval difference/ratio), ci_upper (upper limit confidence interval difference/ratio) p_value (p-value mentioned test).","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_diff.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate the difference between or the ratio of two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_diff","text":"John P. Klein, Brent Logan, Mette Harhoff, Per Kragh Andersen (2007). \"Analyzing Survival Curves Fixed Point Time\". : Statistics Medicine 26, pp. 4505-4519 Michael Coory, Karen E. Lamb, Michael Sorich (2014). \"Risk-Difference Curves can used Communicate Time-Dependent Effects Adjuvant Therapies Early Stage Cancer\". : Journal Clinical Epidemiology 67, pp. 966-972 Edgar C. Fieller (1954). \"Problems Interval Estimation\". : Journal Royal Statistical Society, Series B 16.2, pp. 175-185","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_diff.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimate the difference between or the ratio of two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_diff","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_diff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate the difference between or the ratio of two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_diff","text":"","code":"library(adjustedCurves) library(survival) library(cmprsk)  #### Simple Survival Case with adjusted survival curves ####  # simulate some data as example set.seed(42) sim_dat <- sim_confounded_surv(n=30, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # propensity score model ps_mod <- glm(group ~ x1 + x2 + x4 + x5, data=sim_dat, family=\"binomial\")  # use it to estimate adjusted survival curves with bootstrapping adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=ps_mod,                         conf_int=TRUE,                         bootstrap=TRUE,                         n_boot=10) # n_boot should be much higher in reality  # calculate the whole difference curve adjdiff <- adjusted_curve_diff(adjsurv) adjratio <- adjusted_curve_ratio(adjsurv)  # only some points in time adjdiff <- adjusted_curve_diff(adjsurv, times=c(0.2, 0.4)) adjratio <- adjusted_curve_ratio(adjsurv, times=c(0.2, 0.4))  # with confidence intervals, p-values adjdiff <- adjusted_curve_diff(adjsurv, times=c(0.2, 0.4), conf_int=TRUE) adjratio <- adjusted_curve_ratio(adjsurv, times=c(0.2, 0.4), conf_int=TRUE)  # using bootstrapping adjdiff <- adjusted_curve_diff(adjsurv, times=c(0.2, 0.4), conf_int=TRUE,                                use_boot=TRUE)  #### Competing Risks Case with adjusted CIFs #### library(riskRegression) library(prodlim)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=41, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cause-specific cox-regression for the outcome csc_mod <- CSC(Hist(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                data=sim_dat)  # use it to calculate adjusted CIFs for cause = 1 with bootstrapping adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       method=\"direct\",                       outcome_model=csc_mod,                       conf_int=TRUE,                       bootstrap=TRUE,                       n_boot=10,                       cause=1) #> Warning: Loglik converged before variable  2,3,7 ; coefficient may be infinite.  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Ran out of iterations and did not converge #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Ran out of iterations and did not converge #> Warning: one or more coefficients may be infinite #> Warning: Ran out of iterations and did not converge #> Warning: Rare event  #> Warning: Ran out of iterations and did not converge #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Ran out of iterations and did not converge #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event   # calculate the whole difference curve adjdiff <- adjusted_curve_diff(adjcif) adjratio <- adjusted_curve_ratio(adjcif)  # with confidence intervals adjdiff <- adjusted_curve_diff(adjcif, conf_int=TRUE) adjratio <- adjusted_curve_ratio(adjcif, conf_int=TRUE) #> Warning: NaNs produced  # only at specific points in time adjdiff <- adjusted_curve_diff(adjcif, times=c(0.2, 0.4), conf_int=TRUE) adjratio <- adjusted_curve_ratio(adjcif, times=c(0.2, 0.4), conf_int=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if there is a difference between two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_test","title":"Test if there is a difference between two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_test","text":"function implements modified version Pepe Flemming (1989) test difference two adjusted survival curves CIFs. particular, Null-Hypothesis integral difference two curves specified time interval equal zero.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if there is a difference between two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_test","text":"","code":"adjusted_curve_test(adj, to, from=0, conf_level=0.95,                     interpolation=\"steps\",                     group_1=NULL, group_2=NULL)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if there is a difference between two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_test","text":"adj adjustedsurv object created using adjustedsurv function, adjustedcif object created using adjustedcif function, bootstap=TRUE original function call. number specifying right side time interval interest. value time can read estimated survival curves CIFs. number specifying left side time interval interest. value time can read estimated survival curves CIFs. set 0 default. conf_level number specifying confidence level bootstrap confidence intervals. interpolation Either \"steps\" (default) \"linear\". parameter controls interpolation performed. argument set \"steps\", curves treated step functions. set \"linear\", curves wil treated straight lines point estimates instead. Points lie estimated points interpolated accordingly. usually kept \"steps\". See Details. group_1 Optional argument get one specific hypothesis test. argument takes single character string specifying one levels variable used original adjustedsurv adjustedcif function call. group subtracted . example group_1=\"\" group_2=\"B\" difference - B used. NULL, order factor levels original data determines test order. NULL, group_2 argument also needs specified. arguments used, potential pairwise comparisons ignored. group_2 Also single character string specifying one levels variable. corresponds right side difference equation. See argument group_2.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test if there is a difference between two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_test","text":"adjustedsurv adjustedcif functions bootstrap=TRUE draw n_boot bootstrap samples estimate adjusted curves one. function uses estimates calculates integral difference two curves interval defined . curves approximately equal, quantity close zero. direct variance calculation quantity quite involved even non-adjusted case proposed adjusted survival curves adjusted CIFs yet. can however use distribution integrals bootstrap samples approximate variation. shifting bootstrap distribution centered around 0 approximate distribution integral Null-Hypothesis. p-value can calculated taking proportion cases absolute integral observed actual curves smaller equal shifted bootstrap values. associated print summary methods can used obtain neat data.frame important quantities. also recommend checking test assumptions using plot method. Pairwise Comparisons two survival curves CIFs function automatically performs pairwise comparisons . recommended adjust p-values obtained using method multiple testing. See ?p.adjust information. one potential pairwise comparisons interest, group_1 group_2 arguments can used obtain specific one. Multiple Imputation adjustedsurv adjustedcif object fitted using multiply imputed datasets, tests performed separately dataset. estimates integral difference combined using Rubins Rule. confidence intervals quantity calculated pooling bootstrap standard errors recalculating confidence interval using normal approximation. p-values also pooled using method described Licht (2010). recommended check pooled p-value agreement pooled confidence interval. Graphical Displays plot curves differences directly, recommend using  plot_curve_diff function. Similar main plot functions, lot arguments customize plot. main goal check assumptions, recommend using associated plot method instead. Computational Details Instead relying numerical integration, function uses exact calculations. achieved using either step-function interpolation (interpolation=\"steps\", default) linear interpolation (interpolation=\"linear\"). former case, integral simply sum area squares defined step function. second case, integral simply sum area rectangles. Either way, need approximations. situations (example using parametric survival models method=\"direct\"), curves step functions. case interpolation argument set \"linear\".","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if there is a difference between two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_test","text":"Returns curve_test object. exactly two treatments list contains following object: diff_curves data.frame containing difference curves used calculating integrals. diff_intergals numeric vector containing integrals difference estimated adjusted survival curves CIFs. observed_diff_curve curve difference two non-bootstrapped adjusted survival curves CIFs. observed_diff_integral integral curve observed_diff_curve. integral_se bootstrap standard error difference integral. p_value p-value modified Pepe-Fleming Test. See details. n_boot number bootstrap repetitions used. kind Whether survival curves cumulative incidence functions used. conf_int percentile bootstrap confidence interval difference two curves. categorical Whether two treatments/groups. treat_labs labels treatments/groups. method adjustment method used original adjustedsurv adjustedcif object. interpolation interpolation method specified original adjustedsurv adjustedcif object. call original function call. two treatment groups object returned list objects one list pairwise comparison. multiply imputed datasets used, object also includes mids_analyses object, including curve_test object imputed dataset. also includes mids_p_values object containing separately estimated p-values.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test if there is a difference between two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_test","text":"Margaret Sullivan Pepe Thomas R. Fleming (1989). \"Weighted Kaplan-Meier Statistics: Class Distance Tests Censored Survival Data\". : Biometrics 45.2, pp. 497-507 Margaret Sullivan Pepe Thomas R. Fleming (1991). \"Weighted Kaplan-Meier Statistics: Large Sample Optimality Considerations\". : Journal Royal Statistical Society: Series B 53.2, pp. 341-352 Nicholas . Fisher Peter Hall (1990). \"Bootstrap Hypothesis Testing\". : Australian Journal Statistics 32.2, pp. 177-190 Florent Le Borgne, Bruno Giraudeau, Anne Héléne Querard, Magali Giral, Yohann Foucher (2016). \"Comparisons Performance Different Statistical Tests Time--Event Analysis Confounding Factors: Practical Illustrations Kidney Transplantation\". : Statistics Medicine 35, pp. 1103-1116 Christine Licht (2010). \"New Methods Generating Significance Levels Multiply-Imputed Data\". PhD thesis. Otto-Friedrich-Universität Bamberg, Fakultät Sozial- und Wirtschaftswissenschaften","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Test if there is a difference between two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_test","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_curve_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if there is a difference between two Confounder-Adjusted Survival Curves or CIFs — adjusted_curve_test","text":"","code":"library(adjustedCurves) library(survival) library(cmprsk)  #### Simple Survival Case with adjusted survival curves ####  # simulate some data as example set.seed(42) sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cox-regression for the outcome cox_mod <- coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                  data=sim_dat, x=TRUE)  # use it to estimate adjusted survival curves with bootstrapping adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=FALSE,                         bootstrap=TRUE,                         n_boot=10) # n_boot should be much higher in reality  # test the equality of both curves in the interval 0 to 1 adjtest <- adjusted_curve_test(adjsurv, from=0, to=1) print(adjtest) #> ------------------------------------------------------------------ #>    Test of the Difference between two adjusted Survival Curves #> ------------------------------------------------------------------ #>  #> Using the interval: 0 to 1  #>  #>            ABC ABC SE 95% CI (lower) 95% CI (upper) P-Value N Boot #> 0 vs. 1 -0.144 0.0998        -0.2857         0.0297     0.2     10 #> ------------------------------------------------------------------  #### Competing Risks Case with adjusted CIFs #### library(riskRegression) library(prodlim)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cause-specific cox-regression for the outcome csc_mod <- CSC(Hist(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                data=sim_dat)  # use it to calculate adjusted CIFs for cause = 1 with bootstrapping adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       method=\"direct\",                       outcome_model=csc_mod,                       conf_int=FALSE,                       bootstrap=TRUE,                       n_boot=10,                       cause=1) #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Loglik converged before variable  1 ; coefficient may be infinite.  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  #> Warning: Rare event  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event   # test the equality of both curves in the interval 0 to 1 adjtest <- adjusted_curve_test(adjcif, from=0, to=1) print(adjtest) #> ------------------------------------------------------------------ #>    Test of the Difference between two adjusted CIFs  #> ------------------------------------------------------------------ #>  #> Using the interval: 0 to 1  #>  #>             ABC ABC SE 95% CI (lower) 95% CI (upper) P-Value N Boot #> 0 vs. 1 -0.0182 329910        -0.2683         835775       1     10 #> ------------------------------------------------------------------"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmst.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Confounder-Adjusted Restricted Mean Survival Times — adjusted_rmst","title":"Estimate Confounder-Adjusted Restricted Mean Survival Times — adjusted_rmst","text":"function can utilized estimate confounder-adjusted restricted mean survival time, given previously estimated adjusted survival curves.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmst.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Confounder-Adjusted Restricted Mean Survival Times — adjusted_rmst","text":"","code":"adjusted_rmst(adjsurv, to, from=0, conf_int=FALSE,               conf_level=0.95, interpolation=\"steps\",               difference=FALSE, ratio=FALSE,               group_1=NULL, group_2=NULL)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmst.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Confounder-Adjusted Restricted Mean Survival Times — adjusted_rmst","text":"adjsurv adjustedsurv object created using adjustedsurv function. number specifying left side time interval interest. See details. Usually kept 0 (default) estimate standard RMST. changed good reasons . number specifying right side time interval interest. See details. conf_int Whether bootstrap estimates used estimate standard errors confidence intervals RMST estimates. Can used bootstrap=TRUE used adjustedsurv call. conf_level number specifying confidence level bootstrap confidence intervals. interpolation Either \"steps\" (default) \"linear\". parameter controls interpolation performed. argument set \"steps\", curves treated step functions. set \"linear\", curves wil treated straight lines point estimates instead. Points lie estimated points interpolated accordingly. usually kept \"steps\". See Details. difference Whether estimate difference two adjusted restricted mean survival times instead. conf_int=TRUE also specified, function also return standard error difference, associated confidence interval p-value. p-value result one-sample t-test null-hypothesis difference equal 0. specify difference calculated, group_1 group_2 arguments can used. default, difference first second level variable computed. ratio Whether estimate ratio two adjusted restricted mean survival times instead. conf_int=TRUE also specified, function also return associated confidence interval p-value. p-value result one-sample t-test null-hypothesis ratio equal 1. specify ratio calculated, group_1 group_2 arguments can used. default, ratio first second level variable computed. confidence interval test-statistic estimated using Fieller method. group_1 Optional argument get specific difference ratio. argument takes single character string specifying one levels variable used original adjustedsurv adjustedcif function call. group subtracted . example group_1=\"\" group_2=\"B\" difference=TRUE difference - B used. NULL, order factor levels original data determines order. Ignored difference=FALSE ratio=FALSE. group_2 Also single character string specifying one levels variable. corresponds right side difference/ratio equation. See argument group_2. Ignored difference=FALSE ratio=FALSE.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmst.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Confounder-Adjusted Restricted Mean Survival Times — adjusted_rmst","text":"adjusted restricted mean survival times (RMST) estimated integrating estimated adjusted survival curves specified interval. Let \\(Z\\) grouping variable (corresponding variable argument adjustedsurv function) possible levels \\(Z \\\\{0, 1, 2, ..., k\\}\\). \\(T\\) defined time \\(\\hat{S}_z(t)\\) denotes estimated counterfactual survival function. RMST defined : $$RMST_{z}() = \\int_{=0}^{} \\hat{S}_z(t)dt$$ can interpreted mean survival time individuals group \\(Z = z\\) interval [, ]. Note however simply subtracting estimates give correct estimate area survival curves respective curves cross point. adjusted_curve_test function can used calculate actual area curves instead. See ?adjusted_curve_test information. Confidence Intervals adjsurv object created bootstrap=TRUE adjustedsurv function, bootstrap confidence intervals standard errors RMSTs can approximated setting conf_int TRUE. bootstrap samples occur survival function estimated , bootstrap sample discarded used calculations. Approximate variance calculations relying bootstrap estimates currently implemented. using difference=TRUE standard error difference two RMST values approximated \\(SE_{group_1 - group_2} = \\sqrt{SE_{group_1}^2 + SE_{group_2}^2}\\). using ratio=TRUE confidence intervals calculated using approximate formula given Fieller (1954), assuming values independent. Multiple Imputation multiple imputation used creating adjsurv object, analysis carried multiply imputed datasets pooled using Rubins Rule. bootstrapping carried well, pooled standard error imputed datasets used combination normal approximation re-calculate bootstrap confidence intervals. Competing Risks function used adjustedcif objects, survival probability estimated unbiased way competing risks present. However, similar quantity, adjusted restricted mean time lost, can calculated using adjusted_rmtl function. Graphical Displays plot RMST time (changing values argument) can produced using plot_rmst_curve function. Computational Details Instead relying numerical integration, function uses exact calculations. achieved using either step-function interpolation (interpolation=\"steps\", default) linear interpolation (interpolation=\"linear\"). former case, integral simply sum area squares defined step function. second case, integral simply sum area rectangles. Either way, need approximations. situations (example using parametric survival models method=\"direct\"), curves step functions. case interpolation argument set \"linear\".","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmst.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Confounder-Adjusted Restricted Mean Survival Times — adjusted_rmst","text":"Returns data.frame containing columns group (groups variable) rmst (estimated restricted mean survival time). conf_int=TRUE used additionally contains columns se (standard error restricted mean survival time), ci_lower (lower limit confidence interval), ci_upper (upper limit confidence interval) n_boot (actual number bootstrap estimates used). difference=TRUE used, instead returns data.frame contains columns diff (difference RMST values), se (standard error difference), ci_lower (lower limit confidence interval), ci_upper (upper limit confidence interval) p_value (p-value one-sample t-test). results presented using ratio=TRUE, except diff column named ratio se column.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmst.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate Confounder-Adjusted Restricted Mean Survival Times — adjusted_rmst","text":"Sarah C. Conner, Lisa M. Sullivan, Emelia J. Benjamin, Michael P. LaValley, Sandro Galea, Ludovic Trinquart (2019). \"Adjusted Restricted Mean Survival Times Observational Studies\". : Statistics Medicine 38, pp. 3832-3860 Patrick Royston Mahesh K. B. Parmar (2013). \"Restricted Mean Survival Time: Alternative Hazard Ratio Design Analysis Randomized Trials Time--Event Outcome\". : BMC Medical Research Methodology 13.152 Edgar C. Fieller (1954). \"Problems Interval Estimation\". : Journal Royal Statistical Society, Series B 16.2, pp. 175-185","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmst.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimate Confounder-Adjusted Restricted Mean Survival Times — adjusted_rmst","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmst.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Confounder-Adjusted Restricted Mean Survival Times — adjusted_rmst","text":"","code":"library(adjustedCurves) library(survival)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=30, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cox-regression for the outcome cox_mod <- coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                  data=sim_dat, x=TRUE)  # use it to calculate adjusted survival curves with bootstrapping adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=FALSE,                         bootstrap=TRUE,                         n_boot=10) # n_boot should be much higher in reality  # calculate adjusted restricted mean survival times from 0 to 1 adjrmst <- adjusted_rmst(adjsurv, from=0, to=0.5, conf_int=FALSE)  # calculate adjusted restricted mean survival times from 0 to 1, # including standard errors and confidence intervals adjrmst <- adjusted_rmst(adjsurv, from=0, to=0.5, conf_int=TRUE,                          conf_level=0.95)  # calculate difference between adjusted restricted mean survival times # from 0 to 1 in the two groups adjrmst <- adjusted_rmst(adjsurv, from=0, to=0.5, conf_int=FALSE,                          difference=TRUE)  # calculate ratio between adjusted restricted mean survival times # from 0 to 1 in the two groups adjrmst <- adjusted_rmst(adjsurv, from=0, to=0.5, conf_int=FALSE,                          ratio=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmtl.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Confounder-Adjusted Restricted Mean Time Lost — adjusted_rmtl","title":"Estimate Confounder-Adjusted Restricted Mean Time Lost — adjusted_rmtl","text":"function can utilized estimate confounder-adjusted restricted mean time lost (RMTL), possibly due specific cause, given previously estimated adjusted survival curves / CIFs created using adjustedsurv adjustedcif function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmtl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Confounder-Adjusted Restricted Mean Time Lost — adjusted_rmtl","text":"","code":"adjusted_rmtl(adj, to, from=0, conf_int=FALSE,               conf_level=0.95, interpolation=\"steps\",               difference=FALSE, ratio=FALSE,               group_1=NULL, group_2=NULL)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmtl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Confounder-Adjusted Restricted Mean Time Lost — adjusted_rmtl","text":"adj adjustedsurv object created using adjustedsurv function adjustedcif object created using adjustedcif function. number specifying left side time interval interest. See details. Usually kept 0 (default) estimate standard RMTL. changed good reasons . number specifying right side time interval interest. See details. conf_int Whether bootstrap estimates used estimate standard errors confidence intervals RMST estimates. Can used bootstrap=TRUE used adjustedsurv adjustedcif call. conf_level number specifying confidence level bootstrap confidence intervals. interpolation Either \"steps\" (default) \"linear\". parameter controls interpolation performed. argument set \"steps\", curves treated step functions. set \"linear\", curves wil treated straight lines point estimates instead. Points lie estimated points interpolated accordingly. usually kept \"steps\". See Details. difference Whether estimate difference two adjusted RMTLs instead. conf_int=TRUE also specified, function also return standard error difference, associated confidence interval p-value. p-value result one-sample t-test null-hypothesis difference equal 0. specify difference estimated, group_1 group_2 arguments can used. default, difference first second level variable computed. ratio Whether estimate ratio two RMTLs instead. conf_int=TRUE also specified, function also return associated confidence interval p-value. p-value result one-sample t-test null-hypothesis ratio equal 1. specify ratio calculated, group_1 group_2 arguments can used. default, ratio first second level variable computed. confidence interval test-statistic estimated using Fieller method. group_1 Optional argument get specific difference ratio. argument takes single character string specifying one levels variable used original adjustedsurv adjustedcif function call. group subtracted . example group_1=\"\" group_2=\"B\" difference=TRUE difference - B used. NULL, order factor levels original data determines order. Ignored difference=FALSE ratio=FALSE. group_2 Also single character string specifying one levels variable. corresponds right side difference / ratio equation. See argument group_2. Ignored difference=FALSE ratio=FALSE.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmtl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Confounder-Adjusted Restricted Mean Time Lost — adjusted_rmtl","text":"cause-specific adjusted restricted mean time lost (RMTL) calculated integrating estimated adjusted cause-specific CIF specified interval. Let \\(Z\\) grouping variable (corresponding variable argument adjustedcif function) possible levels \\(Z \\\\{0, 1, 2, ..., k\\}\\). \\(T\\) defined time \\(\\hat{F}_z^d(t)\\) denotes estimated counterfactual CIF cause \\(d\\). RMTL defined : $$RMTL_{z}^d() = \\int_{=0}^{} \\hat{F}_z^d(t)dt$$ can interpreted mean time takes individual succumb event interest group \\(Z = z\\) interval [0, ]. . information method can found references. Note however simply subtracting estimates give correct estimate area CIFs respective curves cross point. adjusted_curve_test function can used calculate actual area curves instead. See ?adjusted_curve_test information. adjustedsurv object supplied adj argument, CIF calculated adjusted survival curves using simple transformation: \\(\\hat{F}_{z}(t) = 1 - \\hat{S}_z(t)\\). calculations identical. Confidence Intervals adj object created bootstrap=TRUE corresponding function, bootstrap confidence intervals standard errors RMTLs can approximated setting conf_int TRUE. bootstrap samples occur CIF estimated , bootstrap sample discarded used calculations. Approximate variance calculations relying bootstrap estimates currently implemented. using difference=TRUE standard error difference two RMST values approximated \\(SE_{group_1 - group_2} = \\sqrt{SE_{group_1}^2 + SE_{group_2}^2}\\). using ratio=TRUE confidence intervals calculated using approximate formula given Fieller (1954), assuming values independent. Multiple Imputation multiple imputation used creating adj object, analysis carried multiply imputed datasets pooled using Rubins Rule. bootstrapping carried well, pooled standard error imputed datasets used combination normal approximation re-calculate bootstrap confidence intervals. Graphical Displays plot RMTL time (changing values argument) can produced using plot_rmtl_curve function. Computational Details Instead relying numerical integration, function uses exact calculations. achieved using either step-function interpolation (interpolation=\"steps\", default) linear interpolation (interpolation=\"linear\"). former case, integral simply sum area squares defined step function. second case, integral simply sum area rectangles. Either way, need approximations. situations (example using parametric models method=\"direct\"), curves step functions. case interpolation argument set \"linear\".","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmtl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Confounder-Adjusted Restricted Mean Time Lost — adjusted_rmtl","text":"Returns data.frame containing columns group (groups variable) rmtl (estimated restricted mean time lost). conf_int=TRUE used additionally contains columns se (standard error restricted mean time lost), ci_lower (lower limit confidence interval), ci_upper (upper limit confidence interval) n_boot (actual number bootstrap estimates used). difference=TRUE used, instead returns data.frame contains columns diff (difference RMTL values), se (standard error difference), ci_lower (lower limit confidence interval), ci_upper (upper limit confidence interval) p_value (p-value one-sample t-test). results presented using ratio=TRUE, except diff column named ratio se column.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmtl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate Confounder-Adjusted Restricted Mean Time Lost — adjusted_rmtl","text":"Sarah C. Conner Ludovic Trunquart (2021). \"Estimation Modeling Restricted Mean Time Lost Presence Competing Risks\". : Statistics Medicine Edgar C. Fieller (1954). \"Problems Interval Estimation\". : Journal Royal Statistical Society, Series B 16.2, pp. 175-185","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmtl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimate Confounder-Adjusted Restricted Mean Time Lost — adjusted_rmtl","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_rmtl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Confounder-Adjusted Restricted Mean Time Lost — adjusted_rmtl","text":"","code":"library(adjustedCurves) library(survival)  ###### when using single-event survival data  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cox-regression for the outcome cox_mod <- coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                  data=sim_dat, x=TRUE)  # use it to calculate adjusted survival curves with bootstrapping adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=FALSE,                         bootstrap=TRUE,                         n_boot=10) # n_boot should be much higher in reality  # calculate adjusted restricted mean survival times from 0 to 1 adjrmst <- adjusted_rmst(adjsurv, from=0, to=1, conf_int=FALSE)  # calculate adjusted restricted mean time lost estimates from 0 to 1, # including standard errors and confidence intervals adjrmst <- adjusted_rmst(adjsurv, from=0, to=1, conf_int=TRUE,                          conf_level=0.95)  # calculate difference in adjusted restricted mean survival times from 0 to 1 adjrmst <- adjusted_rmst(adjsurv, from=0, to=1, conf_int=FALSE,                          difference=TRUE)  ###### when using data with competing-risks  library(riskRegression) library(prodlim)  # simulate some data as example set.seed(42) sim_dat <- sim_confounded_crisk(n=50) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cause-specific cox-regression model for the outcome csc_mod <- CSC(Hist(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                data=sim_dat)  # calculate confounder-adjusted cause-specific CIFs for cause = 1 adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       method=\"direct\",                       outcome_model=csc_mod,                       conf_int=FALSE,                       bootstrap=TRUE,                       n_boot=10,                       cause=1) #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.   # calculate adjusted restricted mean time lost estimates from 0 to 1 # including standard errors and confidence intervals adjrmtl <- adjusted_rmtl(adjcif, from=0, to=1, conf_int=TRUE)  # calculate ratio of adjusted restricted mean time lost estimates from 0 to 1 # including confidence interval and p-value adjrmtl <- adjusted_rmtl(adjcif, from=0, to=1, conf_int=TRUE, ratio=TRUE) #> Warning: NaNs produced"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_surv_quantile.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Confounder-Adjusted Survival Time Quantiles — adjusted_surv_quantile","title":"Estimate Confounder-Adjusted Survival Time Quantiles — adjusted_surv_quantile","text":"function can utilized estimate confounder-adjusted survival time quantiles, including median survival time, given previously estimated adjusted survival curves.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_surv_quantile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Confounder-Adjusted Survival Time Quantiles — adjusted_surv_quantile","text":"","code":"adjusted_surv_quantile(adjsurv, p=0.5, conf_int=FALSE,                        use_boot=FALSE, interpolation=\"steps\")"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_surv_quantile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Confounder-Adjusted Survival Time Quantiles — adjusted_surv_quantile","text":"adjsurv adjustedsurv object created using adjustedsurv function. p quantile interest. calculate median survival time, set parameter 0.5 (default). Multiple values form numeric vector allowed. conf_int Whether calculate confidence intervals . calculated way quantiles using confidence limit curves. requires either conf_int=TRUE bootstrap=TRUE used original adjustedsurv function call. Since directly uses previously estimated intervals, confidence level used original adjustedsurv call used . use_boot Whether use bootstrap confidence interval estimates survival curves estimate confidence intervals survival time quantiles . Can used bootstrap=TRUE used original adjustedsurv function call. Ignored conf_int=FALSE. interpolation Either \"steps\" (default) \"linear\". parameter controls interpolation performed. argument set \"steps\", curves treated step functions. set \"linear\", curves wil treated straight lines point estimates instead. Points lie estimated points interpolated accordingly.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_surv_quantile.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Confounder-Adjusted Survival Time Quantiles — adjusted_surv_quantile","text":"median survival time simply time half patients expected alive. chance surviving beyond time 50 percent. general, quantile can calculated way. can read directly respective survival curve drawing straight line desired quantile p Y-Axis reading X-Axis value line intersects survival curve. adjusted survival time quantile group \\(z\\) (corresponding variable argument adjustedsurv function) formally defined : $$\\hat{Q}_z(p) = min\\left(t | \\hat{S}_z(t) \\leq p\\right)$$ \\(\\hat{S}_z(t)\\) estimated counterfactual survival function \\(z\\). survival probability never drops p, survival time quantile calculated. also applies confidence interval estimation. function calculates quantity automatically. multiple imputation used original function call, survival time quantiles read final pooled survival curves directly.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_surv_quantile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Confounder-Adjusted Survival Time Quantiles — adjusted_surv_quantile","text":"Returns data.frame containing columns p (quantiles original function call), group (groups variable) q_surv (survival time quantile). conf_int=TRUE used also includes confidence limits ci_lower ci_upper columns.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_surv_quantile.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate Confounder-Adjusted Survival Time Quantiles — adjusted_surv_quantile","text":"Omer Ben-Aharon, Racheli Magnezi, Moshe Leshno, Daniel . Goldstein (2019). \"Median Survival Mean Survival: Measure Appropriate Patients, Physicians, Policymakers?\" : Oncologist 24, pp. 1469-1478 Zhongxue Chen Guoyi Zhang (2016). \"Comparing Survival Curves based Medians\". : BMC Medical Research Methodology 16.33","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_surv_quantile.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimate Confounder-Adjusted Survival Time Quantiles — adjusted_surv_quantile","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjusted_surv_quantile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Confounder-Adjusted Survival Time Quantiles — adjusted_surv_quantile","text":"","code":"library(adjustedCurves) library(survival)  # simulate some data as example set.seed(42) sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cox-regression for the outcome cox_mod <- coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                  data=sim_dat, x=TRUE)  # use it to calculate adjusted survival curves with bootstrapping adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=TRUE,                         bootstrap=FALSE)  # calculate adjusted median survival times adjusted_surv_quantile(adjsurv) #>     p group    q_surv #> 1 0.5     0 0.5105218 #> 2 0.5     1 0.6561380  # calculate other quantiles + confidence intervals adjusted_surv_quantile(adjsurv, conf_int=TRUE, p=c(0.2, 0.4)) #>     p group    q_surv  ci_lower  ci_upper #> 1 0.2     0 0.7408272 0.6177998 1.0331462 #> 2 0.4     0 0.6083660 0.4784817 0.7015162 #> 3 0.2     1        NA 0.7408272        NA #> 4 0.4     1 0.7501622 0.6177998 1.0503161"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedcif.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Cause-Specific Confounder-Adjusted Cumulative Incidence Functions — adjustedcif","title":"Estimate Cause-Specific Confounder-Adjusted Cumulative Incidence Functions — adjustedcif","text":"one two main functions R-Package. allows user estimate cause-specific confounder-adjusted cumulative incidence functions presence competing events using variety different methods. methods require additional packages installed , depending specified method, might additional required arguments function call. information available documentation page respective cif_method.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedcif.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Cause-Specific Confounder-Adjusted Cumulative Incidence Functions — adjustedcif","text":"","code":"adjustedcif(data, variable, ev_time, event, cause,             method, conf_int=FALSE, conf_level=0.95,             times=NULL, bootstrap=FALSE, n_boot=500,             n_cores=1, na.action=options()$na.action,             clean_data=TRUE, iso_reg=FALSE,             force_bounds=FALSE, mi_extrapolation=FALSE,             ...)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedcif.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Cause-Specific Confounder-Adjusted Cumulative Incidence Functions — adjustedcif","text":"data data.frame object containing needed time--event data standard format. Can also mids object created mice package. See details works. variable character string specifying variable cumulative incidence functions grouped. Must valid column name data. variable specified needs factor variable. ev_time character string specifying variable indicating time--event time--censoring. Must valid column name data. event character string specifying numeric event indicator. censoring indicator coded 0 events interest 1, 2, etc. Must valid column name data. cause cause interest cumulative incidence functions estimated. number appears event column data. method character string specifying adjustment method use. Case sensitive. See details. conf_int logical variable, indicating whether asymptotic variances confidence intervals cumulative incidence estimated. available methods. information can found documentation method. alternative way get confidence intervals, see bootstrap argument. conf_level number specifying confidence level asymptotic /bootstrap confidence intervals. times numeric vector time points cumulative incidences estimated NULL. NULL cumulative incidence estimated points time event occurred pooled sample. bootstrap logical variable indicating whether bootstrapping performed . bootstrapping, number simple random samples replacement size nrow(data) drawn data. sample calculations repeated used estimate standard errors confidence intervals. can used obtain confidence intervals asymptotic variance calculations available. n_boot Number bootstrap replications perform. Ignored bootstrap FALSE. n_cores number cores use calculating bootstrap estimates. Ignored bootstrap=FALSE. set 1 default, resulting single threaded processing. Internally uses doParallel package n_cores > 1. case also uses doRNG package make results replicable. See ?doRNG ?doParallel details. Using multiple cores speed calculation considerably cases. na.action missing values handled. Can one : na.fail, na.omit, na.pass na.exclude. Also accepts strings function names. See ?na.action details. default uses na.action set global options respective user. clean_data TRUE columns needed estimation removed data calculations performed. ensures calls na.omit (see argument na.action) remove rows fully observed respect relevant columns due missing values irrelevant columns. Set FALSE skip step. Usually argument can ignored. using non-standard outcome models however set FALSE. iso_reg Either TRUE FALSE (default), controlling whether isotonic regression performed resulting failure probability estimates. can used ensure CIFs non-decreasing. Since methods may exhibit problem, argument relevant methods (see method specific documentation). force_bounds Either TRUE FALSE (default), controlling whether resulting failure probability estimates forced lie 0 1. TRUE values higher 1, simply set 1. Values lower 0 similarly set 0. Since methods may exhibit problem, argument relevant methods (see method specific documentation). mi_extrapolation Whether allow extrapolation due imputed survival times . argument relevant using multiply imputed data missing covariates variable, ev_time event. Depending algorithm used obtain imputed datasets, may possible one imputed datasets contain survival times group larger maximum observed survival time group. may lead estimation problems. keeping argument FALSE, times considered ouput. set TRUE, available estimates used. ... arguments passed respective cif_method. example using method=\"direct\" arguments passed cif_direct function. See details.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedcif.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Cause-Specific Confounder-Adjusted Cumulative Incidence Functions — adjustedcif","text":"primary purpose adjustedcif function provide convenient way estimate confounder-adjusted cumulative incidence functions using methods provided literature. plot method provided graphically display estimated cumulative incidence functions well. Currently following methods can used: \"direct\": Direct Standardization based model describing outcome mechanism (CSC, FGR, ..). \"direct_pseudo\": Direct Standardization based Pseudo-Values. \"iptw\": weighted Aalen-Johansen estimator. \"iptw_pseudo\": weighted estimator based Pseudo-Values. \"matching\": Using Propensity Score Matching estimate adjusted CIFs. \"aiptw\": Augmented Inverse Probability Treatment Weighting estimator. \"aiptw_pseudo\": Augmented Inverse Probability Treatment Weighting estimator using Pseudo-Values. \"tmle\": Targeted Maximum Likelihood Estimation continuous time time--event data competing events. \"aalen_johansen\": simple stratified Aalen-Johansen estimator without form adjustment. short description method contained documentation respective cif_method function. concise overview supported functionality method can found associated vignette (vignette(topic=\"method_overview\", package=\"adjustedCurves\")). detailed descriptions cited literature respective documentation pages can used. documentation method=\"direct\" example can accessed using ?cif_direct. Required & Optional Arguments Every method requires specification data, variable, ev_time, event, cause method arguments. arguments mentioned page optional work methods. Depending method used, arguments required well. can found top help page respective method. help pages also list additional optional arguments. Confidence Intervals methods approximations asymptotic variance point estimates CIF proposed literature. available, can estimated added output object using conf_int=TRUE. however recommended use bootstrapping estimate variance instead, can done setting bootstrap=TRUE. n_boot argument set 500 default. number chosen worked well simulations guarantee convergence practice. Users recommended inspect bootstrapped estimates adjust number replications accordingly. allow faster bootstrapping user can choose run function multiple CPU cores parallel using n_cores argument. Missing Data two ways deal missing data using function. first using na.action argument. simply calls respective na.action function data processing. using na.action=\"na.omit\" example, rows complete data kept analysis. Alternatively, function also supports use multiple imputation via mice package. Instead supplying single data.frame, user create mids object using mice function directly pass data argument. methods used rely previously estimated treatment outcome models \"direct\" \"aiptw\", user required supply mira object instead single model. words: models fit every imputed dataset supplying function. See ?mice associated documentation information use multiple imputation. using bootstrap=TRUE multiple imputation, bootstrapping performed every imputed dataset separately. Cumulative Incidences simply averaged across imputed datasets according Rubins Rule. Confidence intervals calculated first averaging standard errors imputed datasets afterwards using pooled value obtain new confidence interval normal approximation. Competing Risks function meant used data containing multiple competing risks. data contain competing-events, recommended use adjustedsurv function instead. estimate CIF directly, CIF can calculated survival using CIF = 1 - \\(S(t)\\). can done automatically plot.adjustedsurv function using cif=TRUE. Graphical Displays general plot estimated adjusted CIFs can obtained using associated plot method. addition, plot difference two estimated adjusted CIFs can produced using plot_curve_diff function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedcif.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Cause-Specific Confounder-Adjusted Cumulative Incidence Functions — adjustedcif","text":"Returns adjustedcif object containing following objects: adjcif data.frame estimated cumulative incidences cause points time level variable. Depending arguments used also includes standard errors confidence intervals. method method used adjust CIFs. categorical Whether 2 groups variable. call original function call. argument bootstrap set TRUE additionally contains following objects: boot_data adjusted CIFs estimated bootstrap sample. boot_adjcif mean CIFs bootstrap samples corresponding standard errors percentile confidence intervals. multiple imputation used, function additionally contains mids_analyses object, containing adjustedcif objects imputed dataset. method specific objects might also contained output.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedcif.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate Cause-Specific Confounder-Adjusted Cumulative Incidence Functions — adjustedcif","text":"Robin Denz, Renate Klaaßen-Mielke, Nina Timmesfeld (2023). \"Comparison Different Methods Adjust Survival Curves Confounders\". : Statistics Medicine 42.10, pp. 1461-1479 relevant literature can found respective cif_method documentation.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedcif.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimate Cause-Specific Confounder-Adjusted Cumulative Incidence Functions — adjustedcif","text":"function written Robin Denz, cif_method functions include wrappers functions written people. information can found respective cif_method documentation.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedcif.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Cause-Specific Confounder-Adjusted Cumulative Incidence Functions — adjustedcif","text":"","code":"library(adjustedCurves) library(survival) library(riskRegression)  set.seed(42)  # simulate some example data sim_dat <- sim_confounded_crisk(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # treatment assignment model glm_mod <- glm(group ~ x2 + x3 + x5 + x6, data=sim_dat, family=\"binomial\")  # outcome model cox_mod <- CSC(Hist(time, event) ~ x1 + x2 + x4 + x5 + group, data=sim_dat)  # using direct adjustment with asymptotic confidence intervals for cause 1 adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"direct\",                       outcome_model=cox_mod,                       conf_int=TRUE,                       bootstrap=FALSE) #> Warning: Rare event   # using IPTW with asymptotic confidence intervals for cause 2 adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       method=\"iptw\",                       cause=2,                       treatment_model=glm_mod,                       conf_int=TRUE,                       bootstrap=FALSE)  # using AIPTW with asymptotic confidence intervals for cause 1 adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"aiptw\",                       outcome_model=cox_mod,                       treatment_model=glm_mod,                       conf_int=TRUE,                       bootstrap=FALSE) #> Warning: Rare event   # using direct adjustment at custom points in time custom_times <- c(0.001, 0.1, 0.2, 0.6, 1.1) adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"direct\",                       outcome_model=cox_mod,                       conf_int=TRUE,                       bootstrap=FALSE,                       times=custom_times) #> Warning: Rare event   # using bootstrapping with direct adjustment # NOTE: In practice the number of bootstrap replications should be #       greater than 10. This is only shown here for convenience. adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"direct\",                       outcome_model=cox_mod,                       conf_int=TRUE,                       bootstrap=TRUE,                       n_boot=10) #> Warning: Rare event  #> Warning: Loglik converged before variable  5 ; coefficient may be infinite.  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Loglik converged before variable  5 ; coefficient may be infinite.  #> Warning: Rare event  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Loglik converged before variable  5 ; coefficient may be infinite.  #> Warning: Rare event  #> Warning: Rare event  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event   # not run because those are too slow # \\donttest{ # using bootstrapping with direct adjustment, run in parallel # on two cores library(foreach) library(parallel) library(doRNG) #> Loading required package: rngtools  adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"direct\",                       outcome_model=cox_mod,                       conf_int=TRUE,                       bootstrap=TRUE,                       n_boot=4,                       n_cores=2) #> Loading required namespace: doParallel #> Warning: Rare event   # using multiple imputation library(mice) library(WeightIt)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # introduce random missingness in x1 as example # NOTE: This is only done as an example, in reality you would #       already have missing data, not introduce it yourself. sim_dat$x1 <- ifelse(runif(n=50) < 0.5, sim_dat$x1, NA)  # perform multiple imputation mids <- mice::mice(data=sim_dat, method=\"pmm\", m=2, printFlag=FALSE)  # IPTW Pseudo using WeightIt on imputed data, for cause = 1 adj <- adjustedcif(data=mids,                    variable=\"group\",                    ev_time=\"time\",                    event=\"event\",                    method=\"iptw_pseudo\",                    cause=1,                    treatment_model=group ~ x1 + x2 + x5 + x6,                    weight_method=\"ps\") plot(adj, force_bounds=TRUE, iso_reg=TRUE)   # More specific examples can be found in the documentation of each # respective cif_method. See ?cif_ + \"method\" for more information. # }"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Confounder-Adjusted Survival Curves — adjustedsurv","title":"Estimate Confounder-Adjusted Survival Curves — adjustedsurv","text":"one two main functions R-Package. allows user estimate confounder-adjusted survival curves using variety different methods. methods require additional packages installed , depending specified method, might additional required arguments function call. information available documentation page respective surv_method.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Confounder-Adjusted Survival Curves — adjustedsurv","text":"","code":"adjustedsurv(data, variable, ev_time, event, method,              conf_int=FALSE, conf_level=0.95, times=NULL,              bootstrap=FALSE, n_boot=500,              n_cores=1, na.action=options()$na.action,              clean_data=TRUE, iso_reg=FALSE,              force_bounds=FALSE, mi_extrapolation=FALSE,              ...)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Confounder-Adjusted Survival Curves — adjustedsurv","text":"data data.frame object containing needed time--event data standard format. Ideally, data set contain required variables. Can also mids object created mice package. See details works. variable character string specifying variable survival curves grouped. Must valid column name data. variable specified needs factor variable. ev_time character string specifying variable indicating time--event time--censoring. Must valid column name data. event character string specifying binary event indicator. Must valid column name data. method character string specifying adjustment method use. Case sensitive. See details. conf_int logical variable, indicating whether asymptotic variances confidence intervals survival probabilities estimated. available methods. information can found documentation method. alternative way get confidence intervals, see bootstrap argument. conf_level number specifying confidence level asymptotic /bootstrap confidence intervals. times numeric vector time points survival probability estimated NULL (default). NULL survival probability estimated points time event occurred pooled sample. bootstrap logical variable indicating whether bootstrapping performed . bootstrapping, number simple random samples replacement size nrow(data) drawn data. sample calculations repeated used estimate standard errors confidence intervals. can used obtain confidence intervals asymptotic variance calculations available. n_boot Number bootstrap replications perform. Ignored bootstrap FALSE. n_cores number cores use calculating bootstrap estimates. Ignored bootstrap=FALSE. set 1 default, resulting single threaded processing. Internally uses doParallel package n_cores > 1. case also uses doRNG package make results replicable. See ?doRNG ?doParallel details. Using multiple cores speed calculation considerably cases. na.action missing values handled. Can one : na.fail, na.omit, na.pass na.exclude. Also accepts strings function names. See ?na.action details. default uses na.action set global options respective user. Ignored multiple imputation used. clean_data TRUE columns needed estimation removed data calculations performed. ensures calls na.omit (see argument na.action) remove rows fully observed respect relevant columns due missing values irrelevant columns. Set FALSE skip step. Usually argument can ignored. using non-standard outcome models however set FALSE. iso_reg Either TRUE FALSE (default), controlling whether isotonic regression performed resulting survival probability estimates. can used ensure survival curves non-increasing. Since methods may problem, argument relevant methods (see method specific documentation). force_bounds Either TRUE FALSE (default), controlling whether resulting survival probability estimates forced lie 0 1. TRUE values higher 1, simply set 1. Values lower 0 similarly set 0. Since methods may problem, argument relevant methods (see method specific documentation). mi_extrapolation Whether allow extrapolation due imputed survival times . argument relevant using multiply imputed data missing covariates variable, ev_time event. Depending algorithm used obtain imputed datasets, may possible one imputed datasets contain survival times group larger maximum observed survival time group. may lead estimation problems. keeping argument FALSE, times considered ouput. set TRUE, available estimates used. ... arguments passed respective surv_method. example using method=\"direct\" arguments passed surv_direct function. See details.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedsurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Confounder-Adjusted Survival Curves — adjustedsurv","text":"primary purpose adjustedsurv function provide convenient way estimate confounder-adjusted survival curves using methods provided literature. plot method provided graphically display estimated survival curves well. Currently following methods can used: \"direct\": Direct Standardization based previously fit model (Cox-Regression, ...). \"direct_pseudo\": Direct Standardization based Pseudo-Values. \"iptw_km\": weighted Kaplan-Meier estimator. \"iptw_cox\": weighted estimator based stratified weighted Cox-Regression model. \"iptw_pseudo\": weighted estimator based Pseudo-Values. \"matching\": Using Propensity Score Matching estimate adjusted survival curves. \"emp_lik\": Empirical Likelihood based estimator. \"aiptw\": Augmented Inverse Probability Treatment Weighting estimator. \"aiptw_pseudo\": Augmented Inverse Probability Treatment Weighting estimator using Pseudo-Values. \"tmle\": Targeted Maximum Likelihood Estimation continuously distributed time--event data. \"strat_amato\": method based stratification weighting Amato (1988). \"strat_nieto\": method based stratification weighting Gregory (1988) Nieto & Coresh (1996). \"strat_cupples\": method based stratification weighting Cupples et al. (1995). \"iv_2SRIF\": instrumental variable method based two stage residual inclusion frailty term. \"prox_iptw\": Proximal causal inference based inverse probability treatment weighting. \"prox_aiptw\": Proximal causal inference based augmented inverse probability treatment weighting. \"km\": simple stratified Kaplan-Meier estimator without form adjustment. short description method contained documentation respective surv_method function. concise overview supported functionality method can found associated vignette (vignette(topic=\"method_overview\", package=\"adjustedCurves\")). detailed descriptions cited literature respective documentation pages can used. documentation method=\"direct\" example can accessed using ?surv_direct. Required & Optional Arguments Every method requires specification data, variable, ev_time, event method arguments. arguments mentioned page optional work methods. Depending method used, arguments required well. can found top help page respective method. help pages also list additional optional arguments. Confidence Intervals methods approximations asymptotic variance point estimates survival function proposed literature. available, can estimated added output object using conf_int=TRUE. however recommended use bootstrapping estimate variance instead, can done setting bootstrap=TRUE. n_boot argument set 500 default. number chosen worked well simulations guarantee convergence practice. Users recommended inspect bootstrapped estimates adjust number replications accordingly. allow faster bootstrapping user can choose run function multiple CPU cores parallel using n_cores argument. Missing Data two ways deal missing data using function. first using na.action argument. simply calls respective na.action function data processing. using na.action=\"na.omit\" example, rows complete data kept analysis. Alternatively, function also supports use multiple imputation via mice package. Instead supplying single data.frame, user create mids object using mice function directly pass data argument. methods used rely previously estimated treatment assignment outcome models \"direct\" \"aiptw\", user required supply mira object instead single model. words: models fit every imputed dataset supplying function. See ?mice associated documentation information use multiple imputation. using bootstrap=TRUE multiple imputation, bootstrapping performed every imputed dataset separately. Survival probabilities simply averaged across imputed datasets according Rubins Rule. Confidence intervals calculated first averaging standard errors imputed datasets afterwards using pooled value obtain new confidence interval normal approximation. Competing Risks data contains competing-risks, function used. however possible estimate confounder-adjusted cause-specific cumulative incidence functions using adjustedcif function. Graphical Displays general plot estimated adjusted survival curves can obtained using associated plot method. addition, plot difference two estimated adjusted survival curves can produced using plot_curve_diff function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Confounder-Adjusted Survival Curves — adjustedsurv","text":"Returns adjustedsurv object containing following objects: adjsurv data.frame estimated adjusted survival probabilities points time level variable. Depending arguments used also includes standard errors confidence intervals. data data.frame used original function call. method method used adjust survival curves. categorical Whether 2 groups variable. call original function call. argument bootstrap set TRUE, additionally contains following objects: boot_data adjusted survival curves estimated bootstrap sample. boot_adjsurv mean adjusted survival curves bootstrap samples corresponding standard errors percentile confidence intervals. multiple imputation used, function additionally contains mids_analyses object, containing adjustedsurv objects imputed dataset. method specific objects might also contained output.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedsurv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate Confounder-Adjusted Survival Curves — adjustedsurv","text":"Robin Denz, Renate Klaaßen-Mielke, Nina Timmesfeld (2023). \"Comparison Different Methods Adjust Survival Curves Confounders\". : Statistics Medicine 42.10, pp. 1461-1479 relevant literature can found respective surv_method documentation.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedsurv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimate Confounder-Adjusted Survival Curves — adjustedsurv","text":"function written Robin Denz, surv_method functions include wrappers functions written people. information can found respective surv_method documentation.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/adjustedsurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Confounder-Adjusted Survival Curves — adjustedsurv","text":"","code":"library(adjustedCurves) library(survival)  set.seed(42)  # simulate some example data sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # treatment assignment model glm_mod <- glm(group ~ x2 + x3 + x5 + x6, data=sim_dat, family=\"binomial\")  # outcome model cox_mod <- coxph(Surv(time, event) ~ x1 + x2 + x4 + x5 + group,                  data=sim_dat, x=TRUE)  # using direct adjustment with asymptotic confidence intervals adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=TRUE,                         bootstrap=FALSE)  # using IPTW Kaplan-Meier with asymptotic confidence intervals adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=glm_mod,                         conf_int=TRUE,                         bootstrap=FALSE)  # using AIPTW with asymptotic confidence intervals adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"aiptw\",                         outcome_model=cox_mod,                         treatment_model=glm_mod,                         conf_int=TRUE,                         bootstrap=FALSE)  # using direct adjustment at custom points in time custom_times <- c(0.001, 0.1, 0.2, 0.6, 1.1) adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=TRUE,                         bootstrap=FALSE,                         times=custom_times)  # using bootstrapping with direct adjustment # NOTE: n_boot should be much higher than 10 in reality, only used #       here as a fast example adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=TRUE,                         bootstrap=TRUE,                         n_boot=10)  # not run because those are too slow # \\donttest{ # using bootstrapping with direct adjustment, run in parallel # on two cores adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=TRUE,                         bootstrap=TRUE,                         n_boot=4,                         n_cores=2)  # using multiple imputation library(mice) library(WeightIt)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # introduce random missingness in x1 as example # NOTE: This is only done as an example, in reality you would #       already have missing data, not introduce it yourself. sim_dat$x1 <- ifelse(runif(n=50) < 0.5, sim_dat$x1, NA)  # perform multiple imputation mids <- mice::mice(data=sim_dat, method=\"pmm\", m=2, printFlag=FALSE)  # IPTW KM using WeightIt on imputed data adj <- adjustedsurv(data=mids,                     variable=\"group\",                     ev_time=\"time\",                     event=\"event\",                     method=\"iptw_km\",                     treatment_model=group ~ x1 + x2 + x5 + x6,                     weight_method=\"ps\") plot(adj)   # More specific examples can be found in the documentation of each # respective surv_method. See ?surv_ + \"method\" for more information. # }"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/as_ggsurvplot_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract a data.frame containing the estimated survival curves from a adjustedsurv object — as_ggsurvplot_df","title":"Extract a data.frame containing the estimated survival curves from a adjustedsurv object — as_ggsurvplot_df","text":"small convenience function extract important quantities adjustedsurv object. resulting data.frame structured according format required ggsurvplot_df function survminer package, making easy use ggsurvplot_df function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/as_ggsurvplot_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract a data.frame containing the estimated survival curves from a adjustedsurv object — as_ggsurvplot_df","text":"","code":"as_ggsurvplot_df(adjsurv)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/as_ggsurvplot_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract a data.frame containing the estimated survival curves from a adjustedsurv object — as_ggsurvplot_df","text":"adjsurv object class adjustedsurv created adjustedsurv function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/as_ggsurvplot_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract a data.frame containing the estimated survival curves from a adjustedsurv object — as_ggsurvplot_df","text":"Returns data.frame containing required information, extracted adjustedsurv object.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/as_ggsurvplot_df.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract a data.frame containing the estimated survival curves from a adjustedsurv object — as_ggsurvplot_df","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/as_ggsurvplot_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract a data.frame containing the estimated survival curves from a adjustedsurv object — as_ggsurvplot_df","text":"","code":"library(adjustedCurves) library(survival)  set.seed(42)  # simulate some example data sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # treatment assignment model glm_mod <- glm(group ~ x2 + x3 + x5 + x6, data=sim_dat, family=\"binomial\")  # estimate some adjusted survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=glm_mod,                         conf_int=TRUE,                         bootstrap=FALSE)  # extract info df <- as_ggsurvplot_df(adjsurv)  # not run here to avoid dependency on survminer if (interactive()) { # plot using survminer, requires the 'survminer' package ggsurvplot_df(df) }"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aalen_johansen.html","id":null,"dir":"Reference","previous_headings":"","what":"Group-Specific Aalen-Johansen CIFs — cif_aalen_johansen","title":"Group-Specific Aalen-Johansen CIFs — cif_aalen_johansen","text":"page explains details estimating standard Aalen-Johansen cumulative incidence functions, stratified group variable (method=\"aalen_johansen\" adjustedcif function). regular arguments adjustedcif function can used. arguments specific method listed . adjustment confounders made. function included reference used confounder adjusted CIFs desired.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aalen_johansen.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group-Specific Aalen-Johansen CIFs — cif_aalen_johansen","text":"... arguments passed cuminc.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aalen_johansen.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Group-Specific Aalen-Johansen CIFs — cif_aalen_johansen","text":"Type Adjustment: adjustments made. just stratified Aalen-Johansen estimator. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies cmprsk package. function just convenient wrapper around cuminc function. See ?cuminc cited literature details.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aalen_johansen.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group-Specific Aalen-Johansen CIFs — cif_aalen_johansen","text":"Adds following additional objects output adjustedsurv function: cuminc_object: object returned cuminc function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aalen_johansen.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Group-Specific Aalen-Johansen CIFs — cif_aalen_johansen","text":"Odd O. Aalen Søren Johansen (1978). \"Empirical Transition Matrix Non-Homogeneous Markov Chains Based Censored Observations\". : Scandinavian Journal Statistics 5.3, pp. 141-150","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aalen_johansen.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Group-Specific Aalen-Johansen CIFs — cif_aalen_johansen","text":"wrapper function written Robin Denz, cuminc function (wrapper build around) written people. See ?cuminc details.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aalen_johansen.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group-Specific Aalen-Johansen CIFs — cif_aalen_johansen","text":"","code":"library(adjustedCurves) library(cmprsk)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=50, max_t=5) sim_dat$group <- as.factor(sim_dat$group)  # calculate un-adjusted aalen-johansen estimates adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"aalen_johansen\")  # plot the curves plot(adjcif)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw.html","id":null,"dir":"Reference","previous_headings":"","what":"Augmented Inverse Probability of Treatment Weighted CIFs — cif_aiptw","title":"Augmented Inverse Probability of Treatment Weighted CIFs — cif_aiptw","text":"page explains details estimating augmented inverse probability treatment weighted cumulative incidence functions competing risks data (method=\"aiptw\" adjustedcif function). regular arguments adjustedcif function can used. Additionally, outcome_model argument treatment_model argument specified adjustedcif call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augmented Inverse Probability of Treatment Weighted CIFs — cif_aiptw","text":"outcome_model [required] Must CauseSpecificCox model object created using CSC function, modeling time--event mechanism. See details examples. treatment_model [required] Must glm model object variable response variable. See details examples. censoring_model Must coxph model object, modeling censoring mechanism NULL. NULL (default) independent censoring assumed. See details examples. verbose Whether print estimation information ate function riskRegression package. Defaults FALSE. ... arguments passed ate.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Augmented Inverse Probability of Treatment Weighted CIFs — cif_aiptw","text":"Type Adjustment: Requires treatment assignment model (glm) outcome model (CSC). Also allows, rely , additional model describing censoring mechanism (coxph object). Doubly-Robust: Estimates Doubly-Robust. Categorical groups: Currently two groups variable allowed. Must still factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies riskRegression package. Instead modeling outcome mechanism treatment assignment mechanism, kind models required use method. either models correctly specified, unbiased estimates obtained. Can also used adjust dependent censoring using Cox-Regression model. obvious advantage method doubly robust property. however comes price efficiency. also possible estimates fall outside 0 1 probability bounds, particularly time near 0 maximal observed event time. also guarantee estimated CIFs monotonically increasing. information methods user referred literature listed references. function basically just wrapper around ate function riskRegression package. Additional arguments may passed function using ... syntax. however recommended use ate directly cases.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augmented Inverse Probability of Treatment Weighted CIFs — cif_aiptw","text":"Adds following additional objects output adjustedcif function: ate_object: object returned ate function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Augmented Inverse Probability of Treatment Weighted CIFs — cif_aiptw","text":"James M. Robins Andrea Rotnitzky (1992). \"Recovery Information Adjustment Dependent Censoring Using Surrogate Markers\". : AIDS Epidemiology: Methodological Issues. Ed. Nicholas P. Jewell, Klaus Dietz, Vernon T. Farewell. New York: Springer Science + Business Media, pp. 297-331 Alan E. Hubbard, Mark J. van der Laan, James M. Robins (2000). \"Nonparametric Locally Efficient Estimation Treatment Specific Survival Distribution Right Censored Data Covariates Observational Studies\". : Statistical Models Epidemiology, Environment, Clinical Trials. Ed. M. Elizabeth Halloran Donald Berry. New York: Springer Science + Business Media, pp. 135-177 Brice Maxime Hugues Ozenne, Thomas Harder Scheike, Laila Staerk (2020). \"Estimation Average Treatment Effects Right-Censored Time Event Outcome Competing Risks\". : Biometrical Journal 62, pp. 751-763","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Augmented Inverse Probability of Treatment Weighted CIFs — cif_aiptw","text":"wrapper function written Robin Denz, ate function (wrapper build around) written people. See ?ate details.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Augmented Inverse Probability of Treatment Weighted CIFs — cif_aiptw","text":"","code":"library(adjustedCurves) library(survival) library(riskRegression)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cause-specific cox-regression for the outcome cox_mod <- CSC(Hist(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                data=sim_dat)  # estimate a treatment assignment model glm_mod <- glm(group ~ x1 + x3 + x5 + x6, data=sim_dat, family=\"binomial\")  # use it to calculate adjusted survival curves adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"aiptw\",                       outcome_model=cox_mod,                       treatment_model=glm_mod,                       conf_int=FALSE) #> Warning: Rare event   # plot the curves plot(adjcif)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw_pseudo.html","id":null,"dir":"Reference","previous_headings":"","what":"Augmented Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_aiptw_pseudo","title":"Augmented Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_aiptw_pseudo","text":"page explains details estimating augmented inverse probability treatment weighted CIFs using pseudo-values competing risks setting (method=\"aiptw_pseudo\" adjustedcif function). regular arguments adjustedcif function can used. Additionally, outcome_vars argument treatment_model argument specified adjustedcif call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw_pseudo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augmented Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_aiptw_pseudo","text":"outcome_vars [required] character vector column names specifying variables used modeling outcome mechanism using geese. See details examples. treatment_model [required] Must glm multinom model object variable response variable. See details examples. type_time character string specifying time modeled. Possible values \"factor\" (modeling point time separate variable, default), \"bs\" (modeling time using B-Splines) \"ns\" (modeling time using natural splines). spline_df number degrees freedom used natural-spline B-spline function. Defaults 5. Ignored type_time=\"factor\".","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw_pseudo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Augmented Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_aiptw_pseudo","text":"Type Adjustment: Requires treatment assignment model (glm multinom) character vector variable names used model outcome mechanism (internally uses geese). contrast \"aiptw\" method function allow dependent censoring. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies geepack prodlim packages. Instead modeling outcome mechanism treatment assignment mechanism, kind models required use method. either models correctly specified, unbiased estimates obtained. contrast \"aiptw\" method, \"aiptw_pseudo\" method uses generalized estimation equation (geese) approach model outcome mechanism. model fit way described \"direct_pseudo\" method. Direct Standardization based estimates transformed using previously estimated propensity score. results doubly-robust property method. information particular method can found original article Wang (2018). original article deals survival probabilities without competing risks, difference CIF estimation competing risks calculation pseudo-values. information Pseudo-Values available Andersen et al. (2017) Andersen Perme (2010). estimating geese model ev_time variable used factor default. results one coefficient estimated unique point time, can slow computationally lot unique points time /dataset many rows. cases recommended use type_time=\"bs\" type_time=\"ns\", results ev_time modeled using B-Splines Natural Splines. Simulation studies indicate little difference estimates appropriately large number spline_df used.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw_pseudo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augmented Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_aiptw_pseudo","text":"Adds following additional objects output adjustedcif function: pseudo_values: matrix estimated pseudo-values. geese_model: geese model used make predictions.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw_pseudo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Augmented Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_aiptw_pseudo","text":"Jixian Wang (2018). \"Simple, Doubly Robust, Efficient Estimator Survival Functions Using Pseudo Observations\". : Pharmaceutical Statistics 17.38-48 James M. Robins Andrea Rotnitzky (1992). \"Recovery Information Adjustment Dependent Censoring Using Surrogate Markers\". : AIDS Epidemiology: Methodological Issues. Ed. Nicholas P. Jewell, Klaus Dietz, Vernon T. Farewell. New York: Springer Science + Business Media, pp. 297-331 Per Kragh Andersen, Elisavet Syriopoulou, Erik T. Parner (2017). \"Causal Inference Survival Analysis using Pseudo-Observations\". : Statistics Medicine 36, pp. 2669-2681 Per Kragh Andersen Maja Pohar Perme (2010). \"Pseudo-Observations Survival Analysis\". : Statistical Methods Medical Research 19, pp. 71-99 Aris Perperoglou, Willi Sauerbrei, Michal Abrahamowicz, Matthias Schmid (2019). \"Review Spline Function Procedures R\". : BMC Medical Research Methodology 19.46, pp. 1-16","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw_pseudo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Augmented Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_aiptw_pseudo","text":"Jixian Wang supplied R source code used original article, used Robin Denz create generalized version method additional functionality improved performance.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_aiptw_pseudo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Augmented Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_aiptw_pseudo","text":"","code":"library(adjustedCurves)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=30, max_t=5) sim_dat$group <- as.factor(sim_dat$group)  # estimate a treatment assignment model glm_mod <- glm(group ~ x1 + x3 + x5 + x6, data=sim_dat, family=\"binomial\")  # use it + pseudo values + geese model to calculate adjusted CIFs adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"aiptw_pseudo\",                       outcome_vars=c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\"),                       treatment_model=glm_mod,                       conf_int=FALSE,                       force_bounds=TRUE,                       iso_reg=TRUE) #> Loading required namespace: geepack  # plot the curves plot(adjcif)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct.html","id":null,"dir":"Reference","previous_headings":"","what":"Direct Adjusted Cumulative Incidence Functions — cif_direct","title":"Direct Adjusted Cumulative Incidence Functions — cif_direct","text":"page explains details estimating confounder-adjusted CIFs using previously fit model describe outcome mechanism competing risks setting (method=\"direct\" adjustedcif function). regular arguments adjustedcif function can used. Additionally, outcome_model argument specified adjustedcif call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Direct Adjusted Cumulative Incidence Functions — cif_direct","text":"outcome_model [required] Must previously fit model object including variable independent variable. Apart classic CauseSpecificCox model function also supports variety models, Fine & Gray model (FGR). See models_cif_direct list supported model objects details. verbose Whether print estimation information ate function riskRegression package. Defaults FALSE. Ignored outcome_model CauseSpecificCox model. predict_fun function used calculate predicted cause-specific cumulative incidences given covariates points time. argument needs specified kind model supplied outcome_model directly supported. See models_cif_direct information. Defaults NULL. ... arguments passed ate CauseSpecificCox model supplied outcome_model argument. Otherwise arguments passed respective predict function. See models_cif_direct details.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Direct Adjusted Cumulative Incidence Functions — cif_direct","text":"Type Adjustment: Requires model describing outcome mechanism. Cause-Specific-Cox models (CSC) Fine & Gray models (FGR) supported, well models. See models_cif_direct full list. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Asymptotic variance calculations available outcome_model CauseSpecificCox model. ate function used calculation case. Bootstrap confidence intervals can however calculated supported models. See ?adjustedcif information bootstrapping. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies riskRegression package. Depending outcome_model packages might needed. See models_cif_direct details. method works executing following steps: (1) First model fitted describes outcome mechanism (time--event). Next (2) multiple copies original dataset created, one possible level variable interest. (3) variable set one level observations dataset. (4) model used predict CIF points time T observation dataset copies. (5) estimated probabilities averaged dataset point time, resulting adjusted CIFs levels group variable specified points time. literature method sometimes called \"Direct Standardization\", \"Corrected Group-Prognosis\", \"G-Computation\" \"G-Formula\". model step (1) \"correct\"\" method produce unbiased estimates counterfactual cumulative incidences. model can called \"correct\" model context can used produce unbiased estimates true (unknown) individual CIFs given covariates. used properly one efficient methods. Theoretically type model used. popular ones CSC models FGR models, variety others models also supported. information can found literature listed references.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Direct Adjusted Cumulative Incidence Functions — cif_direct","text":"Adds following additional objects output adjustedcif function: ate_object: object returned ate function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Direct Adjusted Cumulative Incidence Functions — cif_direct","text":"Xu Zhang Mei-Jie Zhang (2011). \"SAS Macros Estimation Direct Adjusted Cumulative Incidence Curves Proportional Subdistribution Hazards Models\". : Computer Methods Programs Biomedicine 101.1, pp. 87-93 Brice Maxime Hugues Ozenne, Thomas Harder Scheike, Laila Staerk (2020). \"Estimation Average Treatment Effects Right-Censored Time Event Outcome Competing Risks\". : Biometrical Journal 62, pp. 751-763","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Direct Adjusted Cumulative Incidence Functions — cif_direct","text":"function written Robin Denz. using CauseSpecificCox models however, function just wrapper around ate function, written people. See ?ate information.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Direct Adjusted Cumulative Incidence Functions — cif_direct","text":"","code":"library(adjustedCurves) library(survival) library(riskRegression) library(prodlim)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cause-specific cox-regression for the outcome cox_mod <- CSC(Hist(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                  data=sim_dat)  # use it to calculate adjusted CIFs adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"direct\",                       outcome_model=cox_mod,                       conf_int=FALSE) #> Warning: Rare event   # plot the curves plot(adjcif)   # estimate a Fine & Gray model for the outcome instead fgr_mod <- FGR(Hist(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                data=sim_dat, cause=1)  # use it to calculate adjusted CIFs adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"direct\",                       outcome_model=fgr_mod,                       conf_int=FALSE) #> [1] \"x1\"     \"x2\"     \"x3\"     \"x4\"     \"x5\"     \"x6\"     \"group1\" #> [1] \"x1\"     \"x2\"     \"x3\"     \"x4\"     \"x5\"     \"x6\"     \"group1\"  # plot the curves plot(adjcif)   # not run because it would be too slow # \\donttest{ ## using multiple imputation library(mice)  # introduce random missingness in x1 as example # NOTE: This is only done as an example, in reality you would #       already have missing data, not introduce it yourself. sim_dat$x1 <- ifelse(runif(n=50) < 0.5, sim_dat$x1, NA)  # perform multiple imputation mids <- mice::mice(data=sim_dat, method=\"pmm\", m=5, printFlag=FALSE)  # fit model for each imputed dataset, using the CSC_MI helper function mira <- CSC_MI(mids, Hist(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group)  # calculate adjusted CIFs on imputed data adj <- adjustedcif(data=mids,                    variable=\"group\",                    ev_time=\"time\",                    event=\"event\",                    method=\"direct\",                    cause=1,                    outcome_model=mira) #> Warning: Rare event  #> Warning: Rare event  #> Warning: Rare event  #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  plot(adj)  # }"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct_pseudo.html","id":null,"dir":"Reference","previous_headings":"","what":"Direct Adjusted CIFs using Pseudo-Values — cif_direct_pseudo","title":"Direct Adjusted CIFs using Pseudo-Values — cif_direct_pseudo","text":"page explains details estimating direct adjusted cumulative incidence functions using pseudo-values competing risks setting (method=\"direct_pseudo\" adjustedcif function). regular arguments adjustedcif function can used. Additionally, outcome_vars argument specified adjustedcif call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct_pseudo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Direct Adjusted CIFs using Pseudo-Values — cif_direct_pseudo","text":"outcome_vars [required] character vector column names specifying variables used modeling outcome mechanism. See details examples. type_time character string specifying time modeled. Possible values \"factor\" (modeling point time separate variable, default), \"bs\" (modeling time using B-Splines) \"ns\" (modeling time using natural splines). spline_df number degrees freedom used natural-spline B-spline function. Defaults 5. Ignored type_time=\"factor\".","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct_pseudo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Direct Adjusted CIFs using Pseudo-Values — cif_direct_pseudo","text":"Type Adjustment: Requires character vector variable names used model outcome mechanism (internally uses geese). Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Bootstrapping can still used estimate confidence intervals (see ?adjustedcif). Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies geepack prodlim packages. method works executing following steps: (1) First Pseudo-Values cause-specific cumulative incidence function estimated observation dataset points time T. Afterwards (2) new dataset created every individual observation multiple rows, one point time interest. (3) dataset used fit generalized estimating equations (geese) model, using Pseudo-Values independent variable. Next (4) multiple copies new dataset created, one possible level variable interest. (5) variable set one level observations dataset. (5) geese model used predict CIF points time T observation dataset copies. (6) estimated probabilities averaged dataset point time, resulting adjusted CIFs levels group variable specified points time. essentially procedure described \"direct\". difference instead relying CSC model, method uses Pseudo-Values geese model. estimating geese model ev_time variable used factor default. results one coefficient estimated unique point time, can slow computationally lot unique points time /dataset many rows. cases recommended use type_time=\"bs\" type_time=\"ns\", results ev_time modeled using B-Splines Natural Splines. Simulation studies indicate little difference estimates appropriately large number spline_df used.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct_pseudo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Direct Adjusted CIFs using Pseudo-Values — cif_direct_pseudo","text":"Adds following additional objects output adjustedcif function: pseudo_values: matrix estimated pseudo-values. geese_model: geese model used make predictions.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct_pseudo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Direct Adjusted CIFs using Pseudo-Values — cif_direct_pseudo","text":"Per Kragh Andersen, Elisavet Syriopoulou, Erik T. Parner (2017). \"Causal Inference Survival Analysis using Pseudo-Observations\". : Statistics Medicine 36, pp. 2669-2681 Per Kragh Andersen Maja Pohar Perme (2010). \"Pseudo-Observations Survival Analysis\". : Statistical Methods Medical Research 19, pp. 71-99 Aris Perperoglou, Willi Sauerbrei, Michal Abrahamowicz, Matthias Schmid (2019). \"Review Spline Function Procedures R\". : BMC Medical Research Methodology 19.46, pp. 1-16","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct_pseudo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Direct Adjusted CIFs using Pseudo-Values — cif_direct_pseudo","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_direct_pseudo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Direct Adjusted CIFs using Pseudo-Values — cif_direct_pseudo","text":"","code":"library(adjustedCurves)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=30, max_t=1.3) sim_dat$group <- as.factor(sim_dat$group)  # calculate adjusted CIFs, with time as factor adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"direct_pseudo\",                       outcome_vars=c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\"),                       type_time=\"factor\",                       force_bounds=TRUE,                       iso_reg=TRUE) plot(adjcif)   # with time modelled as B-Spline using 5 degrees of freedom adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"direct_pseudo\",                       outcome_vars=c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\"),                       type_time=\"bs\",                       spline_df=5,                       force_bounds=TRUE,                       iso_reg=TRUE)  # plot the curves plot(adjcif)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Probability of Treatment Weighted CIFs — cif_iptw","title":"Inverse Probability of Treatment Weighted CIFs — cif_iptw","text":"page explains details estimating inverse probability treatment weighted cumulative incidence functions competing risks setting (method=\"iptw\" adjustedcif function). regular arguments adjustedcif function can used. Additionally, treatment_model argument specified adjustedcif call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Probability of Treatment Weighted CIFs — cif_iptw","text":"treatment_model [required] Must glm multinom model object variable response variable. censoring_model Either NULL (default) make adjustments dependent censoring, coxph object. See ?ate details. verbose Whether print estimation information ate function riskRegression package. Defaults FALSE. ... arguments passed ate.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inverse Probability of Treatment Weighted CIFs — cif_iptw","text":"Type Adjustment: Requires model describing treatment assignment mechanism. must either glm multinom object. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies riskRegression package method works modeling treatment assignment mechanism. Adjusted CIFs calculated first estimating appropriate case-weights observation data. weights used weighted version Aalen-Johansen estimator. weights correctly estimated resulting estimates unbiased. detailed description can found Neumann et al. (2016) Choi et al. (2019). utilizing another set weights, function can also correct estimates covariate-dependent censoring (Ozenne et al. 2020). Asymptotic variance calculations based efficient influence curve. Internally, function simply calls ate function appropriate arguments. three-dot syntax can used pass arguments function. however recommended use ate function directly specific settings required.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Probability of Treatment Weighted CIFs — cif_iptw","text":"Adds following additional objects output adjustedcif function: ate_object: object returned ate function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Inverse Probability of Treatment Weighted CIFs — cif_iptw","text":"Anke Neumann Cécile Billionnet (2016). \"Covariate Adjustment Cumulative Incidence Functions Competing Risks Data Using Inverse Probability Treatment Weighting\". : Computer Methods Programs Biomedicine 129, pp. 63-70 Sangbum Choi, Chaewon Kim, Hua Zhong, Eun-Seok Ryu, Sung Won Han (2019). \"Adjusted-Crude-Incidence Analysis Multiple Treatments Unbalanced Samples Competing Risks\". : Statistics Inference 12, pp. 423-437 Brice Maxime Hugues Ozenne, Thomas Harder Scheike, Laila Stærk (2020). \"Estimation Average Treatment Effects Right-Censored Time Event Outcome Competing Risks\". : Biometrical Journal 62, pp. 751-763","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Inverse Probability of Treatment Weighted CIFs — cif_iptw","text":"wrapper function written Robin Denz, ate function written people. See ?ate information.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse Probability of Treatment Weighted CIFs — cif_iptw","text":"","code":"library(adjustedCurves)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=50, max_t=5) sim_dat$group <- as.factor(sim_dat$group)  # estimate a treatment assignment model glm_mod <- glm(group ~ x1 + x3 + x5 + x6, data=sim_dat, family=\"binomial\")  # use it to calculate adjusted CIFs adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"iptw\",                       treatment_model=glm_mod) #> Warning: Rare event  plot(adjcif)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw_pseudo.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_iptw_pseudo","title":"Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_iptw_pseudo","text":"page explains details estimating inverse probability treatment weighted cumulative incidence functions using Pseudo-Values competing risks setting (method=\"iptw_pseudo\" adjustedcif function). regular arguments adjustedcif function can used. Additionally, treatment_model argument specified adjustedcif call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw_pseudo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_iptw_pseudo","text":"treatment_model [required] Must either model object variable response variable, vector weights formula can passed WeightIt. weight_method Method used WeightIt function call. Ignored treatment_model formula object. Defaults \"ps\". stabilize Whether stabilize weights . set FALSE default. Stabilizing weights ensures sum weights equal original sample size. effect point estimates, asymptotic variance calculations confidence intervals. trim Can either FALSE (default) numeric value trim weights. FALSE, weights used calculated supplied. numeric value supplied, weights bigger trim set trim analysis carried . Useful weights extremely large. se_method One \"miller\", \"galloway\", \"cochrane\" \"Hmisc\". Specifies kind standard error calculate. Defaults \"cochrane\". See details. ... arguments passed weightit.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw_pseudo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_iptw_pseudo","text":"Type Adjustment: Requires model describing treatment assignment mechanism. must either glm multinom object. Alternatively, weights can supplied directly estimated using WeightIt Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies prodlim package. WeightIt package also required treatment_model formula object. method works modeling treatment assignment mechanism. Adjusted CIFs calculated first estimating appropriate case-weights observation data. can done using inverse probability treatment weights using propensity score (usually estimated using logistic regression model) method (see weightit). Pseudo-Values cause-specific CIF calculated every observation data points time \\(T\\). Since Pseudo-Values bypass problem censoring, simple weighted average Pseudo-Values can taken every \\(T\\). See Andersen et al. (2017) details method Andersen Perme (2010) information Pseudo-Values general. standard error estimator can approximated calculation weighted version standard error estimator. Interestingly, exact method exists weighted case. Four approximations implemented can chosen using se_method argument. equations \"miller\", \"galloway\" \"cochrane\" described compared Gatz Smith (1995). \"Hmisc\" standard equation weight term added, specified Hmisc package, used stabilized weights (stabilize=TRUE). generally recommended use bootstrap estimates instead.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw_pseudo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_iptw_pseudo","text":"Adds following additional objects output adjustedcif function: pseudo_values: matrix estimated pseudo-values. weights: final weights used analysis.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw_pseudo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_iptw_pseudo","text":"Per Kragh Andersen, Elisavet Syriopoulou, Erik T. Parner (2017). \"Causal Inference Survival Analysis using Pseudo-Observations\". : Statistics Medicine 36, pp. 2669-2681 Per Kragh Andersen Maja Pohar Perme (2010). \"Pseudo-Observations Survival Analysis\". : Statistical Methods Medical Research 19, pp. 71-99 Donald F. Gatz Luther Smith (1995). \"Standard Error Weighted Mean Concentration - : Bootstrapping Vs Methods\". : Atmospheric Environment 29.11, pp. 1185-1193 William G. Cochran (1977). Sampling Techniques. Vol. 3. New York: Wiley J. N. Galloway, G. E. Likens, M. E. Hawley (1984). \"Acid Precipitation: Natural Versus Anthropogenic Components\". : Science 226, pp. 829-831 J. M. Miller (1977). Statistical Evaluation U.S. Precipitation Chemistry Network. Precipitation Scavenging (edited Semonin R. G. Beadle R. W.) pp. 639-659. Available CONF 74100 National Technical Information Service, U.S. Dept. Commerce, Springfiel, VA.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw_pseudo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_iptw_pseudo","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_iptw_pseudo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse Probability of Treatment Weighted CIFs using Pseudo-Values — cif_iptw_pseudo","text":"","code":"library(adjustedCurves)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=50, max_t=5) sim_dat$group <- as.factor(sim_dat$group)  # estimate a treatment assignment model glm_mod <- glm(group ~ x1 + x3 + x5 + x6, data=sim_dat, family=\"binomial\")  # use it to calculate adjusted CIFs adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"iptw_pseudo\",                       treatment_model=glm_mod) plot(adjcif, force_bounds=TRUE, iso_reg=TRUE)   # Alternatively, use custom weights # In this example we use weights calculated using the propensity score, # which is equal to using the glm model directly in the function ps_score <- glm_mod$fitted.values weights <- ifelse(sim_dat$group==1, 1/ps_score, 1/(1-ps_score))  adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"iptw_pseudo\",                       treatment_model=weights) plot(adjcif, force_bounds=TRUE, iso_reg=TRUE)   # And a third alternative: use the WeightIt package # here an example with equal results to the ones above: adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"iptw_pseudo\",                       treatment_model=group ~ x1 + x3 + x5 + x6,                       weight_method=\"ps\") plot(adjcif, force_bounds=TRUE, iso_reg=TRUE)   # here an example using Entropy Balancing Weighting: adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"iptw_pseudo\",                       treatment_model=group ~ x1 + x3 + x5 + x6,                       weight_method=\"ebal\") plot(adjcif, force_bounds=TRUE, iso_reg=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_matching.html","id":null,"dir":"Reference","previous_headings":"","what":"Using Propensity-Score Matching to Calculate Adjusted CIFs — cif_matching","title":"Using Propensity-Score Matching to Calculate Adjusted CIFs — cif_matching","text":"page explains details estimating adjusted cumulative incidence functions using propensity-score matching competing risks setting (method=\"matching\" adjustedcif function). regular arguments adjustedcif function can used. Additionally, treatment_model argument specified adjustedcif call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_matching.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Using Propensity-Score Matching to Calculate Adjusted CIFs — cif_matching","text":"treatment_model [required] Must either model object variable response variable vector previously estimated propensity scores. gtol Tolerance estimated treatment assignment probabilities truncated. Every propensity score bigger 1 - gtol set 1 - gtol every propensity score smaller gtol set gtol. Useful extreme propensity scores close 0 1. Defaults 0.001, ... arguments passed Match function Matching Package.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_matching.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Using Propensity-Score Matching to Calculate Adjusted CIFs — cif_matching","text":"Type Adjustment: Requires model describing treatment assignment mechanism. must either glm object vector propensity scores. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: two groups variable allowed. Must factor variable exactly two levels. Approximate Variance: Calculations approximate variance confidence intervals currently available. Bootstrapping can still used estimate confidence intervals (see ?adjustedcif). Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies Matching cmprsk packages. Using estimated propensity score, individual observations dataset matched creating new dataset covariate distributions balanced respect two groups defined variable. simple Aalen-Johansen estimator used calculate confounder-adjusted CIFs. corresponds method described Austin & Fine (2019). Details algorithm used matching can found documentation Matching package. Simulation results showed specific implementation method least efficient method contained R-Package. produce unbiased estimates, variation estimates high. strongly suggest using one methods implemented .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_matching.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Using Propensity-Score Matching to Calculate Adjusted CIFs — cif_matching","text":"Adds following additional objects output adjustedcif function: match_object: object creates using Match function. cuminc_object: cuminc object fit matched data.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_matching.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Using Propensity-Score Matching to Calculate Adjusted CIFs — cif_matching","text":"Peter C. Austin Jason P. Fine (2019). \"Propensity-Score Matching Competing Risks Survival Analysis\". : Statistics Medicine 38, pp. 751-777","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_matching.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Using Propensity-Score Matching to Calculate Adjusted CIFs — cif_matching","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_matching.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Using Propensity-Score Matching to Calculate Adjusted CIFs — cif_matching","text":"","code":"library(adjustedCurves) library(survival) library(Matching) #> Loading required package: MASS #> ##  #> ##  Matching (Version 4.10-14, Build Date: 2023-09-13) #> ##  See https://www.jsekhon.com for additional documentation. #> ##  Please cite software as: #> ##   Jasjeet S. Sekhon. 2011. ``Multivariate and Propensity Score Matching #> ##   Software with Automated Balance Optimization: The Matching package for R.'' #> ##   Journal of Statistical Software, 42(7): 1-52.  #> ##  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=50, max_t=5) sim_dat$group <- as.factor(sim_dat$group)  # estimate treatment assignment model glm_mod <- glm(group ~ x1 + x2 + x4 + x6, data=sim_dat, family=\"binomial\")  # calculate adjusted CIFs adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"matching\",                       treatment_model=glm_mod) plot(adjcif)   # Alternatively, supply the propensity score directly # Here we use the logistic regression to calculate it, so we get # exactly the same result. The propensity score can be calculated in # any other way in practice, allowing flexibility ps_score <- glm_mod$fitted.values  adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       cause=1,                       method=\"matching\",                       treatment_model=ps_score)  # plot the curves plot(adjcif)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_tmle.html","id":null,"dir":"Reference","previous_headings":"","what":"Targeted Maximum Likelihood Estimation for Continuous Time Competing Events Data — cif_tmle","title":"Targeted Maximum Likelihood Estimation for Continuous Time Competing Events Data — cif_tmle","text":"page explains details estimating causal cause-specific cumulative incidence functions competing risks setting targeted maximum likelihood estimation (method=\"tmle\" adjustedcif function). regular arguments adjustedcif function can used. Additionally, outcome_model argument treatment_model argument specified adjustedcif call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_tmle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Targeted Maximum Likelihood Estimation for Continuous Time Competing Events Data — cif_tmle","text":"outcome_model [required] list containing least one Cox model formula desired cause. Cox model formula, time variable always called time status variable always called status. example, use just one Cox model cause = 1 including variables dataset independent variables user can use list(Surv(time, status==1) ~ .). cause = 2 interest list(Surv(time, status==2) ~ .) instead. Cox models defined list fitted data ensemble models used provide initial predictions conditional hazard. See details documentation concrete package information. treatment_model [required] character vector specifying SuperLearner libraries used obtain estimate propensity score. example, c(\"SL.glm\", \"SL.glmnet\") used. See ?SuperLearner details. censoring_model Either NULL (default) make adjustments dependent censoring, list Cox models described outcome_model argument. difference outcome_model argument status==0 used Cox formulas. See ?formatArguments concrete package details. cv_args list arguments specifying exactly cross-validation performed. Internally passed CVArg argument formatArguments function concrete package. max_update_iter single positive integer specifying maximum iterations performed obtain estimates. Defaults 500. Internally passed MaxUpdateIter argument formatArguments function concrete package. one_step_eps single positive number specifying step size tmle updates. Defaults 0.1. Internally passed OneStepEps argument formatArguments function concrete package. min_nuisance single number 0 1 used truncating g-related denominator clever covariate. Defaults 5/sqrt(nrow(data))/log(nrow(data)). Internally passed MinNuisance argument formatArguments function concrete package. verbose Whether print estimation information doConcrete function concrete package. Defaults FALSE. return_models Whether add estimated models outcome, treatment, censoring mechanism output object. Defaults TRUE.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_tmle.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Targeted Maximum Likelihood Estimation for Continuous Time Competing Events Data — cif_tmle","text":"Type Adjustment: Requires model describing treatment assignment mechanism outcome mechanism, also allows model censoring mechanism. See details concrete package. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: function currently allows two levels variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies concrete package, data.table package respective dependencies. : function implements Targeted Maximum Likelihood Estimation (TMLE) continuously distributed competing-events data described Rytgaard et al. (2023) Rytgaard van der Laan (2022). TMLE method similar AIPTW methods included package. also relies outcome model treatment model (additional optional censoring model) obtain counterfactual failure probability estimates. contrast AIPTW methods, however, estimator uses iterative approach obtain estimates update targets entire cumulative incidence function. consequence, resulting estimates guaranteed lie 0/1 probability bounds also guaranteed non-decreasing time. Simulation studies theoretical results indicate good performance method terms bias standard errors. See cited literature detailed rigorous explanations method. Instead relying single model obtain propensity score initial conditional hazards estimates, estimator relies SuperLearner framework conjunction cross-validation . cross-validation performed may controlled cv_args argument. resulting models can inspected output object return_models set TRUE. Implementation: Internally, function simply calls multiple functions concrete package correct order appropriate arguments. wrapper function limited sense allow dynamic interventions time-varying variables, supported concrete package. recommended use concrete package directly user wants use features specific settings required. Speed Considerations: method computationally expensive. medium large datasets considering many different points time, usually take long time execute. speed important, recommend using methods. Alternatively, user may adjust times arguments target fewer points time.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_tmle.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Targeted Maximum Likelihood Estimation for Continuous Time Competing Events Data — cif_tmle","text":"previous version package (<= 0.9.1) included function name, removed version 0.10.0. old version implemented TMLE estimator applicable discrete-time survival data based survtmle package, removed CRAN. new version implements different estimator. Code using method version <= 0.9.1 work versions 0.10.2 higher.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_tmle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Targeted Maximum Likelihood Estimation for Continuous Time Competing Events Data — cif_tmle","text":"Adds following additional objects output adjustedcif function: concrete_object: object returned doConcrete function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_tmle.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Targeted Maximum Likelihood Estimation for Continuous Time Competing Events Data — cif_tmle","text":"Helene C. W. Rytgaard Mark J. van der Laan (2023). \"Targeted Maximum Likelihood Estimation Causal Inference Survival Competing Risks Analysis\". : Lifetime Data Analysis Helene C. W. Rytgaard Mark J. van der Laan (2023). \"One-Step Targeted Maximum Likelihood Estimation Targeting Cause-Specific Absolute Risks Survival Curves\". : Biometrika Helene C. W. Rytgaard, Frank Eriksson Mark J. van der Laan (2023). \"Estimation Time-Specific Intervention Effects Continuously Distributed Time--Event Outcomes Targeted Maximum Likelihood Estimation\". : Biometrics David Chen, Helene C. W. Rytgaard Edwin Fong Jens M. Tarp Maya L. Petersen Mark J. van der Laan Thomas . Gerds (2023). \"concrete: R Package Continuous-Time, Competing Risks Targeted Maximum Likelihood Estimation\". Available <https://github.com/imbroglio-dc/concrete> CRAN","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_tmle.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Targeted Maximum Likelihood Estimation for Continuous Time Competing Events Data — cif_tmle","text":"wrapper function written Robin Denz, real estimation functions contained concrete package, written David Chen. See ?doConcrete information.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/cif_tmle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Targeted Maximum Likelihood Estimation for Continuous Time Competing Events Data — cif_tmle","text":"","code":"library(adjustedCurves)  data <- sim_confounded_crisk(n=100) data$group <- factor(data$group)  # for a single point in time using only one model for both # the treatment mechanism and outcome mechanism out <- adjustedcif(data=data,                    variable=\"group\",                    ev_time=\"time\",                    event=\"event\",                    cause=1,                    treatment_model=c(\"SL.glm\"),                    outcome_model=list(Surv(time, status==1) ~ .),                    times=c(0.5),                    conf_int=TRUE,                    method=\"tmle\") #> Loading required namespace: concrete  ## using multiple models for both the treatment assignment and ## outcome mechanism out <- adjustedcif(data=data,                    variable=\"group\",                    ev_time=\"time\",                    event=\"event\",                    cause=1,                    treatment_model=c(\"SL.glm\", \"SL.mean\"),                    outcome_model=list(Surv(time, status==1) ~ x1 + x3,                                       Surv(time, status==1) ~ x2 + x4 + x5),                    times=c(0.5),                    conf_int=TRUE,                    method=\"tmle\")  ## with corrections for covariate dependent censoring out <- adjustedcif(data=data,                    variable=\"group\",                    ev_time=\"time\",                    event=\"event\",                    cause=1,                    treatment_model=c(\"SL.glm\", \"SL.mean\"),                    outcome_model=list(Surv(time, status==1) ~ x1 + x3,                                       Surv(time, status==1) ~ x2 + x4 + x5),                    censoring_model=list(Surv(time, status==0) ~ x6 + x1),                    times=c(0.5),                    conf_int=TRUE,                    method=\"tmle\")"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/models_cif_direct.html","id":null,"dir":"Reference","previous_headings":"","what":"List of supported models in cif_direct — models_cif_direct","title":"List of supported models in cif_direct — models_cif_direct","text":"Supported models outcome_model argument using method=\"direct\" adjustedcif function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/models_cif_direct.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List of supported models in cif_direct — models_cif_direct","text":"following models directly supported outcome_model cif_direct function. first letter parentheses object name group indicator. list information group. CSC [, Required Packages: riskRegression] FGR [B, Required Packages: riskRegression] riskRegression [B, Required Packages: riskRegression] prodlim [B, Required Packages: prodlim, riskRegression] rfsrc [B, Required Packages: randomForestSRC, riskRegression] ARR [B, Required Packages: riskRegression] fit_hal [B, Required Packages: hal9001, riskRegression] fastCrr [C, Required Packages: fastcmprsk] comp.risk [C, Required Packages: timereg] model fitting S3 prediction method valid predict_fun can used well. See . Group : direct adjusted cumulative incidences estimated directly using ate function. Additional arguments supplied using ... syntax passed ate function. Group B: predictRisk function used obtain predicted cumulative incidences, used G-Computation step. Additional arguments supplied using ... syntax passed predictRisk function.Group C: Custom code used estimation. Additional arguments supplied using ... syntax currently supported. sometimes possible use models even listed . two ways make work. first one use models S3 predict method. works predict function contains arguments object, newdata, times cause returns matrix predicted cause-specific cumulative incidences. matrix size nrow(data) * length(times), row corresponds row original dataset column one point time. matrix contain cause-specific cumulative incidences predicted model given covariates. predict method exists option left write function produces output described supply function predict_fun argument. think important models missing list, please file issue official github page specific feature request (URL can found DESCRIPTION file) contact package maintainer directly using given e-mail address.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/models_cif_direct.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"List of supported models in cif_direct — models_cif_direct","text":"using outcome models directly supported (either default predict method custom predict_fun) might necessary set clean_data argument adjustedcif function FALSE.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/models_surv_direct.html","id":null,"dir":"Reference","previous_headings":"","what":"List of supported models in surv_direct — models_surv_direct","title":"List of supported models in surv_direct — models_surv_direct","text":"Supported models outcome_model argument using method=\"direct\" adjustedsurv function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/models_surv_direct.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List of supported models in surv_direct — models_surv_direct","text":"following models directly supported outcome_model surv_direct function. first letter parentheses object name group indicator. list information group. coxph [, Required Packages: survival, riskRegression] cph [, Required Packages: rms, survival, riskRegression] aalen [B, Required Packages: timereg, pec] cox.aalen [B, Required Packages: timereg, pec] selectCox [B, Required Packages: riskRegression, pec] pecCforest [B, Required Packages: pec] pecRpart [B, Required Packages: pec, Bootstrapping allowed.] riskRegression [C, Required Packages: riskRegression] prodlim [C, Required Packages: prodlim, riskRegression] psm [C, Required Packages: rms, riskRegression] flexsurvreg [C, Required Packages: flexsurv, riskRegression] flexsurvspline [C, Required Packages: flexsurv, riskRegression] ranger [C, Required Packages: ranger, riskRegression] rfsrc [C, Required Packages: randomForestSRC, riskRegression] ARR [C, Required Packages: riskRegression] penalizedS3 [C, Required Packages: penalized, riskRegression] gbm [C, Required Packages: gbm, riskRegression] fit_hal [C, Required Packages: hal9001, riskRegression] fitSmoothHazard [C, Required Packages: casebase, riskRegression] glm [D, Required Packages: stats, pec] ols [D, Required Packages: rms, pec] randomForest [D, Required Packages: randomForest, pec] mexhaz [E, Required Packages: mexhaz] model fitting S3 prediction method valid predict_fun can used well. See . Group : direct adjusted survival probabilities estimated directly using ate function. Additional arguments supplied using ... syntax passed ate function. Note Surv() calls required fit model made inside formula, saved elsewhere. Group B: Predicted survival probabilities obtained using predictSurvProb function. G-Computation carried using . Additional arguments supplied using ... syntax passed predictSurvProb function. Group C: predictRisk function used obtain predicted cumulative incidences, transformed survival probabilities. Additional arguments supplied using ... syntax passed predictRisk function.Group D: models allowed censoring. Predicted survival probabilities obtained using predictProb function pec package. Additional arguments supplied using ... syntax passed predictProb function.Group E: Custom code used obtain predicted survival probabilities. Additional arguments used. sometimes possible use models even listed . two ways make work. first one use models S3 predict method. works predict function contains arguments object, newdata times returns matrix predicted survival probabilities. matrix size nrow(data) * length(times), row corresponds row original dataset column one point time. matrix contain survival probabilities predicted model given covariates. predict method exists option left write function produces output described supply function predict_fun argument. think important models missing list, please file issue official github page specific feature request (URL can found DESCRIPTION file) contact package maintainer directly using given e-mail address.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/models_surv_direct.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"List of supported models in surv_direct — models_surv_direct","text":"using outcome models directly supported (either default predict method custom predict_fun) might necessary set clean_data argument adjustedsurv function FALSE.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedcif.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Confounder-Adjusted Cumulative Incidence Functions — plot.adjustedcif","title":"Plot Confounder-Adjusted Cumulative Incidence Functions — plot.adjustedcif","text":"function graphically display confounder-adjusted cumulative incidence functions previously estimated using adjustedcif function. user can customize plot using variety options. Internally uses ggplot2 package, additional implemented features can added using standard ggplot2 syntax. function also includes option use isotonic regression CIFs, benefit estimated curves monotone.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedcif.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Confounder-Adjusted Cumulative Incidence Functions — plot.adjustedcif","text":"","code":"# S3 method for adjustedcif plot(x, conf_int=FALSE, max_t=Inf,      iso_reg=FALSE, force_bounds=FALSE,      use_boot=FALSE, color=TRUE,      linetype=FALSE, facet=FALSE,      line_size=1, line_alpha=1, xlab=\"Time\",      ylab=\"Adjusted Cumulative Incidence\",      title=NULL, subtitle=NULL, legend.title=\"Group\",      legend.position=\"right\",      gg_theme=ggplot2::theme_classic(),      ylim=NULL, custom_colors=NULL,      custom_linetypes=NULL,      single_color=NULL, single_linetype=NULL,      conf_int_alpha=0.4, steps=TRUE,      censoring_ind=\"none\",      censoring_ind_size=0.5,      censoring_ind_alpha=1,      censoring_ind_shape=17,      censoring_ind_width=NULL,      ...)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedcif.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Confounder-Adjusted Cumulative Incidence Functions — plot.adjustedcif","text":"x adjustedcif object created using adjustedcif function. conf_int logical variable indicating whether confidence intervals drawn. max_t number indicating latest event time plotted. iso_reg logical variable indicating whether estimates monotonized using isotonic regression. See details. force_bounds logical variable indicating whether 0 1 bounds CIFs forced plot. See details. use_boot logical variable denoting whether bootstrapped estimates used curves confidence intervals. Can used calculated. See adjustedcif. color logical variable indicating whether curves colored differently. custom_colors argument can used directly specify colors use. Alternatively single_color argument can used everything color. linetype logical variable indicating whether curves different linetypes. custom_linetypes argument can used directly specify linetypes use. Alternatively single_linetype argument can used curves linetype. facet logical variable indicating whether curves different facets. line_size number controlling thickness curves. line_alpha number controlling transparency level curves. xlab character string used X-Axis label plot. ylab character string used Y-Axis label plot. title character string used title plot. Set NULL (default) title used. subtitle character string used subtitle plot. Set NULL (default) subtitle used. legend.title character string used title legend. Set NULL legend included. legend.position character string specifying position legend. Ignored legend_title=NULL. gg_theme ggplot2 theme object used plot. ylim numeric vector length two, specifying limits Y-Axis. Set NULL use ggplot2 default values. custom_colors (named) vector specify colors CIF possibly confidence region. Set NULL use ggplot2 default values. Ignored color=FALSE. custom_linetypes (named) vector specify linetype CIF. Set NULL use ggplot2 default values. Ignored linetype=FALSE. single_color single color use every curve, irrespective group status. color specified well argument override , also generate warning. Set NULL (default) ignore argument. single_linetype single linetype use every curve, irrespective group status. linetype specified well argument override , also generate warning. Set NULL (default) ignore argument. conf_int_alpha number indicating level transparency used drawing confidence regions. steps logical variable indicating whether CIFs plotted step function using straight lines. Straight lines used simple Aalen-Joahnsen estimator. recommended use straight lines sufficiently fine grid time points used estimation step. censoring_ind kind indicator plot censored observations CIFs. Must one \"none\" (plotting indicators , default), \"lines\" (plotting small vertical lines) \"points\" (plotting points). affected linetype color well. Observations failed due competing event considered censored . censoring_ind_size numeric value specifying size censoring indicators. Ignored censoring_ind=\"none\". censoring_ind_alpha numeric value specifying alpha level censoring indicators. Ignored censoring_ind=\"none\". censoring_ind_shape numeric value specifying shape censoring indicators using censoring_ind=\"points\". Ignored otherwise. available shapes see ?geom_point. censoring_ind_width numeric value specifying width censoring indicators. Ignored unless censoring_ind=\"lines\". default (censoring_ind_width=NULL) width censoring indicators equal 5 percent plot height. ... Currently used.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedcif.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Confounder-Adjusted Cumulative Incidence Functions — plot.adjustedcif","text":"using certain methods guarantee resulting estimated CIFs monotonically increasing. unfortunate since know case. Isotonic regression can used fix problem ensuring CIFs actually monotonically increasing everywhere, also close observations possible. Westling et al. (2020) showed mathematically usually add systematic bias estimates. information method can found Robertson et al. (1988). adjustment can done using function setting iso_reg TRUE. Similarly, methods can produce estimates lie outside theoretical 0 1 bounds probability. setting force_bounds TRUE estimates manually set either 0 1 (whichever closer).","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedcif.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Confounder-Adjusted Cumulative Incidence Functions — plot.adjustedcif","text":"Returns ggplot2 object.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedcif.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Confounder-Adjusted Cumulative Incidence Functions — plot.adjustedcif","text":"Ted Westling, Mark J. van der Laan, Marco Carone (2020). \"Correcting Estimator Multivariate Monotone Function Isotonic Regression\". : Electronic Journal Statistics 14, pp. 3032-3069 Tim Robertson, F. T. Wright, R. L. Dykstra (1988). Order Restricted Statistical Inference. Hoboken: John Wiley & Sons","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedcif.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Confounder-Adjusted Cumulative Incidence Functions — plot.adjustedcif","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedcif.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Confounder-Adjusted Cumulative Incidence Functions — plot.adjustedcif","text":"","code":"library(adjustedCurves) library(riskRegression) library(prodlim) library(survival) library(ggplot2)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_crisk(n=50) sim_dat$group <- as.factor(sim_dat$group)  # calculate a Cause-Specific-Cox model cox_mod <- CSC(Hist(time, event) ~ x1 + x3 + x5 + group,                data=sim_dat)  # use it to calculate adjusted CIFs with bootstrapping (for cause = 1) adjcif <- adjustedcif(data=sim_dat,                       variable=\"group\",                       ev_time=\"time\",                       event=\"event\",                       method=\"direct\",                       outcome_model=cox_mod,                       conf_int=TRUE,                       bootstrap=TRUE,                       n_boot=15, # should be much bigger in reality                       cause=1) #> Warning: Rare event  #> Warning: Estimated risk outside the range [0,1]. #> Consider setting the argument 'product.limit' to FALSE.  #> Warning: Rare event  #> Warning: Rare event  #> Warning: Rare event  #> Warning: Loglik converged before variable  1 ; coefficient may be infinite.  #> Warning: Rare event  #> Warning: Rare event   # plot the curves with default values plot(adjcif)   # plot after applying isotonic regression plot(adjcif, iso_reg=TRUE)   # plot with confidence intervals estimated using asymptotic variances plot(adjcif, conf_int=TRUE) #> Loading required namespace: pammtools   # plot with confidence intervals estimated using bootstrapping plot(adjcif, conf_int=TRUE, use_boot=TRUE)   # plot with different linetypes only plot(adjcif, linetype=TRUE, color=FALSE, facet=FALSE)   # plot with different facets only plot(adjcif, linetype=FALSE, color=FALSE, facet=TRUE)   # plot with different linetypes and different colors plot(adjcif, linetype=TRUE, color=TRUE, facet=FALSE)   # plot with some custom characteristics plot(adjcif, legend.position=\"bottom\", linetype=TRUE,      custom_colors=c(\"green\", \"blue\"), legend.title=\"Custom\",      title=\"Custom Plot\", conf_int=TRUE, linesize=0.5)   # adding further ggplot2 elements plot(adjcif) + theme_bw()"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Confounder-Adjusted Survival Curves — plot.adjustedsurv","title":"Plot Confounder-Adjusted Survival Curves — plot.adjustedsurv","text":"function graphically display confounder-adjusted survival curves previously estimated using adjustedsurv function. user can customize plot using variety options. Internally uses ggplot2 package, additional implemented features can added using standard ggplot2 syntax. function also includes option use isotonic regression survival curves, benefit estimated curves monotone.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Confounder-Adjusted Survival Curves — plot.adjustedsurv","text":"","code":"# S3 method for adjustedsurv plot(x, conf_int=FALSE, max_t=Inf,      iso_reg=FALSE, force_bounds=FALSE,      use_boot=FALSE, cif=FALSE, color=TRUE,      linetype=FALSE, facet=FALSE,      line_size=1, line_alpha=1, xlab=\"Time\",      ylab=\"Adjusted Survival Probability\",      title=NULL, subtitle=NULL, legend.title=\"Group\",      legend.position=\"right\",      gg_theme=ggplot2::theme_classic(),      ylim=NULL, custom_colors=NULL,      custom_linetypes=NULL,      single_color=NULL, single_linetype=NULL,      conf_int_alpha=0.4, steps=TRUE,      median_surv_lines=FALSE,      median_surv_size=0.5,      median_surv_linetype=\"dashed\",      median_surv_color=\"black\",      median_surv_alpha=1,      median_surv_quantile=0.5,      censoring_ind=\"none\",      censoring_ind_size=0.5,      censoring_ind_alpha=1,      censoring_ind_shape=17,      censoring_ind_width=NULL,      ...)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Confounder-Adjusted Survival Curves — plot.adjustedsurv","text":"x adjustedsurv object created using adjustedsurv function. conf_int logical variable indicating whether confidence intervals drawn. max_t number indicating latest survival time plotted. iso_reg logical variable indicating whether estimates monotonized using isotonic regression. See details. force_bounds logical variable indicating whether 0 1 bounds survival probabilities forced plot. See details. use_boot logical variable denoting whether bootstrapped estimates used curves confidence intervals. Can used calculated. See adjustedsurv. cif TRUE cumulative incidence functions drawn instead survival curves. calculated taking 1 - adjusted survival probability. FALSE (default) usual survival curves shown. color logical variable indicating whether curves colored differently. custom_colors argument can used directly specify colors use. Alternatively single_color argument can used everything color. linetype logical variable indicating whether curves different linetypes. custom_linetypes argument can used directly specify linetypes use. Alternatively single_linetype argument can used curves linetype. facet logical variable indicating whether curves different facets. line_size number controlling thickness survival curves. line_alpha number controlling transparency level survival curves. xlab character string used X-Axis label plot. ylab character string used Y-Axis label plot. title character string used title plot. Set NULL title used. subtitle character string used subtitle plot. Set NULL subtitle used. legend.title character string used title legend. Set NULL legend included. legend.position character string specifying position legend. Ignored legend_title=NULL. gg_theme ggplot2 theme object used plot. ylim numeric vector length two, specifying limits Y-Axis. Set NULL use ggplot2 default values. custom_colors (named) vector specify colors adjusted survival curve possibly confidence region. Set NULL use ggplot2 default values. Ignored color=FALSE. custom_linetypes (named) vector specify linetype adjusted survival curve. Set NULL use ggplot2 default values. Ignored color=FALSE. Ignored linetype=FALSE. single_color single color use every survival curve, irrespective group status. color specified well argument override , also generate warning. Set NULL (default) ignore argument. single_linetype single linetype use every survival curve, irrespective group status. linetype specified well argument override , also generate warning. Set NULL (default) ignore argument. conf_int_alpha number indicating level transparency used drawing confidence regions. steps logical variable indicating whether survival curves plotted step function using straight lines. Straight lines used simple Kaplan-Meier estimator. recommended use straight lines sufficiently fine grid time points used estimation step. median_surv_lines Whether draw indicator lines median survival times, makes easier read curves. Survival curves undefined median survival times receive lines. median_surv_size size median survival indicator lines. Ignored median_surv_lines=FALSE. median_surv_linetype linetype median survival indicator lines. Ignored median_surv_lines=FALSE. median_surv_color color median survival indicator lines. Ignored median_surv_lines=FALSE. median_surv_alpha transparency level median survival indicator lines. Ignored median_surv_lines=FALSE. median_surv_quantile survival quantile drawn. draw median survival time, set parameter 0.5 (default). censoring_ind kind indicator plot censored observations survival curves. Must one \"none\" (plotting indicators , default), \"lines\" (plotting small vertical lines) \"points\" (plotting points). affected linetype color well. censoring_ind_size numeric value specifying size censoring indicators. Ignored censoring_ind=\"none\". censoring_ind_alpha numeric value specifying alpha level censoring indicators. Ignored censoring_ind=\"none\". censoring_ind_shape numeric value specifying shape censoring indicators using censoring_ind=\"points\". Ignored otherwise. available shapes see ?geom_point. censoring_ind_width numeric value specifying width censoring indicators. Ignored unless censoring_ind=\"lines\". default (censoring_ind_width=NULL) width censoring indicators equal 5 percent plot height. ... Currently used.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedsurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Confounder-Adjusted Survival Curves — plot.adjustedsurv","text":"using certain methods guarantee resulting estimated survival curves monotonically decreasing. unfortunate since know case. Isotonic regression can used fix problem ensuring survival curves actually monotonically decreasing everywhere, also close observations possible. Westling et al. (2020) showed mathematically add systematic bias estimates. information method can found Robertson et al. (1988). adjustment can done using function setting iso_reg TRUE. Similarly, methods can produce estimates lie outside theoretical 0 1 bounds probability. setting force_bounds TRUE estimates manually set either 0 1 (whichever closer). currently option add risk tables plot, way meaningfully adjust confounders. prefer using ggsurvplot syntax, can also use as_ggsurvplot_df function extract data.frame adjustedsurv object, can used directly call ggsurvplot_df function survminer package.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Confounder-Adjusted Survival Curves — plot.adjustedsurv","text":"Returns ggplot2 object.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedsurv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Confounder-Adjusted Survival Curves — plot.adjustedsurv","text":"Robin Denz, Renate Klaaßen-Mielke, Nina Timmesfeld (2023). \"Comparison Different Methods Adjust Survival Curves Confounders\". : Statistics Medicine 42.10, pp. 1461-1479 Ted Westling, Mark J. van der Laan, Marco Carone (2020). \"Correcting Estimator Multivariate Monotone Function Isotonic Regression\". : Electronic Journal Statistics 14, pp. 3032-3069 Tim Robertson, F. T. Wright, R. L. Dykstra (1988). Order Restricted Statistical Inference. Hoboken: John Wiley & Sons","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedsurv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Confounder-Adjusted Survival Curves — plot.adjustedsurv","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.adjustedsurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Confounder-Adjusted Survival Curves — plot.adjustedsurv","text":"","code":"library(adjustedCurves) library(survival) library(ggplot2)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cox-regression for the outcome cox_mod <- coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                  data=sim_dat, x=TRUE)   # use it to calculate adjusted survival curves with bootstrapping adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=TRUE,                         bootstrap=TRUE,                         n_boot=15) # should be much bigger in reality  # plot the curves with default values plot(adjsurv)   # plot after applying isotonic regression plot(adjsurv, iso_reg=TRUE)   # plot with confidence intervals estimated using asymptotic variances plot(adjsurv, conf_int=TRUE)   # plot with confidence intervals estimated using bootstrapping plot(adjsurv, conf_int=TRUE, use_boot=TRUE)   # plot with different linetypes only plot(adjsurv, linetype=TRUE, color=FALSE, facet=FALSE)   # plot with different facets only plot(adjsurv, linetype=FALSE, color=FALSE, facet=TRUE)   # plot with different linetypes and different colors plot(adjsurv, linetype=TRUE, color=TRUE, facet=FALSE)   # plot with median survival indicator lines plot(adjsurv, median_surv_lines=TRUE)   # plot with small lines indicating where observations were censored plot(adjsurv, censoring_ind=\"lines\")   # plot with points indicating where observations were censored plot(adjsurv, censoring_ind=\"points\", censoring_ind_size=4)   # plot with some custom characteristics plot(adjsurv, legend.position=\"bottom\", linetype=TRUE,      custom_colors=c(\"green\", \"blue\"), legend.title=\"Custom\",      title=\"Custom Plot\", conf_int=TRUE, linesize=0.5,      median_surv_lines=TRUE, censoring_ind=\"lines\")   # adding further ggplot2 elements plot(adjsurv) + theme_bw()"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.curve_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Method for curve_test Objects — plot.curve_test","title":"Plot Method for curve_test Objects — plot.curve_test","text":"Produces either spaghetti-plot bootstrapped difference curves (type=\"curves\") kernel-density plot shifted bootstrap distribution difference curve integrals (type=\"integral\").","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.curve_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Method for curve_test Objects — plot.curve_test","text":"","code":"# S3 method for curve_test plot(x, type=\"curves\", xlab=NULL,      ylab=NULL, title=NULL, ...)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.curve_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Method for curve_test Objects — plot.curve_test","text":"x object class curve_test created adjusted_curve_test function. type Either \"curves\" \"integral\", specifying plotted. xlab label X-Axis. Set NULL use default label. ylab label Y-Axis. Set NULL use default label. title title plot. Set NULL use title. ... Currently used.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.curve_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Method for curve_test Objects — plot.curve_test","text":"using type=\"curves\" black curve shows observed curve difference. using type=\"integral\" red line shows observed integral curve difference. graphics can used check assumptions test hold. bootstrap-shifted distribution integral difference approximately normally distributed. kernel-density estimate shown type=\"integral\" clearly normally distributed, estimated p-value might wrong. Similarly, curves differences vary randomly around black line using type=\"curves\", estimated p-value might wrong. also try rerun adjustedsurv adjustedcif function bigger number n_boot.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.curve_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Method for curve_test Objects — plot.curve_test","text":"Returns ggplot2 object.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.curve_test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Method for curve_test Objects — plot.curve_test","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot.curve_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Method for curve_test Objects — plot.curve_test","text":"","code":"# See ?adjusted_curve_test"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_curve_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the Difference Between or the Ratio of Two Adjusted Survival Curves or CIFs — plot_curve_diff","title":"Plot the Difference Between or the Ratio of Two Adjusted Survival Curves or CIFs — plot_curve_diff","text":"function graphically display difference ratio two confounder-adjusted survival curves previously estimated using adjustedsurv function two confounder-adjusted CIFs previously estimated using adjustedcif function. user can customize plot using variety options. Internally uses ggplot2 package, additional implemented features can added using standard ggplot2 syntax.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_curve_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the Difference Between or the Ratio of Two Adjusted Survival Curves or CIFs — plot_curve_diff","text":"","code":"plot_curve_diff(x, group_1=NULL, group_2=NULL,                 conf_int=FALSE, conf_level=0.95, type=\"steps\",                 times=NULL, max_t=Inf, use_boot=FALSE,                 size=0.7, color=\"black\", linetype=\"solid\",                 alpha=1, conf_int_alpha=0.4,                 points_ci_size=NULL, points_ci_width=NULL,                 xlab=\"Time\", ylab=NULL, title=NULL,                 subtitle=NULL, gg_theme=ggplot2::theme_classic(),                 line_at_ref=TRUE, line_at_ref_size=0.7,                 line_at_ref_color=\"grey\", line_at_ref_linetype=\"dashed\",                 line_at_ref_alpha=1,                 loess_smoother=FALSE, loess_span=0.75,                 loess_color=color, loess_size=size,                 loess_linetype=\"dashed\", loess_alpha=alpha,                 test=NULL, integral_from=0, integral_to=NULL,                 p_value=FALSE, integral=FALSE,                 interval=FALSE, text_pos_x=\"left\",                 text_pos_y=\"bottom\", text_size=3.5,                 text_family=\"serif\", text_fontface=\"italic\",                 text_color=\"black\", text_alpha=1,                 text_digits=3, text_format_p=TRUE,                 fill_area=FALSE, area_color=\"blue\", area_alpha=0.4,                 fill_only_interval=TRUE,                 ...)  plot_curve_ratio(x, group_1=NULL, group_2=NULL, conf_int=FALSE,                  conf_level=0.95, type=\"steps\", times=NULL,                  max_t=Inf, use_boot=FALSE, size=0.7, color=\"black\",                  linetype=\"solid\", alpha=1,                  conf_int_alpha=0.4, xlab=\"Time\", ylab=NULL,                  title=NULL, subtitle=NULL,                  gg_theme=ggplot2::theme_classic(),                  line_at_ref=TRUE, line_at_ref_size=0.7,                  line_at_ref_color=\"grey\",                  line_at_ref_linetype=\"dashed\",                  line_at_ref_alpha=1, ...)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_curve_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the Difference Between or the Ratio of Two Adjusted Survival Curves or CIFs — plot_curve_diff","text":"x adjustedsurv object created using adjustedsurv function adjustedcif object created using adjustedcif function. group_1 single character string specifying one levels variable used original adjustedsurv adjustedcif function call. group subtracted . example group_1=\"\" group_2=\"B\" plotted curve correspond survival probability (CIF) minus survival probability (CIF) B time. NULL, default first level variable. Similarly one plots ratios instead, ratio calculated / B. group_2 Also single character string specifying one levels variable. corresponds right side difference equation. See argument group_2. NULL, default second level variable. conf_int logical variable indicating whether confidence intervals drawn. works conf_int=TRUE bootstrap=TRUE used original adjustedsurv adjustedcif function call. conf_level confidence level used calculating confidence intervals. Ignored conf_int=FALSE. type Must one \"steps\" (drawing difference/ratio step function), \"lines\" (drawing difference/ratio using linear interpolation), \"points\" (drawing points ) \"none\" (drawing nothing, useful smoothed difference interest). defaults \"steps\". ratios, \"steps\" \"lines\" options available. times optional numeric vector points time difference ratio estimated. NULL (default) differences / ratios estimated whole curve. affects plot effect integral p_value also specified. max_t number indicating latest time curve extended . use_boot Whether use bootstrapped estimates calculate confidence intervals . Can used bootstrap=TRUE used original adjustedsurv adjustedcif function call. Ignored conf_int=FALSE. size number controlling thickness curve. color string specifying color curve. linetype string specifying linetype curve. alpha number controlling transparency level curves. conf_int_alpha number indicating level transparency used drawing confidence regions. points_ci_size used type=\"points\". Controls size error bars. points_ci_width used type=\"points\". Controls width error bars. xlab character string used X-Axis label plot. Defaults \"Time\". ylab character string used Y-Axis label plot. default (NULL) uses equation used calculate differences / ratios, based names supplied group_1 group_2. title character string used title plot. Set NULL title used. subtitle character string used subtitle plot. Set NULL subtitle used. gg_theme ggplot2 theme object used plot. line_at_ref Whether draw horizontal line y = 0 differences y = 1 ratios . line_at_ref_size size line drawn reference value. Ignored line_at_ref=FALSE. line_at_ref_color color line drawn reference value. Ignored line_at_ref=FALSE. line_at_ref_linetype linetype line drawn reference value. Ignored line_at_ref=FALSE. line_at_ref_alpha transparency level line drawn reference value. Ignored line_at_ref=FALSE. loess_smoother Whether draw LOESS smoother difference curves. loess_span span LOESS smoother. Ignored loess_smoother=FALSE. See stat_smooth ggplot2 package, method=\"loess\" details. loess_color color LOESS smoother line. Ignored loess_smoother=FALSE. loess_size size LOESS smoother line. Ignored loess_smoother=FALSE. loess_linetype linetype LOESS smoother line. Ignored loess_smoother=FALSE. loess_alpha transparency level LOESS smoother line. Ignored loess_smoother=FALSE. test optional curve_test object created using adjusted_curve_test function. supplied can used add p-value integral statistic plot. Alternatively, needed arguments can specified obtain values needed test. See . Set NULL (default) ignore . integral_from number specifying left limit integral. p_value=TRUE test=NULL, argument passed argument adjusted_curve_test function perform test. integral_to number specifying right limit integral. p_value=TRUE test=NULL, argument passed argument adjusted_curve_test function perform test. p_value Whether add p-value plot . requires either user supplies previously created curve_test object test argument, required arguments call function supplied (least integral_to). Either way works bootstrap=TRUE used original adjustedsurv adjustedcif function call. integral Whether add integral difference interval [, ] plot . requires either user supplies previously created curve_test object test argument, required arguments call function supplied (least integral_to). interval Whether add interval integral calculated plot well. text_pos_x X position text. Can either \"left\" (default), \"middle\", \"right\" number specifying exact position. text_pos_y Y position text. Can either \"bottom\" (default), \"middle\", \"top\" number specifying exact position. text_digits number digits p-value integral difference rounded . text_size size text. text_family family text. Defaults \"serif\". text_fontface fontface text. Defaults \"italic\". text_color color text. Defaults \"black\". text_alpha transparency level text. text_format_p Whether format p-values smaller 0.01 < 0.01. fill_area Whether add color area 0 difference. area_color color used fill area 0 difference using fill_area=TRUE. Ignored otherwise. area_alpha transparency level used fill area 0 difference using fill_area=TRUE. Ignored otherwise. fill_only_interval Whether area corresponding interval defined integral_from integral_to filled. used fill_area=TRUE. ... Currently used.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_curve_diff.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot the Difference Between or the Ratio of Two Adjusted Survival Curves or CIFs — plot_curve_diff","text":"function allows easy creation difference / ratio curves. syntax exactly adjusted survival curves adjusted CIFs. Similarly, syntax ratios difference curves, although options difference curve function available ratio curve function. default calculates estimates last point estimates group_1 curve group_2 curve available. currently support plotting multiple curves , useful two treatment groups variable. user interested , recommend calling function multiple times desired comparisons concatenating individual plots one plot afterwards using suitable function par ggarrange. information differences ratios confidence intervals calculated can found documentation adjusted_curve_diff function. information overall p-value integral calculated differences can found adjusted_curve_test function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_curve_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the Difference Between or the Ratio of Two Adjusted Survival Curves or CIFs — plot_curve_diff","text":"Returns ggplot2 object.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_curve_diff.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot the Difference Between or the Ratio of Two Adjusted Survival Curves or CIFs — plot_curve_diff","text":"Michael Coory, Karen E. Lamb, Michael Sorich (2014). \"Risk-Difference Curves can used Communicate Time-Dependent Effects Adjuvant Therapies Early Stage Cancer\". : Journal Clinical Epidemiology 67, pp. 966-972 Lihui Zhao, Lu Tian, Hajime Uno, Scott D. Solomon, Marc . Pfeffer, Jerald S. Schindler, L. J. Wei (2012). \"Utilizing Integrated Difference Two Survival Functions Quantify Treatment Contrast Designing, Monitoring Analyzing Comparative Clinical Study\". : Clinical Trials 9.5, pp. 570-577","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_curve_diff.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot the Difference Between or the Ratio of Two Adjusted Survival Curves or CIFs — plot_curve_diff","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_curve_diff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the Difference Between or the Ratio of Two Adjusted Survival Curves or CIFs — plot_curve_diff","text":"","code":"library(adjustedCurves) library(survival) library(ggplot2)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cox-regression for the outcome cox_mod <- coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                  data=sim_dat, x=TRUE)   # use it to calculate adjusted survival curves with bootstrapping adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=TRUE,                         bootstrap=TRUE,                         n_boot=15) # should be much bigger in reality  # plot the difference with default values plot_curve_diff(adjsurv)   # plot the ratio with default values plot_curve_ratio(adjsurv)   # plot with reversed differences plot_curve_diff(adjsurv, group_1=\"1\", group_2=\"0\")   # plot with confidence intervals plot_curve_diff(adjsurv, conf_int=TRUE)  plot_curve_ratio(adjsurv, conf_int=TRUE)   # plot using lines instead plot_curve_diff(adjsurv, conf_int=TRUE, type=\"lines\")   # plot using points instead plot_curve_diff(adjsurv, conf_int=TRUE, type=\"points\")   # plot using an additional loess smoother plot_curve_diff(adjsurv, loess_smoother=TRUE)   # plot without the line at reference plot_curve_diff(adjsurv, line_at_ref=FALSE)  plot_curve_ratio(adjsurv, line_at_ref=FALSE)   # plot with some custom parameters plot_curve_diff(adjsurv, conf_int=TRUE, color=\"blue\", linetype=\"dotted\",                 alpha=0.8, line_at_ref_size=1.1, line_at_ref_color=\"red\",                 loess_smoother=TRUE, loess_span=0.55)   # adding a p-value for a difference test in the interval [0, 0.75] plot_curve_diff(adjsurv, conf_int=TRUE, p_value=TRUE, integral_from=0,                 integral_to=0.75, integral=TRUE) #> Loading required namespace: ggpp #> Registered S3 methods overwritten by 'ggpp': #>   method                  from    #>   heightDetails.titleGrob ggplot2 #>   widthDetails.titleGrob  ggplot2   # adding a p-value for a difference test in the interval [0, 0.75], # and also showing that integral visually in the plot plot_curve_diff(adjsurv, conf_int=FALSE, p_value=TRUE, integral_from=0,                 integral_to=0.75, integral=TRUE, fill_area=TRUE,                 interval=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmst_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Adjusted Restricted Mean Survival Time Curves — plot_rmst_curve","title":"Plot Adjusted Restricted Mean Survival Time Curves — plot_rmst_curve","text":"function graphically display Restricted Mean Survival Time (RMST) time, using confounder-adjusted survival curves previously estimated using adjustedsurv function. plot functions package, internally uses ggplot2 package allows variety options.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmst_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Adjusted Restricted Mean Survival Time Curves — plot_rmst_curve","text":"","code":"plot_rmst_curve(adjsurv, times=NULL, conf_int=FALSE,                 interpolation=\"steps\", max_t=Inf,                 color=TRUE, linetype=FALSE, facet=FALSE,                 size=1, alpha=1, xlab=\"Time\", ylab=\"RMST\",                 title=NULL, subtitle=NULL, legend.title=\"Group\",                 legend.position=\"right\",                 gg_theme=ggplot2::theme_classic(),                 custom_colors=NULL, custom_linetypes=NULL,                 conf_int_alpha=0.4, ...)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmst_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Adjusted Restricted Mean Survival Time Curves — plot_rmst_curve","text":"adjsurv adjustedsurv object created using adjustedsurv function. times vector points time, passed argument adjusted_rmst function NULL (default). NULL, adjusted RMST estimated points event occurred. Otherwise estimated times. conf_int logical variable indicating whether bootstrap confidence intervals drawn. interpolation Corresponds argument name adjusted_rmst function. max_t number indicating latest survival time plotted. color logical variable indicating whether curves colored differently. custom_colors argument can used directly specify colors use. Set FALSE keep plot black white. linetype logical variable indicating whether curves different linetypes. custom_linetypes argument can used directly specify linetypes use. Set FALSE keep lines solid. facet logical variable indicating whether curves different facets. size number controlling thickness RMST curves. alpha number controlling transparency level RMST curves. xlab character string used X-Axis label plot. ylab character string used Y-Axis label plot. title character string used title plot. Set NULL title used. subtitle character string used subtitle plot. Set NULL subtitle used. legend.title character string used title legend. Set NULL legend included. legend.position character string specifying position legend. Ignored legend_title=NULL. gg_theme ggplot2 theme object used plot. custom_colors (named) vector specify colors adjusted RMST curve possibly confidence region. Set NULL use ggplot2 default values. Ignored color=FALSE. custom_linetypes (named) vector specify linetype adjusted RMST curve. Set NULL use ggplot2 default values. Ignored color=FALSE. Ignored linetype=FALSE. conf_int_alpha number indicating level transparency used drawing confidence regions. ... Currently used.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmst_curve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Adjusted Restricted Mean Survival Time Curves — plot_rmst_curve","text":"function simply calls adjusted_rmst range values, getting adjusted RMST estimates whole range survival curves. estimates plotted curve adjusted RMST replacing survival probability Y-Axis. brief description RMST calculated package, see documentation adjusted_rmst function. Literature describing RMST Curve Plots detail given references section. RMST curve can created adjusted survival curves. similar graphic adjusted CIFs can created utilizing adjusted Restricted Mean Time Lost (RMTL). calculation statistic implemented adjusted_rmtl function associated curve can created using plot_rmtl_curve function. confidence intervals specified many points time times, function might get slow. even slower multiple imputation also used creating adjustedsurv object.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmst_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Adjusted Restricted Mean Survival Time Curves — plot_rmst_curve","text":"Returns ggplot2 object.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmst_curve.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Adjusted Restricted Mean Survival Time Curves — plot_rmst_curve","text":"Lihui Zhao, Brian Claggett, Lu Tian, Hajime Uno, Marc . Pfeffer, Scott D. Solomon, Lorenzo Trippa, L. J. Wei (2016). \"Restricted Mean Survival Time Curve Survival Analysis\". : Biometrics 72.1, pp. 215-221 Jason J. Z. Liao, Frank Liu, Wen-Chi Wu (2020). \"Dynamic RMST Curves Survival Analysis Clinical Trials\". : BMC Medical Research Methodology 20.218","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmst_curve.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Adjusted Restricted Mean Survival Time Curves — plot_rmst_curve","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmst_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Adjusted Restricted Mean Survival Time Curves — plot_rmst_curve","text":"","code":"library(adjustedCurves) library(survival) library(ggplot2)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cox-regression for the outcome cox_mod <- coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                  data=sim_dat, x=TRUE)   # use it to calculate adjusted survival curves with bootstrapping adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=TRUE,                         bootstrap=TRUE,                         n_boot=15) # should be much bigger in reality  # plot the curves with default values plot_rmst_curve(adjsurv)   # plot with confidence intervals plot_rmst_curve(adjsurv, conf_int=TRUE)   # plot with some custom options plot_rmst_curve(adjsurv, max_t=0.5, linetype=TRUE,                 custom_colors=c(\"green\", \"blue\"))"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmtl_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Adjusted Restricted Mean Time Lost Curves — plot_rmtl_curve","title":"Plot Adjusted Restricted Mean Time Lost Curves — plot_rmtl_curve","text":"function graphically display Restricted Mean Time Lost (RMTL) time, using confounder-adjusted survival curves previously estimated using adjustedsurv function, cause-specific confounder-adjusted CIFs previously estimated using adjustedcif function. plot functions package, internally uses ggplot2 package allows variety options.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmtl_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Adjusted Restricted Mean Time Lost Curves — plot_rmtl_curve","text":"","code":"plot_rmtl_curve(adj, times=NULL, conf_int=FALSE,                 interpolation=\"steps\", max_t=Inf,                 color=TRUE, linetype=FALSE, facet=FALSE,                 size=1, alpha=1, xlab=\"Time\", ylab=\"RMTL\",                 title=NULL, subtitle=NULL, legend.title=\"Group\",                 legend.position=\"right\",                 gg_theme=ggplot2::theme_classic(),                 custom_colors=NULL, custom_linetypes=NULL,                 conf_int_alpha=0.4, ...)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmtl_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Adjusted Restricted Mean Time Lost Curves — plot_rmtl_curve","text":"adj adjustedsurv object created using adjustedsurv function, adjustedcif object created using adjustedcif function. times vector points time, passed argument adjusted_rmtl function NULL (default). NULL, adjusted RMTL estimated points event occurred. Otherwise estimated times. conf_int logical variable indicating whether bootstrap confidence intervals drawn. interpolation Corresponds argument name adjusted_rmtl function. max_t number indicating latest survival time plotted. color logical variable indicating whether curves colored differently. custom_colors argument can used directly specify colors use. Set FALSE keep plot black white. linetype logical variable indicating whether curves different linetypes. custom_linetypes argument can used directly specify linetypes use. Set FALSE keep lines solid. facet logical variable indicating whether curves different facets. size number controlling thickness RMTL curves. alpha number controlling transparency level RMTL curves. xlab character string used X-Axis label plot. ylab character string used Y-Axis label plot. title character string used title plot. Set NULL title used. subtitle character string used subtitle plot. Set NULL subtitle used. legend.title character string used title legend. Set NULL legend included. legend.position character string specifying position legend. Ignored legend_title=NULL. gg_theme ggplot2 theme object used plot. custom_colors (named) vector specify colors adjusted RMTL curve possibly confidence region. Set NULL use ggplot2 default values. Ignored color=FALSE. custom_linetypes (named) vector specify linetype adjusted RMTL curve. Set NULL use ggplot2 default values. Ignored color=FALSE. Ignored linetype=FALSE. conf_int_alpha number indicating level transparency used drawing confidence regions. ... Currently used.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmtl_curve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Adjusted Restricted Mean Time Lost Curves — plot_rmtl_curve","text":"function simply calls adjusted_rmtl range values, getting adjusted RMTL estimates whole range survival curves CIFs. estimates plotted curve adjusted RMTL replacing survival probability failure probability Y-Axis. brief description RMTL calculated package, see documentation adjusted_rmtl function. Literature describing RMTL Curve Plots detail given references section. confidence intervals specified many points time times, function might get slow. even slower multiple imputation also used creating adjustedsurv adjustedcif object.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmtl_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Adjusted Restricted Mean Time Lost Curves — plot_rmtl_curve","text":"Returns ggplot2 object.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmtl_curve.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Adjusted Restricted Mean Time Lost Curves — plot_rmtl_curve","text":"Lihui Zhao, Brian Claggett, Lu Tian, Hajime Uno, Marc . Pfeffer, Scott D. Solomon, Lorenzo Trippa, L. J. Wei (2016). \"Restricted Mean Survival Time Curve Survival Analysis\". : Biometrics 72.1, pp. 215-221","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmtl_curve.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Adjusted Restricted Mean Time Lost Curves — plot_rmtl_curve","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/plot_rmtl_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Adjusted Restricted Mean Time Lost Curves — plot_rmtl_curve","text":"","code":"library(adjustedCurves) library(survival) library(ggplot2)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cox-regression for the outcome cox_mod <- coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                  data=sim_dat, x=TRUE)   # use it to calculate adjusted survival curves with bootstrapping adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=TRUE,                         bootstrap=TRUE,                         n_boot=15) # should be much bigger in reality  # plot the curves with default values plot_rmtl_curve(adjsurv)   # plot with confidence intervals plot_rmtl_curve(adjsurv, conf_int=TRUE)   # plot with some custom options plot_rmtl_curve(adjsurv, max_t=0.5, linetype=TRUE,                 custom_colors=c(\"green\", \"blue\"))"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/print.curve_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for curve_test Objects — print.curve_test","title":"Print Method for curve_test Objects — print.curve_test","text":"Prints important parts output object.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/print.curve_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for curve_test Objects — print.curve_test","text":"","code":"# S3 method for curve_test print(x, digits=4, ...)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/print.curve_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for curve_test Objects — print.curve_test","text":"x object class curve_test created adjusted_curve_test function. digits many digits use rounding results. ... Currently used.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/print.curve_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for curve_test Objects — print.curve_test","text":"Silently returns data.frame can seen calling function. ABC abbreviation \"area curves\".","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/print.curve_test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for curve_test Objects — print.curve_test","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/print.curve_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print Method for curve_test Objects — print.curve_test","text":"","code":"# See ?adjusted_curve_diff"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_crisk.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate Competing Risks Data with Confounders — sim_confounded_crisk","title":"Simulate Competing Risks Data with Confounders — sim_confounded_crisk","text":"function simulate time--event data multiple competing causes failure one multiple confounders. user can specify relationship covariates cause-specific survival time relationship covariates treatment assignment probability. Random censoring based custom function may also introduced. Can used simulation studies showcase usage adjusted CIF methodology presented package.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_crisk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate Competing Risks Data with Confounders — sim_confounded_crisk","text":"","code":"sim_confounded_crisk(n=500, lcovars=NULL, outcome_betas=NULL,                      group_beta=c(1, 0), gamma=c(1.8, 1.8),                      lambda=c(2, 2), treatment_betas=NULL,                      intercept=-0.5, gtol=0.001,                      cens_fun=function(n){stats::rweibull(n, 1, 2)},                      cens_args=list(), max_t=1.7)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_crisk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate Competing Risks Data with Confounders — sim_confounded_crisk","text":"n integer specifying sample size simulated data set. lcovars named list specify covariates. list element vector containing information desired covariate distribution. See details. outcome_betas list numeric vectors beta coefficients cause-specific time--event outcome. list length      lcovars list every entry numeric vector one entry cause failure. See details. group_beta numeric vector containing specifying beta coefficients grouping variable cause-specific survival time. contain one entry every cause failure. gamma numeric parameter simulation survival time using weibull distribution. See details. lambda numeric parameter simulation survival time using weibull distribution. See details. treatment_betas named numeric vector beta coefficients treatment assignment model. intercept intercept treatment assignment model. gtol Tolerance estimated treatment assignment probabilities truncated. cens_fun function generate censoring times. function needs take least one argument called n. Additional arguments allowed can supplied using cens_args argument. cens_args list named arguments passed cens_fun. max_t number denoting maximum follow-time. Every event time bigger threshold censored. contrast single event survival simulation, value actually supplied used numerical inversion step. Theoretically Inf can used, might work practice.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_crisk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate Competing Risks Data with Confounders — sim_confounded_crisk","text":"simulation confounded competing risks data five main steps: (1) Generation covariates, (2) Assigning treatment variable, (3) Generating cause-specific survival time (4) Generating corresponding cause failure (5) Introducing censoring. First, covariates generated taking independent n random samples distributions defined lcovars. second step generated covariates used estimate probability receiving treatment (propensity score) simulated person dataset. done using logistic regression model, using values treatment_betas coefficients interecept intercept. changing intercept, user can vary proportion cases end treatment group average. estimated probabilities used generate treatment variable (\"group\"), making treatment assignment dependent covariates. Next, survival times generated based method described Beyersman et al. (2009) using causal coefficients defined outcome_betas group_beta. survival time generated corresponding cause failure drawn multinomial distribution probabilities defined cause hazard cause-specific hazards. details can found cited literature. independently generated covariates covariate-dependent treatment variable used step. introduces confounding. Independent right-censoring introduced taking n independent random draws distribution defined cens_fun censoring every individual whose censoring time smaller simulated survival time. whole process based work Chatton et al. (2020). Currently supports binary treatments allow dependent censoring.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_crisk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate Competing Risks Data with Confounders — sim_confounded_crisk","text":"Returns data.frame object containing simulated covariates, event indicator (\"event\"), survival/censoring time (\"time\") group variable (\"group\").","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_crisk.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate Competing Risks Data with Confounders — sim_confounded_crisk","text":"Jan Beyersmann, Arélien Latouche, Anika Buchholz, Martin Schumacher (2009). \"Simulating Competing Risks Data Survival Analysis\". : Statistics Medicine 28, pp. 956-971 D. Morina . Navarro (2017). \"Competing Risks Simulation survsim R Package\". : Communications Statistics: Simulation Computation 46.7, pp. 5712-5722 Arthur Chatton, Florent Le Borgne, Clémence Leyrat, Yohann Foucher (2020). G-Computation Inverse Probability Weighting Time--Event Outcomes: Comparative Study. arXiv:2006.16859v1","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_crisk.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate Competing Risks Data with Confounders — sim_confounded_crisk","text":"code step (3) (4) described details taken survsim R-Package, written David Morina Soler (slight modifications). rest function written Robin Denz.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_crisk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate Competing Risks Data with Confounders — sim_confounded_crisk","text":"","code":"library(adjustedCurves)  set.seed(42)  # simulate data with default values sim_dat <- sim_confounded_crisk(n=10)  # set group betas to 0 sim_dat <- sim_confounded_crisk(n=10, group_beta=c(0, 0))  # set some custom values outcome_betas <- list(c(0.03, 0.4),                       c(1.1, 0.8),                       c(0, 0),                       c(-0.2, -0.4),                       c(log(1.3), log(1.3)/3),                       c(0, 0))  treatment_betas <- c(x1=0, x2=log(3), x3=log(1.2),                      x4=0, x5=log(1.1), x6=log(1.4))  lcovars <- list(x1=c(\"rbinom\", 1, 0.3),                 x2=c(\"rbinom\", 1, 0.7),                 x3=c(\"rbinom\", 1, 0.5),                 x4=c(\"rnorm\", 0, 1),                 x5=c(\"rnorm\", 0, 1.1),                 x6=c(\"rnorm\", 0, 0.9))  sim_dat <- sim_confounded_crisk(n=10,                                 treatment_betas=treatment_betas,                                 outcome_betas=outcome_betas,                                 lcovars=lcovars)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate Survival Data with Confounders — sim_confounded_surv","title":"Simulate Survival Data with Confounders — sim_confounded_surv","text":"function simulate time--event data one multiple confounders. user can specify relationship covariates survival time relationship covariates treatment assignment probability. Random censoring based custom function may also introduced. Can used simulation studies showcase usage adjusted survival curve methodology presented package.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate Survival Data with Confounders — sim_confounded_surv","text":"","code":"sim_confounded_surv(n=500, lcovars=NULL, outcome_betas=NULL,                     group_beta=-1, surv_dist=\"weibull\",                     gamma=1.8, lambda=2, treatment_betas=NULL,                     intercept=-0.5, gtol=0.001,                     cens_fun=function(n){stats::rweibull(n, 1, 2)},                     cens_args=list(), max_t=Inf)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate Survival Data with Confounders — sim_confounded_surv","text":"n integer specifying sample size simulated data set. lcovars named list specify covariates. list element vector containing information desired covariate distribution. See details. outcome_betas named numeric vector beta coefficients time--event outcome. group_beta number specifying beta coefficient grouping variable survival time. surv_dist character string denoting distribution used simulation survival time. See details. gamma numeric parameter simulation survival time. See details. lambda numeric parameter simulation survival time. See details. treatment_betas named numeric vector beta coefficients treatment assignment model. intercept intercept treatment assignment model. gtol Tolerance estimated treatment assignment probabilities truncated. cens_fun function generate censoring times NULL. NULL, censoring introduced. cens_args Arguments passed cens_fun. Ignored cens_fun=NULL. max_t number denoting maximum follow-time. Every event time bigger threshold censored.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_surv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate Survival Data with Confounders — sim_confounded_surv","text":"simulation confounded survival data four main steps: (1) Generation covariates, (2) Assigning treatment variable, (3) Generating survival times (4) introducing censoring. First, covariates generated taking independent n random samples distributions defined lcovars. second step generated covariates used estimate probability receiving treatment (propensity score) simulated person dataset. done using logistic regression model, using values treatment_betas coefficients interecept intercept. changing intercept, user can vary proportion cases end treatment group average. estimated probabilities used generate treatment variable (\"group\"), making treatment assignment dependent covariates. Next, survival times generated based method described Bender et al. (2005) using causal coefficients defined outcome_betas group_beta. independently generated covariates covariate-dependent treatment variable used step. introduces confounding. Independent right-censoring introduced taking n independent random draws distribution defined cens_fun censoring every individual whose censoring time smaller simulated survival time. whole process based work Chatton et al. (2020). Currently supports binary treatments allow dependent censoring.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate Survival Data with Confounders — sim_confounded_surv","text":"Returns data.frame object containing simulated covariates, event indicator (\"event\"), survival/censoring time (\"time\") group variable (\"group\").","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_surv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate Survival Data with Confounders — sim_confounded_surv","text":"Ralf Bender, Thomas Augustin, Maria Blettner (2005). \"Generating Survival Times Simulate Cox Proportional Hazards Models\". : Statistics Medicine 24.11, pp. 1713-1723 Arthur Chatton, Florent Le Borgne, Clémence Leyrat, Yohann Foucher (2020). G-Computation Inverse Probability Weighting Time--Event Outcomes: Comparative Study. arXiv:2006.16859v1","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_surv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate Survival Data with Confounders — sim_confounded_surv","text":"Robin Denz","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/sim_confounded_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate Survival Data with Confounders — sim_confounded_surv","text":"","code":"library(adjustedCurves)  set.seed(42)  # simulate data with default values sim_dat <- sim_confounded_surv(n=10)  # simulate data with some new values lcovars <- list(x1=c(\"rnorm\", 1, 2),                 x2=c(\"rnorm\", 3, 4),                 x3=c(\"runif\", 1, 2)) treatment_betas <- c(x1=0.2, x2=0.6, x3=-0.9) outcome_betas <- c(x1=1.1, x2=0, x3=-0.3)  sim_dat <- sim_confounded_surv(n=10, lcovars=lcovars,                                treatment_betas=treatment_betas,                                outcome_betas=outcome_betas)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw.html","id":null,"dir":"Reference","previous_headings":"","what":"Augmented Inverse Probability of Treatment Weighted Survival Curves — surv_aiptw","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves — surv_aiptw","text":"page explains details estimating augmented inverse probability treatment weighted survival curves single event time--event data (method=\"aiptw\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, outcome_model argument treatment_model argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves — surv_aiptw","text":"outcome_model [required] Must coxph model object, modeling time--event mechanism. See details examples. treatment_model [required] Must glm model object variable response variable. See details examples. censoring_model Must coxph model object, modeling censoring mechanism NULL. NULL (default) independent censoring assumed. See details examples. verbose Whether print estimation information ate function riskRegression package. Defaults FALSE. ... arguments passed ate.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves — surv_aiptw","text":"Type Adjustment: Requires treatment assignment model (glm) outcome model (coxph). Also allows, rely , additional model describing censoring mechanism (also coxph object). Doubly-Robust: Estimates Doubly-Robust. Categorical groups: Currently two groups variable allowed. Must still factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies riskRegression package. Instead modeling outcome mechanism treatment assignment mechanism, kind models required use method. either models correctly specified, unbiased estimates obtained. Can also used adjust dependent censoring using another Cox-Regression model. obvious advantage method doubly robust property. however comes price efficiency. also possible estimates fall outside 0 1 probability bounds, particularly time near 0 maximal observed event time. also guarantee estimated survival curves monotonically decreasing. information methods user referred literature listed references. function basically just wrapper around ate function riskRegression package. Additional arguments may passed function using ... syntax. however recommended use ate directly cases.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves — surv_aiptw","text":"Adds following additional objects output adjustedsurv function: ate_object: object returned ate function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves — surv_aiptw","text":"James M. Robins Andrea Rotnitzky (1992). \"Recovery Information Adjustment Dependent Censoring Using Surrogate Markers\". : AIDS Epidemiology: Methodological Issues. Ed. Nicholas P. Jewell, Klaus Dietz, Vernon T. Farewell. New York: Springer Science + Business Media, pp. 297-331 Alan E. Hubbard, Mark J. van der Laan, James M. Robins (2000). \"Nonparametric Locally Efficient Estimation Treatment Specific Survival Distribution Right Censored Data Covariates Observational Studies\". : Statistical Models Epidemiology, Environment, Clinical Trials. Ed. M. Elizabeth Halloran Donald Berry. New York: Springer Science + Business Media, pp. 135-177 Min Zhang Douglas E. Schaubel (2012). \"Contrasting Treatment-Specific Survival Using Double-Robust Estimators\". : Statistics Medicine 31.30, pp. 4255-4268 Xiaofei Bai, Anastasios . Tsiatis, Sean M. O’Brien (2013). \"Doubly-Robust Estimators Treatment-Specific Survival Distributions Observational Studies Stratified Sampling\". : Biometrics 69, pp. 830–839 Brice Maxime Hugues Ozenne, Thomas Harder Scheike, Laila Staerk (2020). \"Estimation Average Treatment Effects Right-Censored Time Event Outcome Competing Risks\". : Biometrical Journal 62, pp. 751–763","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves — surv_aiptw","text":"wrapper function written Robin Denz, ate function (wrapper build around) written people. See ?ate details.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves — surv_aiptw","text":"","code":"library(adjustedCurves) library(riskRegression) library(survival)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cox-regression for the outcome cox_mod <- coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                  data=sim_dat, x=TRUE)  # estimate a treatment assignment model glm_mod <- glm(group ~ x1 + x3 + x5 + x6, data=sim_dat, family=\"binomial\")  # use it to calculate adjusted survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"aiptw\",                         outcome_model=cox_mod,                         treatment_model=glm_mod,                         conf_int=FALSE)  # plot the curves plot(adjsurv)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw_pseudo.html","id":null,"dir":"Reference","previous_headings":"","what":"Augmented Inverse Probability of Treatment Weighted Survival Curves using Pseudo-Values — surv_aiptw_pseudo","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves using Pseudo-Values — surv_aiptw_pseudo","text":"page explains details estimating augmented inverse probability treatment weighted survival curves using Pseudo-Values single event time--event data (method=\"aiptw_pseudo\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, outcome_vars argument treatment_model argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw_pseudo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves using Pseudo-Values — surv_aiptw_pseudo","text":"outcome_vars [required] character vector column names specifying variables used modeling outcome mechanism using geese. See details examples. treatment_model [required] Must glm multinom model object variable response variable. Alternatively can supply numeric vector propensity scores directly. See details examples. type_time character string specifying time modeled. Possible values \"factor\" (modeling point time separate variable, default), \"bs\" (modeling time using B-Splines) \"ns\" (modeling time using natural splines). spline_df number degrees freedom used natural-spline B-spline function. Ignored type_time=\"factor\". Defaults 5. censoring_vars optional character vector specifying variables data. used calculation inverse probability censoring weighted pseudo observations. See ?pseudo_aareg information. Set NULL (default) use standard pseudo-values without corrections dependent censoring instead. ipcw_method specific method used calculation inverse probability censoring weighted pseudo observations. Can either \"binder\" (default) \"hajek\". See ?pseudo_aareg information. Ignored censoring_vars=NULL.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw_pseudo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves using Pseudo-Values — surv_aiptw_pseudo","text":"Type Adjustment: Requires treatment assignment model (glm multinom) character vector variable names used model outcome mechanism (internally uses geese). Covariate-Dependent censoring can corrected using inverse probability censoring weighted pseudo-values (Binder et al. 2014) Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies geepack prodlim packages. Additionally requires eventglm package censoring_vars specified. Instead modeling outcome mechanism treatment assignment mechanism, kind models required use method. either models correctly specified, unbiased estimates obtained. contrast \"aiptw\" method, \"aiptw_pseudo\" method uses generalized estimation equation (geese) approach model outcome mechanism. model fit way described \"direct_pseudo\" method. Direct Standardization based estimates transformed using previously estimated propensity score. results doubly-robust property method. information particular method can found original article Wang (2018), information Pseudo-Values available Andersen et al. (2017) Andersen Perme (2010). estimating geese model ev_time variable used factor default. results one coefficient estimated unique point time, can slow computationally lot unique points time /dataset many rows. cases recommended use type_time=\"bs\" type_time=\"ns\", results ev_time modeled using B-Splines Natural Splines. Simulation studies indicate little difference estimates appropriately large number spline_df used. Additionally, covariate-dependent censoring can accounted using inverse probability censoring weighted pseudo-values (Binder et al. 2014) instead regular pseudo-values (specified using censoring_vars ipcw_method arguments).","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw_pseudo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves using Pseudo-Values — surv_aiptw_pseudo","text":"Adds following additional objects output adjustedsurv function: pseudo_values: matrix estimated pseudo-values. geese_model: geese model used make predictions.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw_pseudo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves using Pseudo-Values — surv_aiptw_pseudo","text":"Jixian Wang (2018). \"Simple, Doubly Robust, Efficient Estimator Survival Functions Using Pseudo Observations\". : Pharmaceutical Statistics 17.38-48 James M. Robins Andrea Rotnitzky (1992). \"Recovery Information Adjustment Dependent Censoring Using Surrogate Markers\". : AIDS Epidemiology: Methodological Issues. Ed. Nicholas P. Jewell, Klaus Dietz, Vernon T. Farewell. New York: Springer Science + Business Media, pp. 297-331 Per Kragh Andersen, Elisavet Syriopoulou, Erik T. Parner (2017). \"Causal Inference Survival Analysis using Pseudo-Observations\". : Statistics Medicine 36, pp. 2669-2681 Per Kragh Andersen Maja Pohar Perme (2010). \"Pseudo-Observations Survival Analysis\". : Statistical Methods Medical Research 19, pp. 71-99 Aris Perperoglou, Willi Sauerbrei, Michal Abrahamowicz, Matthias Schmid (2019). \"Review Spline Function Procedures R\". : BMC Medical Research Methodology 19.46, pp. 1-16 Nadine Binder, Thomas . Gerds, Per Kragh Andersen (2014). \"Pseudo- Observations Competing Risks Covariate Dependent Censoring\". : Lifetime Data Analysis 20, pp. 303-315","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw_pseudo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves using Pseudo-Values — surv_aiptw_pseudo","text":"Jixian Wang supplied R source code used original article, used Robin Denz create generalized version method additional functionality improved performance.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_aiptw_pseudo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Augmented Inverse Probability of Treatment Weighted Survival Curves using Pseudo-Values — surv_aiptw_pseudo","text":"","code":"library(adjustedCurves)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a treatment assignment model glm_mod <- glm(group ~ x1 + x3 + x5 + x6, data=sim_dat, family=\"binomial\")  # use it + pseudo values + geese model to calculate adjusted survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"aiptw_pseudo\",                         outcome_vars=c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\"),                         treatment_model=glm_mod,                         conf_int=TRUE)  # plot the curves plot(adjsurv, conf_int=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct.html","id":null,"dir":"Reference","previous_headings":"","what":"Direct Adjusted Survival Curves — surv_direct","title":"Direct Adjusted Survival Curves — surv_direct","text":"page explains details estimating confounder-adjusted survival curves using previously fit Cox-Regression model single event time--event data using Direct Standardization (method=\"direct\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, outcome_model argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Direct Adjusted Survival Curves — surv_direct","text":"outcome_model [required] Must previously fit model object including variable independent variable. Apart classic coxph model function also supports variety models. See models_surv_direct list supported model objects details. verbose Whether print estimation information ate function riskRegression package. Ignored outcome_model coxph object. Defaults FALSE. predict_fun function used calculate predicted survival probabilities given covariates points time. argument needs specified kind model supplied outcome_model directly supported. See models_surv_direct information. Defaults NULL. ... arguments passed ate outcome_model coxph object. Otherwise additional arguments passed respective predict method. See models_surv_direct information.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Direct Adjusted Survival Curves — surv_direct","text":"Type Adjustment: Requires model describing outcome mechanism. See models_surv_direct list supported model objects details. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available outcome_model coxph object. ate function used calculation case. Bootstrap confidence intervals can however calculated supported models. See ?adjustedsurv information bootstrapping. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies riskRegression package. Depending outcome_model packages might needed. See models_surv_direct details. method works executing following steps: (1) First model fitted describes outcome mechanism (time--event). Next (2) multiple copies original dataset created, one possible level variable interest. (3) variable set one level observations dataset. (4) model used predict survival probabilities points time T observation dataset copies. (5) estimated probabilities averaged dataset point time, resulting adjusted survival probabilities levels group variable specified points time. literature method sometimes called \"Direct Standardization\", \"Corrected Group-Prognosis\", \"G-Computation\" \"G-Formula\". model step (1) \"correct\"\" method produce unbiased estimates counterfactual survival curves. model can called \"correct\" model context can used produce unbiased estimates true (unknown) individual survival probabilities given covariates. used properly one efficient methods. information can found literature listed references. popular model describing outcome mechanism time--event context Cox-regression model (coxph). function however also supports variety models.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Direct Adjusted Survival Curves — surv_direct","text":"Adds following additional objects output adjustedsurv function: ate_object: object returned ate function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Direct Adjusted Survival Curves — surv_direct","text":"-Ming Chang, Rebecca Gelman, Marcello Pagano (1982). \"Corrected Group Prognostic Curves Summary Statistics\". : Journal Chronic Diseases 35, pp. 669-674 Robert W. Makuch (1982). \"Adjusted Survival Curve Estimation Using Covariates\". : Journal Chronic Diseases 35.6, pp. 437-443 Xu Zhang, Fausto R. Loberiza, John P. Klein, Mei-Jie Zhang (2007). \"SAS Macro Estimation Direct Adjusted Survival Curves Based Stratified Cox Regression Model\". : Computer Methods Programs Biomedicine 88, pp. 95-101","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Direct Adjusted Survival Curves — surv_direct","text":"function written Robin Denz. using coxph models however, function just wrapper around ate function, written people. See ?ate information.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Direct Adjusted Survival Curves — surv_direct","text":"","code":"library(adjustedCurves) library(survival) library(riskRegression)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a cox-regression for the outcome cox_mod <- coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                  data=sim_dat, x=TRUE)  # use it to calculate adjusted survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=cox_mod,                         conf_int=FALSE)  # plot the curves plot(adjsurv)   # not run to avoid dependency on flexsurv and mice too slow if (interactive()) { ## using a flexsurv() model, this requires the 'fleysurv' package mod_flexsurvreg <- flexsurvreg(Surv(time, event) ~ group + x1 + x2 + x5 + x6,                                data=sim_dat, dist=\"gengamma\")  # using it to calculate the adjusted survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct\",                         outcome_model=mod_flexsurvreg,                         conf_int=FALSE)  # plot using steps=FALSE to draw them as smooth functions, since # they were estimated using a parametric model plot(adjsurv, steps=FALSE)  ## using multiple imputation library(mice)  # introduce random missingness in x1 as example # NOTE: This is only done as an example, in reality you would #       already have missing data, not introduce it yourself. sim_dat$x1 <- ifelse(runif(n=50) < 0.5, sim_dat$x1, NA)  # perform multiple imputation mids <- mice::mice(data=sim_dat, method=\"pmm\", m=5, printFlag=FALSE)  # fit model for each imputed dataset mira <- with(mids, coxph(Surv(time, event) ~ x1 + x2 + x3 + x4 + x5 + x6 + group,                          x=TRUE))  # calculate adjusted survival curves on imputed data adj <- adjustedsurv(data=mids,                     variable=\"group\",                     ev_time=\"time\",                     event=\"event\",                     method=\"direct\",                     outcome_model=mira) plot(adj) }"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct_pseudo.html","id":null,"dir":"Reference","previous_headings":"","what":"Direct Adjusted Survival Curves using Pseudo-Values — surv_direct_pseudo","title":"Direct Adjusted Survival Curves using Pseudo-Values — surv_direct_pseudo","text":"page explains details estimating direct adjusted survival curves using pseudo-values single event time--event data (method=\"direct_pseudo\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, outcome_vars argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct_pseudo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Direct Adjusted Survival Curves using Pseudo-Values — surv_direct_pseudo","text":"outcome_vars [required] character vector column names specifying variables used modeling outcome mechanism. See details examples. type_time character string specifying time modeled. Possible values \"factor\" (modeling point time separate variable, default), \"bs\" (modeling time using B-Splines) \"ns\" (modeling time using natural splines). spline_df number degrees freedom used natural-spline B-spline function. Ignored type_time=\"factor\". Defaults 5. censoring_vars optional character vector specifying variables data. used calculation inverse probability censoring weighted pseudo observations. See ?pseudo_aareg information. Set NULL (default) use standard pseudo-values without corrections dependent censoring instead. ipcw_method specific method used calculation inverse probability censoring weighted pseudo observations. Can either \"binder\" (default) \"hajek\". See ?pseudo_aareg information. Ignored censoring_vars=NULL.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct_pseudo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Direct Adjusted Survival Curves using Pseudo-Values — surv_direct_pseudo","text":"Type Adjustment: Requires character vector variable names used model outcome mechanism (internally uses geese). Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Bootstrapping can still used estimate confidence intervals (see ?adjustedsurv). Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies geepack prodlim packages. Additionally requires eventglm package censoring_vars specified. method works executing following steps: (1) First Pseudo-Values survival probabilities estimated observation dataset points time T. Afterwards (2) new dataset created every individual observation multiple rows, one point time interest. (3) dataset used fit generalized estimating equations (geese) model, using Pseudo-Values independent variable. Next (4) multiple copies new dataset created, one possible level variable interest. (5) variable set one level observations dataset. (5) geese model used predict survival probabilities points time T observation dataset copies. (6) estimated probabilities averaged dataset point time, resulting adjusted survival probabilities levels group variable specified points time. essentially procedure described \"direct\". difference instead relying coxph model, method uses Pseudo-Values geese model. can useful data conform assumptions needed use Cox-Regression model (example proportional hazards assumption). estimating geese model ev_time variable used factor default. results one coefficient estimated unique point time, can slow computationally lot unique points time /dataset many rows. cases recommended use type_time=\"bs\" type_time=\"ns\", results ev_time modeled using B-Splines Natural Splines. Simulation studies indicate little difference estimates appropriately large number spline_df used. Additionally, covariate-dependent censoring can accounted using inverse probability censoring weighted pseudo-values (Binder et al. 2014) instead regular pseudo-values (specified using censoring_vars ipcw_method arguments).","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct_pseudo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Direct Adjusted Survival Curves using Pseudo-Values — surv_direct_pseudo","text":"Adds following additional objects output adjustedsurv function: pseudo_values: matrix estimated pseudo-values. geese_model: geese model used make predictions.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct_pseudo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Direct Adjusted Survival Curves using Pseudo-Values — surv_direct_pseudo","text":"Per Kragh Andersen, Elisavet Syriopoulou, Erik T. Parner (2017). \"Causal Inference Survival Analysis using Pseudo-Observations\". : Statistics Medicine 36, pp. 2669-2681 Per Kragh Andersen Maja Pohar Perme (2010). \"Pseudo-Observations Survival Analysis\". : Statistical Methods Medical Research 19, pp. 71-99 Aris Perperoglou, Willi Sauerbrei, Michal Abrahamowicz, Matthias Schmid (2019). \"Review Spline Function Procedures R\". : BMC Medical Research Methodology 19.46, pp. 1-16 Nadine Binder, Thomas . Gerds, Per Kragh Andersen (2014). \"Pseudo-Observations Competing Risks Covariate Dependent Censoring\". : Lifetime Data Analysis 20, pp. 303-315","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct_pseudo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Direct Adjusted Survival Curves using Pseudo-Values — surv_direct_pseudo","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_direct_pseudo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Direct Adjusted Survival Curves using Pseudo-Values — surv_direct_pseudo","text":"","code":"library(adjustedCurves) library(geepack)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # calculate adjusted survival curves, with time as factor adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct_pseudo\",                         outcome_vars=c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\"),                         type_time=\"factor\",                         force_bounds=TRUE,                         iso_reg=TRUE)  # with time modelled as B-Spline using 5 degrees of freedom adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"direct_pseudo\",                         outcome_vars=c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\"),                         type_time=\"bs\",                         spline_df=5,                         force_bounds=TRUE,                         iso_reg=TRUE)  # plot the curves plot(adjsurv)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_emp_lik.html","id":null,"dir":"Reference","previous_headings":"","what":"Empirical Likelihood Estimation Survival Curves — surv_emp_lik","title":"Empirical Likelihood Estimation Survival Curves — surv_emp_lik","text":"page explains details estimating adjusted survival curves using empirical likelihood estimation methodology introduced Wang et al. (2019) single event time--event data (method=\"emp_lik\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, treatment_vars argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_emp_lik.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empirical Likelihood Estimation Survival Curves — surv_emp_lik","text":"treatment_vars [required] character vector column names specifying variables used covariates empirical likelihood estimation. See details examples. moment character string specifying moment adjust . Can either \"first\" (default) \"second\". standardize logical variable indicating whether treatment_vars variables standardized. Defaults FALSE. See details. gtol number specifying tolerance weights. basically used avoid division 0 errors cases weights estimated 0. Defaults 0.00001. max_iter Maximum number iterations allowed newton-raphson algorithm. Set 100 default enough cases. newton_tol Tolerance used newton-raphson algorithm. Set 1.0e-06 default enough cases.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_emp_lik.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Empirical Likelihood Estimation Survival Curves — surv_emp_lik","text":"Type Adjustment: Requires character vector variable names used balance distribution covariates (treatment assignment mechanism) Doubly-Robust: Estimates Doubly-Robust (see details). Categorical groups: binary treatments allowed. column specified variable must factor variable exactly two levels. Approximate Variance: Calculations approximate variance confidence intervals available. Bootstrapping can still used estimate confidence intervals (see ?adjustedsurv). Allowed Time Values: Allows continuous integer survival times. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies MASS package. code adjKMtest package used internally (see <https://github.com/kimihua1995/adjKMtest>) necessary install package. code directly included R-Package. use method, please cite paper Wang et al. (2019). non-parametric likelihood based method require researcher assume data generated known family distributions. method works forcing moments covariates equal treatment groups, maximization constrained likelihood function. resulting equality distributions removes bias created confounders. method proposed Wang et al. (2019). Since exact form mechanisms left unspecified, robust model misspecification IPTW direct adjustment. underlying method theoretically doubly-robust shown Wang et al. (2019), specific implementation method implemented package demonstrated Denz et al. (2022). example, confounder quadratic effect treatment-assignment passed function linear predictor (e.g. without squaring ) method produce asymptotically biased estimates.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_emp_lik.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Empirical Likelihood Estimation Survival Curves — surv_emp_lik","text":"Adds additional objects output adjustedsurv function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_emp_lik.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Empirical Likelihood Estimation Survival Curves — surv_emp_lik","text":"Xiaofei Wang, Fangfang Bai, Herbert Pang, Stephen L. George (2019). \"Bias-Adjusted Kaplan-Meier Survival Curves Marginal Treatment Effect Observational Studies\". : Journal Biopharmaceutical Statistics 29.4, pp. 592-605 Art B. Owen (2001). Empirical Likelihood. Boca Raton: CRC Press Robin Denz, Renate Klaaßen-Mielke, Nina Timmesfeld (2023). \"Comparison Different Methods Adjust Survival Curves Confounders\". : Statistics Medicine 42.10, pp. 1461-1479","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_emp_lik.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Empirical Likelihood Estimation Survival Curves — surv_emp_lik","text":"functions used estimation written : Fangfang Bai, PhD School Statistics, University International Business Economics, Beijing, China. Xiaofei Wang, PhD Department Biostatistics Bioinformatics, Duke University, Durham, NC, USA. Robin Denz performed small changes code (documented code-comments source code) wrote wrapper function.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_emp_lik.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Empirical Likelihood Estimation Survival Curves — surv_emp_lik","text":"","code":"library(adjustedCurves)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # calculate adjusted survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"emp_lik\",                         treatment_vars=c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\"),                         moment=\"first\") #> Warning: Dichotomous variables coded with 0 and 1 found in  'treatment_vars'. Consider recoding to -1 and 1 to avoid estimation problems. #> Warning: Dichotomous variables coded with 0 and 1 found in  'treatment_vars'. Consider recoding to -1 and 1 to avoid estimation problems. #> Warning: Dichotomous variables coded with 0 and 1 found in  'treatment_vars'. Consider recoding to -1 and 1 to avoid estimation problems.  # plot the curves plot(adjsurv)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Probability of Treatment Weighted Survival using Cox-Regression — surv_iptw_cox","title":"Inverse Probability of Treatment Weighted Survival using Cox-Regression — surv_iptw_cox","text":"page explains details estimating inverse probability treatment weighted survival curves using weighted univariate cox-regression single event time--event data (method=\"iptw_cox\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, treatment_model argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Probability of Treatment Weighted Survival using Cox-Regression — surv_iptw_cox","text":"treatment_model [required] Must either model object variable response variable, vector weights formula can passed WeightIt. weight_method Method used WeightIt function call. Ignored treatment_model formula object. Defaults \"ps\". stabilize Whether stabilize weights . set FALSE default. Stabilizing weights ensures sum weights equal original sample size. effect point estimates, asymptotic variance calculations confidence intervals. trim Can either FALSE (default) numeric value trim weights. FALSE, weights used calculated supplied. numeric value supplied, weights bigger trim set trim analysis carried . Useful weights extremely large. ... arguments passed weightit.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_cox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inverse Probability of Treatment Weighted Survival using Cox-Regression — surv_iptw_cox","text":"Type Adjustment: Requires model describing treatment assignment mechanism. must either glm multinom object. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies survival package. Additionally, WeightIt package required treatment_model formula object. method works modeling treatment assignment mechanism. Adjusted survival curves calculated first estimating appropriate case-weights observation data. can done using inverse probability treatment weights using propensity score (usually estimated using logistic regression model) method (see ?weightit). estimates used fit weighted Cox-Regression model, stratified variable. Survival Curves based model estimated using method implemented survfit.coxph function. information can found literature listed \"references\". difference iptw_km method slightly different weighting approach. default method uses robust sandwich-type variance estimator (robust=TRUE coxph function call) calculate standard error used construction confidence intervals. estimator shown biased Austin (2016). Coupled stabilized weights however (stabilize=TRUE) gives conservative estimates variance confidence intervals (Xu et al. 2010). still recommended use bootstrap confidence intervals instead. can done setting bootstrap=TRUE adjustedsurv function call.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Probability of Treatment Weighted Survival using Cox-Regression — surv_iptw_cox","text":"Adds following additional objects output adjustedsurv function: cox_model: stratified weighted coxph model. survfit: survfit object created using cox_model object. weights: final weights used analysis. Returns list object containing data.frame estimated adjusted survival probabilities points time level variable, weighted coxph model, weighted survfit object weights used analysis.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_cox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Inverse Probability of Treatment Weighted Survival using Cox-Regression — surv_iptw_cox","text":"Stephen R. Cole Miguel . Hernán (2004). \"Adjusted Survival Curves Inverse Probability Weights\". : Computer Methods Programs Biomedicine 2003.75, pp. 45-49 Peter C. Austin (2016). \"Variance Estimation Using Inverse Probability Treatment Weighting (IPTW) Survival Analysis\". : Statistics Medicine 35, pp. 5642-5655 Stanley Xu, Colleen Ross Marsha . Raebel, Susan Shetterly, Christopher Blanchette, David Smith (2010). \"Use Stabilized Inverse Propensity Scores Weights Directly Estimate Relative Risk Confidence Intervals\". : Value Health 13.2, pp. 273-277","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_cox.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Inverse Probability of Treatment Weighted Survival using Cox-Regression — surv_iptw_cox","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_cox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse Probability of Treatment Weighted Survival using Cox-Regression — surv_iptw_cox","text":"","code":"library(adjustedCurves) library(survival)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a treatment assignment model glm_mod <- glm(group ~ x1 + x3 + x5 + x6, data=sim_dat, family=\"binomial\")  # use it to calculate adjusted survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_cox\",                         treatment_model=glm_mod)  # Alternatively, use custom weights # In this example we use weights calculated using the propensity score, # which is equal to using the glm model directly in the function ps_score <- glm_mod$fitted.values weights <- ifelse(sim_dat$group==1, 1/ps_score, 1/(1-ps_score))  adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_cox\",                         treatment_model=weights)  # And a third alternative: use the WeightIt package # here an example with equal results to the ones above: adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_cox\",                         treatment_model=group ~ x1 + x3 + x5 + x6,                         weight_method=\"ps\")  # here an example using Entropy Balancing Weighting: adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_cox\",                         treatment_model=group ~ x1 + x3 + x5 + x6,                         weight_method=\"ebal\")"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_km.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Probability of Treatment Weighted Kaplan-Meier estimates — surv_iptw_km","title":"Inverse Probability of Treatment Weighted Kaplan-Meier estimates — surv_iptw_km","text":"page explains details estimating inverse probability treatment weighted survival curves using weighted version Kaplan-Meier estimator single event time--event data (method=\"iptw_km\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, treatment_model argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_km.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Probability of Treatment Weighted Kaplan-Meier estimates — surv_iptw_km","text":"treatment_model [required] Must either model object variable response variable, vector weights formula can passed WeightIt. weight_method Method used WeightIt function call. Ignored treatment_model formula object. Defaults \"ps\". stabilize Whether stabilize weights . set FALSE default. Stabilizing weights ensures sum weights equal original sample size. effect point estimates, asymptotic variance calculations confidence intervals. trim Can either FALSE (default) numeric value trim weights. FALSE, weights used calculated supplied. numeric value supplied, weights bigger trim set trim analysis carried . Useful weights extremely large. ... arguments passed weightit.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_km.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inverse Probability of Treatment Weighted Kaplan-Meier estimates — surv_iptw_km","text":"Type Adjustment: Requires model describing treatment assignment mechanism. must either glm multinom object. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method depend packages directly. However WeightIt package required treatment_model formula object. method works modeling treatment assignment mechanism. Adjusted survival curves calculated first estimating appropriate case-weights observation data. can done using inverse probability treatment weights using propensity score (usually estimated using logistic regression model) method (see ?weightit). weights used weighted version Kaplan-Meier estimator proposed Xie Liu (2005). weights correctly estimated resulting estimates unbiased. difference iptw_cox method slightly different weighting approach. Asymptotic variances calculated using equations given Xie Liu (2005). also recommended use stabilized weights using stabilize=TRUE (default value). information can found cited literature.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_km.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Probability of Treatment Weighted Kaplan-Meier estimates — surv_iptw_km","text":"Adds following additional objects output adjustedsurv function: weights: final weights used analysis. n_at_risk: data.frame containing weighted number risk weighted number events used calculations point time groups.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_km.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Inverse Probability of Treatment Weighted Kaplan-Meier estimates — surv_iptw_km","text":"Jun Xie Chaofeng Liu (2005). \"Adjusted Kaplan-Meier Estimator Log- Rank Test Inverse Probability Treatment Weighting Survival Data\". : Statistics Medicine 24, pp. 3089-3110 Stanley Xu, Colleen Ross Marsha . Raebel, Susan Shetterly, Christopher Blanchette, David Smith (2010). \"Use Stabilized Inverse Propensity Scores Weights Directly Estimate Relative Risk Confidence Intervals\". : Value Health 13.2, pp. 273-277","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_km.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Inverse Probability of Treatment Weighted Kaplan-Meier estimates — surv_iptw_km","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_km.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse Probability of Treatment Weighted Kaplan-Meier estimates — surv_iptw_km","text":"","code":"library(adjustedCurves)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a treatment assignment model glm_mod <- glm(group ~ x1 + x3 + x5 + x6, data=sim_dat, family=\"binomial\")  # use it to calculate adjusted survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=glm_mod)  # Alternatively, use custom weights # In this example we use weights calculated using the propensity score, # which is equal to using the glm model directly in the function ps_score <- glm_mod$fitted.values weights <- ifelse(sim_dat$group==1, 1/ps_score, 1/(1-ps_score))  adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=weights)  # And a third alternative: use the WeightIt package # here an example with equal results to the ones above: adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=group ~ x1 + x3 + x5 + x6,                         weight_method=\"ps\")  # here an example using Entropy Balancing Weighting: adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=group ~ x1 + x3 + x5 + x6,                         weight_method=\"ebal\")"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_pseudo.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Probability of Treatment Weighted Survival Estimates using Pseudo-Values — surv_iptw_pseudo","title":"Inverse Probability of Treatment Weighted Survival Estimates using Pseudo-Values — surv_iptw_pseudo","text":"page explains details estimating inverse probability treatment weighted survival curves using Pseudo-Values single event time--event data (method=\"iptw_pseudo\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, treatment_model argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_pseudo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Probability of Treatment Weighted Survival Estimates using Pseudo-Values — surv_iptw_pseudo","text":"treatment_model [required] Must either model object variable response variable, vector weights formula can passed WeightIt. weight_method Method used WeightIt function call. Ignored treatment_model formula object. Defaults \"ps\". stabilize Whether stabilize weights . set FALSE default. Stabilizing weights ensures sum weights equal original sample size. effect point estimates, asymptotic variance calculations confidence intervals. trim Can either FALSE (default) numeric value trim weights. FALSE, weights used calculated supplied. numeric value supplied, weights bigger trim set trim analysis carried . Useful weights extremely large. se_method One \"miller\", \"galloway\", \"cochrane\" \"Hmisc\". Specifies kind standard error calculate. Defaults \"cochrane\". See details. censoring_vars optional character vector specifying variables data. used calculation inverse probability censoring weighted pseudo observations. See ?pseudo_aareg information. Set NULL (default) use standard pseudo-values without corrections dependent censoring instead. ipcw_method specific method used calculation inverse probability censoring weighted pseudo observations. Can either \"binder\" (default) \"hajek\". See ?pseudo_aareg information. Ignored censoring_vars=NULL. ... arguments passed weightit.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_pseudo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inverse Probability of Treatment Weighted Survival Estimates using Pseudo-Values — surv_iptw_pseudo","text":"Type Adjustment: Requires model describing treatment assignment mechanism. must either glm multinom object. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies prodlim package. WeightIt package also required treatment_model formula object. Additionally requires eventglm package censoring_vars specified. method works modeling treatment assignment mechanism. Adjusted survival curves calculated first estimating appropriate case-weights observation data. can done using inverse probability treatment weights using propensity score (usually estimated using logistic regression model) method (see ?weightit). Pseudo-Values calculated every observation data points time \\(T\\). Since Pseudo-Values bypass problem censoring, simple weighted average Pseudo-Values can taken every \\(T\\). See Andersen et al. (2017) details method Andersen Perme (2010) information Pseudo-Values general. standard error estimator can approximated calculation weighted version standard error estimator. Interestingly, exact method exists weighted case. Four approximations implemented can chosen using se_method argument. equations \"miller\", \"galloway\" \"cochrane\" described compared Gatz Smith (1995). \"Hmisc\" standard equation weight term added, specified Hmisc package, used stabilized weights (stabilize=TRUE). generally recommended use bootstrap estimates instead. Additionally, covariate-dependent censoring can accounted using inverse probability censoring weighted pseudo-values (Binder et al. 2014) instead regular pseudo-values (specified using censoring_vars ipcw_method arguments).","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_pseudo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Probability of Treatment Weighted Survival Estimates using Pseudo-Values — surv_iptw_pseudo","text":"Adds following additional objects output adjustedsurv function: pseudo_values: matrix estimated pseudo-values. weights: final weights used analysis.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_pseudo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Inverse Probability of Treatment Weighted Survival Estimates using Pseudo-Values — surv_iptw_pseudo","text":"Per Kragh Andersen, Elisavet Syriopoulou, Erik T. Parner (2017). \"Causal Inference Survival Analysis using Pseudo-Observations\". : Statistics Medicine 36, pp. 2669-2681 Per Kragh Andersen Maja Pohar Perme (2010). \"Pseudo-Observations Survival Analysis\". : Statistical Methods Medical Research 19, pp. 71-99 Donald F. Gatz Luther Smith (1995). \"Standard Error Weighted Mean Concentration - : Bootstrapping Vs Methods\". : Atmospheric Environment 29.11, pp. 1185-1193 William G. Cochran (1977). Sampling Techniques. Vol. 3. New York: Wiley J. N. Galloway, G. E. Likens, M. E. Hawley (1984). \"Acid Precipitation: Natural Versus Anthropogenic Components\". : Science 226, pp. 829-831 J. M. Miller (1977). Statistical Evaluation U.S. Precipitation Chemistry Network. Precipitation Scavenging (edited Semonin R. G. Beadle R. W.) pp. 639-659. Available CONF 74100 National Technical Information Service, U.S. Dept. Commerce, Springfiel, VA Nadine Binder, Thomas . Gerds, Per Kragh Andersen (2014). \"Pseudo-Observations Competing Risks Covariate Dependent Censoring\". : Lifetime Data Analysis 20, pp. 303-315","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_pseudo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Inverse Probability of Treatment Weighted Survival Estimates using Pseudo-Values — surv_iptw_pseudo","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iptw_pseudo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse Probability of Treatment Weighted Survival Estimates using Pseudo-Values — surv_iptw_pseudo","text":"","code":"library(adjustedCurves)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate a treatment assignment model glm_mod <- glm(group ~ x1 + x3 + x5 + x6, data=sim_dat, family=\"binomial\")  # use it to calculate adjusted survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=glm_mod,                         force_bounds=TRUE,                         iso_reg=TRUE)  # Alternatively, use custom weights # In this example we use weights calculated using the propensity score, # which is equal to using the glm model directly in the function ps_score <- glm_mod$fitted.values weights <- ifelse(sim_dat$group==1, 1/ps_score, 1/(1-ps_score))  adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=weights,                         force_bounds=TRUE,                         iso_reg=TRUE)  # And a third alternative: use the WeightIt package # here an example with equal results to the ones above: adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=group ~ x1 + x3 + x5 + x6,                         weight_method=\"ps\",                         force_bounds=TRUE,                         iso_reg=TRUE)  # here an example using Entropy Balancing Weighting: adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"iptw_km\",                         treatment_model=group ~ x1 + x3 + x5 + x6,                         weight_method=\"ebal\",                         force_bounds=TRUE,                         iso_reg=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iv_2SRIF.html","id":null,"dir":"Reference","previous_headings":"","what":"Instrumental Variable based Survival Curve Estimation using the Two Stage Residual Inclusion method with a Frailty Term (2SRI-F) — surv_iv_2SRIF","title":"Instrumental Variable based Survival Curve Estimation using the Two Stage Residual Inclusion method with a Frailty Term (2SRI-F) — surv_iv_2SRIF","text":"page explains details estimating adjusted survival curves using 2SRI-F instrumental variable method introduced Martinez-Camblor et al. (2021) single event time--event data (method=\"iv_2SRIF\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, adjust_vars argument instrument argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iv_2SRIF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instrumental Variable based Survival Curve Estimation using the Two Stage Residual Inclusion method with a Frailty Term (2SRI-F) — surv_iv_2SRIF","text":"adjust_vars [required] character vector column names specifying observed variables used covariates linear regression model Cox model. Set NULL use additional observed covariates. See details examples. instrument [required] single character string specifying instrumental variable. variable numeric fulfill conditions required called instrumental variable. See details references information. frailty_dist single character string specifying distribution used frailty term (internally passed distribution argument frailty function). Defaults \"gaussian\" usually kept value. return_models Either TRUE (default) FALSE, indicating whether output object also contain two models used estimation suvival curves.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iv_2SRIF.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Instrumental Variable based Survival Curve Estimation using the Two Stage Residual Inclusion method with a Frailty Term (2SRI-F) — surv_iv_2SRIF","text":"Type Adjustment: Allows adjustment observed confounders Cox model adjustment unmeasured confounders using instrumental variable approach. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: binary treatments allowed. column specified variable must factor variable exactly two levels. Approximate Variance: Calculations approximate variance confidence intervals available. Bootstrapping can still used estimate confidence intervals (see ?adjustedsurv). Allowed Time Values: Allows continuous integer survival times. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: None. instrument variable directly influences variable interest effect survival probability known confounders. Essentially, variable determines whether person receives specific level variable, without influencing anything else. clever calculations, variables may used adjust confounding factors. nice non-technical explanation general methodology instrumental variables given Iwashyna Kennedy (2013). specific explanations method used given Martinez-Camblor et al. (2021). Unlike methods included package, instrumental variable approach allows adjustment unmeasured confounding, simultaneously allowing adjustment observed confounders. main advantage method. , however, usable exists variable can reasonably used instrumental variable. Conditions constitutes variable details estimation process can found original article Martinez-Camblor et al. (2021). Note method target average treatment effect (ATE), instead targets local average treatment effect (LATE), also sometimes called complier average causal effect (CACE) described Lee et al. (2023). main reason estimator included simulation study performed author package (Denz et al. 2022). therefore currently easy judge well method performs comparison methods.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iv_2SRIF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instrumental Variable based Survival Curve Estimation using the Two Stage Residual Inclusion method with a Frailty Term (2SRI-F) — surv_iv_2SRIF","text":"return_models set TRUE, adds following objects adjustedsurv function: lm_mod: linear regression model used obtain residuals first stage estimation process. cox_mod: Cox model used second stage estimation process.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iv_2SRIF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Instrumental Variable based Survival Curve Estimation using the Two Stage Residual Inclusion method with a Frailty Term (2SRI-F) — surv_iv_2SRIF","text":"Pablo Martínez-Camblor, Todd . MacKenzie, Douglas O. Staiger, Phillip P. Goodney, Jamer O'Malley (2021). \"Summarizing Causal Differences Survival Curves Presence Unmeasured Confounding\". : International Journal Biostatistics 17.2, pp. 223-240 Youjin Lee, Edward H. Kennedy, Nandita Mitra (2023). \"Doubly Robust Nonparametric Instrumental Variable Estimators Survival Outcomes\". : Biostatistics 24.2, pp. 518-537 Robin Denz, Renate Klaaßen-Mielke, Nina Timmesfeld (2023). \"Comparison Different Methods Adjust Survival Curves Confounders\". : Statistics Medicine 42.10, pp. 1461-1479 Theodore J. Iwashyna Edward H. Kennedy (2013). \"Instrumental Variable Analyses: Exploiting Natural Randomness Understand Causal Mechanisms\". : Annals American Thoracic Society 10.3, pp. 255-260","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iv_2SRIF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Instrumental Variable based Survival Curve Estimation using the Two Stage Residual Inclusion method with a Frailty Term (2SRI-F) — surv_iv_2SRIF","text":"Robin Denz re-factored adapted code online supplementary original article Martinez-Camblor et al. (2021) implement method.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_iv_2SRIF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Instrumental Variable based Survival Curve Estimation using the Two Stage Residual Inclusion method with a Frailty Term (2SRI-F) — surv_iv_2SRIF","text":"","code":"library(adjustedCurves) library(survival)  set.seed(42)  ## This example has been taken from the online supplement of the original ## article by Martinez-Camblor et al. (2021)  # generate some data n <- 1000 t <- seq(0, 10, 0.01) bu <- log(2) hr <- 2 v <- 2 a <- 1  U <- stats::rnorm(n) Z <- stats::rnorm(n) W <- stats::rnorm(n) e <- stats::rnorm(n)  X0 <- (U + Z + a*W + (v - a^2)^0.5*e >= 0) L0 <- Z + bu*U L1 <- log(hr) + Z + bu*U T <- stats::rexp(n, 0.005)  T0 <- T/exp(L0) T1 <- T/exp(L1)  censor <- stats::rexp(n, 0.05) time1 <- pmin(ifelse(X0==1,T1,T0), censor) status1 <- 1-(censor==time1) time <- pmin(time1, 10) status <- ifelse(time1 > 10, 0, status1)  dt <- as.data.frame(cbind(time, status, X0, Z, W)) dt$X0 <- factor(dt$X0)  # calculate adjusted survival curves adjsurv <- adjustedsurv(data=dt,                         variable=\"X0\",                         ev_time=\"time\",                         event=\"status\",                         method=\"iv_2SRIF\",                         adjust_vars=\"Z\",                         instrument=\"W\")  # plot the curves plot(adjsurv)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_km.html","id":null,"dir":"Reference","previous_headings":"","what":"Group-Specific Kaplan-Meier Survival Curves — surv_km","title":"Group-Specific Kaplan-Meier Survival Curves — surv_km","text":"page explains details estimating group-specific Kaplan-Meier curves single event time--event data (method=\"km\" adjustedsurv function). regular arguments adjustedsurv function can used. arguments specific method listed . Calculates standard Kaplan-Meier survival curves, stratified group variable. adjustment confounders made. function included reference used confounder adjusted survival curves desired.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_km.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group-Specific Kaplan-Meier Survival Curves — surv_km","text":"conf_type type confidence interval calculated. character string, passed conf.type argument survfit function. Defaults \"log\", also default survfit.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_km.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Group-Specific Kaplan-Meier Survival Curves — surv_km","text":"Type Adjustment: adjustments made. just stratified Kaplan-Meier estimator. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies survival package.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_km.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group-Specific Kaplan-Meier Survival Curves — surv_km","text":"Adds following additional objects output adjustedsurv function: survfit_object: survfit object used calculate Kaplan-Meier curves.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_km.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Group-Specific Kaplan-Meier Survival Curves — surv_km","text":"E. L. Kaplan Paul Meier (1958). \"Nonparametric Estimation Incomplete Observations\". : Journal American Statistical Association 53.282, pp. 457-481","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_km.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Group-Specific Kaplan-Meier Survival Curves — surv_km","text":"wrapper function written Robin Denz, survfit function (wrapper build around) written people. See ?survfit details.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_km.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group-Specific Kaplan-Meier Survival Curves — surv_km","text":"","code":"library(adjustedCurves) library(survival)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # calculate un-adjusted kaplan-meier survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"km\")  # plot the curves plot(adjsurv)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_matching.html","id":null,"dir":"Reference","previous_headings":"","what":"Using Propensity-Score Matching to Calculate Adjusted Survival Curves — surv_matching","title":"Using Propensity-Score Matching to Calculate Adjusted Survival Curves — surv_matching","text":"page explains details estimating adjusted survival curves using propensity-score matching single event time--event data (method=\"matching\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, treatment_model argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_matching.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Using Propensity-Score Matching to Calculate Adjusted Survival Curves — surv_matching","text":"treatment_model [required] Must either model object variable response variable vector previously estimated propensity scores. gtol Tolerance estimated treatment assignment probabilities truncated. Every propensity score bigger 1 - gtol set 1 - gtol every propensity score smaller gtol set gtol. Useful extreme propensity scores close 0 1. Defaults 0.001. ... arguments passed Match function Matching Package.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_matching.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Using Propensity-Score Matching to Calculate Adjusted Survival Curves — surv_matching","text":"Type Adjustment: Requires model describing treatment assignment mechanism. must either glm object. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: two groups variable allowed. Must factor variable exactly two levels. Approximate Variance: Calculations approximate variance confidence intervals currently available. Bootstrap confidence intervals can however calculated supported models. See ?adjustedsurv information bootstrapping. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies Matching package. Using estimated propensity score, individual observations dataset matched creating new dataset covariate distributions balanced respect two groups defined variable. simple Kaplan-Meier estimator used calculate confounder-adjusted survival curves. corresponds method described Austin (2014). Details algorithm used matching can found documentation Matching package. choose implement matching based estimators (see Winnett & Sasieni (2002), Galimberti et al. (2002) Austin (2020)) wide range matching algorithms parameters. Trying automate matching process function like , opinion, disrupt workflow user also encouraging suboptimal practices. however included simple version matching estimator reference raise awareness using matching valid method obtain adjusted survival curves. Simulation studies shown particular method implemented significantly less efficient methods included R-Package. produce unbiased estimates, variation estimates high. suggest using one available methods.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_matching.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Using Propensity-Score Matching to Calculate Adjusted Survival Curves — surv_matching","text":"Adds following additional objects output adjustedsurv function: match_object: object creates using Match function. survfit_object: survfit object fit matched data.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_matching.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Using Propensity-Score Matching to Calculate Adjusted Survival Curves — surv_matching","text":"Peter C. Austin (2014). \"Use Propensity Score Methods Survival Time--Event Outcomes: Reporting Measures Effect Similar Used Randomized Experiments\". : Statistics Medicine 33, pp. 1242-1258 Angela Winnett Peter Sasieni (2002). \"Adjusted Nelson-Aalen Estimates Retrospective Matching\". : Journal American Statistical Association 97.457, pp. 245-256 Stefania Galimberti, Peter Sasieni, Maria Grazia Valsecchi (2002). \"Weighted Kaplan-Meier Estimator Matched Data Application Comparison Chemotherapy Bone-Marrow Transplant Leukaemia\". : Statistics Medicine 21, pp. 3847-3864 Peter C. Austin, Neal Thomas, Donald B. Rubin (2020). \"Covariate-Adjusted Survival Analyses Propensity-Score Matched Samples: Imputing Potential Time- -Event Outcomes\". : Statistical Methods Medical Research 29.3, pp. 728-751","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_matching.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Using Propensity-Score Matching to Calculate Adjusted Survival Curves — surv_matching","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_matching.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Using Propensity-Score Matching to Calculate Adjusted Survival Curves — surv_matching","text":"","code":"library(adjustedCurves) library(Matching)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # estimate treatment assignment model glm_mod <- glm(group ~ x1 + x2 + x4 + x6, data=sim_dat, family=\"binomial\")  # calculate adjusted survival curves adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"matching\",                         treatment_model=glm_mod)  # Alternatively, supply the propensity score directly # Here we use the logistic regression to calculate it, so we get # exactly the same result. The propensity score can be calculated in # any other way in practice, allowing flexibility ps_score <- glm_mod$fitted.values  adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"matching\",                         treatment_model=ps_score)  # plot the curves plot(adjsurv)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_aiptw.html","id":null,"dir":"Reference","previous_headings":"","what":"Proximal Augmented Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_aiptw","title":"Proximal Augmented Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_aiptw","text":"page explains details estimating augmented inverse probability treatment weighted survival curves using proximal causal inference based method single event time--event data (method=\"prox_aiptw\" described Ying et al. (2022) adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, treatment_proxy, outcome_proxy adjust_vars arguments specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_aiptw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proximal Augmented Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_aiptw","text":"adjust_vars [required] character vector specifying names variables data. variables may consist observed confounders. least one variable named. Can numeric, character factor variables. Corresponds \\(X\\) (type 1 proxy) article Ying et al. (2022). treatment_proxy [required] single character string specifying (numeric) variable used treatment proxy. Corresponds \\(Z\\) (type 3 proxy) article Ying et al. (2022). outcome_proxy [required] single character string specifying (numeric) variable used outcome proxy. Corresponds \\(W\\) (type 2 proxy) article Ying et al. (2022). optim_method single character string passed method argument optim function, used internally fitting q-confounding bridge function h-confounding bridge function. Defaults \"BFGS\". pass additional argument internal optim call, see argument optim_control. optim_control list named arguments passed control argument optim function, used internally fitting q-confounding bridge function h-confounding bridge function. Set list() pass additional argument (default). return_fit Whether add intermediate results, q-confounding bridge function output object. Defaults TRUE.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_aiptw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Proximal Augmented Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_aiptw","text":"Type Adjustment: Uses proximal causal inference framework adjust measured unmeasured confounding use q-confounding bridge function h-confounding bridge function, essentially augmented inverse probability treatment weighting, using proxies. Doubly-Robust: Estimates Doubly-Robust sense one bridge functions correctly specified achieve unbiased estimates, given relevant assumptions hold. Categorical groups:variable may contain two groups. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: Depends numDeriv dependencies package. method based proximal causal inference framework, first introduced Miao et al. (2018) later extended allow estimation counterfactual survival curves Ying et al. (2022). allows estimation treatment-specific counterfactual survival curve unmeasured confounding, true data-generation mechanism particular structure. particular, must observed variable (contained dataset) potential cause treatment (variable) also unrelated time--event endpoint, except measured confounders (adjust_vars) particular known unmeasured confounder. type variable called treatment_proxy. Secondly, must another observed variable directly indirectly causes outcome, unrelated treatment expect measured confounders known unmeasured confounder mentioned earlier. type variable called outcome_proxy. better explanation given Zivich et al. (2023). information underlying assumptions can found papers listed references. Ying et al. (2022) proposed two methods utilize kind structure estimation counterfactual survival curve. one implemented relies estimating q-confounding bridge h-confounding bridge using parametric models. essentially means uses treatment-assignment mechanism outcome-mechanism adjust confounding, similar regular augmented inverse probability weighted estimator.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_aiptw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Proximal Augmented Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_aiptw","text":"Adds following additional objects output adjustedsurv function: noncensor_cumhaz: estimated cumulative hazard function. noncensor_cumhaz_IF: influence function based estimated cumulative hazard function. q_bridge: list containing results fitting q-confounding bridge function. h_bridge: list containing results fitting h-confounding bridge function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_aiptw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Proximal Augmented Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_aiptw","text":"Andrew Ying, Yifan Cui Eric J. Tchetgen Tchetgen (2022). \"Proximal Causal Inference Marginal Counterfactual Survival Curves\". arXiv:2204.13144 Wang Miao, Zhi Geng Eric J. Tchetgen Tchetgen (2018). \"Identifying Causal Effects Proxy Variables Unmeasured Confounder\". : Biometrika 105.4, pp. 987-993. Paul N. Zivich, Stephen R. Cole, Jessie K. Edwards, Grace E. Mulholland, Bonnie E. Shook-Sa Eric J. Tchetgen Tchetgen (2023). \"Introducing Proximal Causal Inference Epidemiologists\". : American Journal Epidemiology 192.7, pp. 1224-1227. Eric J. Tchetgen Tchetgen, Andrew Ying, Yifan Cui, Xu Shi Wang Miao (2020). \"Introduction Proximal Causal Learning\". arXiv:2009.10982","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_aiptw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Proximal Augmented Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_aiptw","text":"Andrew Ying wrote low-level estimation functions used actually obtain relevant values. Robin Denz wrote wrapper functions around include method package.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_aiptw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Proximal Augmented Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_aiptw","text":"","code":"library(numDeriv) library(adjustedCurves)  #### generate some example data that fufill all assumptions #### # code was taken from the github repository associated with the original # paper by Ying et al. (2022): https://github.com/andrewyyp/Proximal_MSF  # simulation parameters para_set <- list(mu_X = 1.1,                  sigma_X = 0.75,                  mu_U = 1.1,                  sigma_U = 0.75,                  alpha_A = c(0.3, 0.4, -0.6),                  mu_Z = c(-0.2, -0.3, 0.65),                  sigma_Z = 0.5,                  mu_W = c(-0.6, 0.4, 0.65),                  sigma_W = 0.5,                  mu_T0 = c(0.1, 0.6, 0.25, 0.5),                  mu_C = 0.2,                  admin_C = 2 )  # small function to obtain the required data data_gen <- function(N, para_set, a = NULL) {   # generate X, U   X <- para_set$mu_X + rnorm(N, 0, para_set$sigma_X)   U <- para_set$mu_U + rnorm(N, 0, para_set$sigma_U)   X <- pmax(X, 0)   U <- pmax(U, 0)    if (is.null(a)) {     # generate A     prop_score_0 <- 1/(1 + exp(-cbind(1, X, U) %*% para_set$alpha_A))     A <- rbinom(N, 1, prop_score_0)   } else {     A <- rep(a, N)   }     # generate Z   Z <- cbind(1, X, U) %*% para_set$mu_Z + rnorm(N, 0, para_set$sigma_Z)    # generate W   W <- cbind(1, X, U) %*% para_set$mu_W + rnorm(N, 0, para_set$sigma_W)     #generate Y   T0 <- rexp(N, rate = cbind(1, A, X, U) %*% para_set$mu_T0)    C <- rexp(N, rate = para_set$mu_C)   C <- pmin(C, para_set$admin_C)   if (is.null(a)) {     df <- data.frame(X, U, A, Z, W, T0 = pmin(T0, C), Delta = (T0 <= C))   } else {     df <- data.frame(X, U, A, Z, W, T0 = T0, Delta = rep(1, N))   }   return(df) }  #### Simple example ####  set.seed(4356) # NOTE: increase N to get more stable estimates, kept low here to pass #       speed requirements set by CRAN data <- data_gen(N=50, para_set=para_set) data$A <- factor(data$A)  adj <- adjustedsurv(data=data,                     variable=\"A\",                     ev_time=\"T0\",                     event=\"Delta\",                     method=\"prox_aiptw\",                     adjust_vars=\"X\",                     treatment_proxy=\"Z\",                     outcome_proxy=\"W\",                     conf_int=TRUE) plot(adj, iso_reg=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_iptw.html","id":null,"dir":"Reference","previous_headings":"","what":"Proximal Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_iptw","title":"Proximal Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_iptw","text":"page explains details estimating inverse probability treatment weighted survival curves using proximal causal inference based method single event time--event data (method=\"prox_iptw\" described Ying et al. (2022) adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, treatment_proxy, outcome_proxy adjust_vars arguments specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_iptw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proximal Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_iptw","text":"adjust_vars [required] character vector specifying names variables data. variables may consist observed confounders. least one variable named. Corresponds \\(X\\) (type 1 proxy) article Ying et al. (2022). treatment_proxy [required] single character string specifying variable used treatment proxy. Corresponds \\(Z\\) (type 3 proxy) article Ying et al. (2022). outcome_proxy [required] single character string specifying variable used outcome proxy. Corresponds \\(W\\) (type 2 proxy) article Ying et al. (2022). optim_method single character string passed method argument optim function, used internally fitting q-confounding bridge function. Defaults \"BFGS\". pass additional argument internal optim call, see argument optim_control. optim_control list named arguments passed control argument optim function, used internally fitting q-confounding bridge function. Set list() pass additional argument (default). return_fit Whether add intermediate results, q-confounding bridge function output object. Defaults TRUE.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_iptw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Proximal Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_iptw","text":"Type Adjustment: Uses proximal causal inference framework adjust measured unmeasured confounding q-confounding bridge function, essentially inverse probability treatment weighting, using proxies. Doubly-Robust: Estimates Doubly-Robust. Categorical groups:variable may contain two groups. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: Depends numDeriv dependencies package. method based proximal causal inference framework, first introduced Miao et al. (2018) later extended allow estimation counterfactual survival curves Ying et al. (2022). allows estimation treatment-specific counterfactual survival curve unmeasured confounding, true data-generation mechanism particular structure. particular, must observed variable (contained dataset) potential cause treatment (variable) also unrelated time--event endpoint, except measured confounders (adjust_vars) particular known unmeasured confounder. type variable called treatment_proxy. Secondly, must another observed variable directly indirectly causes outcome, unrelated treatment expect measured confounders known unmeasured confounder mentioned earlier. type variable called outcome_proxy. better explanation given Zivich et al. (2023). information underlying assumptions can found papers listed references. Ying et al. (2022) proposed two methods utilize kind structure estimation counterfactual survival curve. one implemented relies estimating q-confounding bridge using parametric model. essentially means uses treatment-assignment mechanism adjust confounding, similar regular inverse probability weighted estimator.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_iptw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Proximal Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_iptw","text":"Adds following additional objects output adjustedsurv function: noncensor_cumhaz: estimated cumulative hazard function. noncensor_cumhaz_IF: influence function based estimated cumulative hazard function. q_bridge: list containing results fitting q-confounding bridge function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_iptw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Proximal Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_iptw","text":"Andrew Ying, Yifan Cui Eric J. Tchetgen Tchetgen (2022). \"Proximal Causal Inference Marginal Counterfactual Survival Curves\". arXiv:2204.13144 Wang Miao, Zhi Geng Eric J. Tchetgen Tchetgen (2018). \"Identifying Causal Effects Proxy Variables Unmeasured Confounder\". : Biometrika 105.4, pp. 987-993. Paul N. Zivich, Stephen R. Cole, Jessie K. Edwards, Grace E. Mulholland, Bonnie E. Shook-Sa Eric J. Tchetgen Tchetgen (2023). \"Introducing Proximal Causal Inference Epidemiologists\". : American Journal Epidemiology 192.7, pp. 1224-1227. Eric J. Tchetgen Tchetgen, Andrew Ying, Yifan Cui, Xu Shi Wang Miao (2020). \"Introduction Proximal Causal Learning\". arXiv:2009.10982","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_iptw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Proximal Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_iptw","text":"Andrew Ying wrote low-level estimation functions used actually obtain relevant values. Robin Denz wrote wrapper functions around include method package.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_prox_iptw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Proximal Inverse Probability of Treatment Weighted Survival Curve Estimates — surv_prox_iptw","text":"","code":"library(numDeriv) library(adjustedCurves)  #### generate some example data that fufill all assumptions #### # code was taken from the github repository associated with the original # paper by Ying et al. (2022): https://github.com/andrewyyp/Proximal_MSF  # simulation parameters para_set <- list(mu_X = 1.1,                  sigma_X = 0.75,                  mu_U = 1.1,                  sigma_U = 0.75,                  alpha_A = c(0.3, 0.4, -0.6),                  mu_Z = c(-0.2, -0.3, 0.65),                  sigma_Z = 0.5,                  mu_W = c(-0.6, 0.4, 0.65),                  sigma_W = 0.5,                  mu_T0 = c(0.1, 0.6, 0.25, 0.5),                  mu_C = 0.2,                  admin_C = 2 )  # small function to obtain the required data data_gen <- function(N, para_set, a = NULL) {   # generate X, U   X <- para_set$mu_X + rnorm(N, 0, para_set$sigma_X)   U <- para_set$mu_U + rnorm(N, 0, para_set$sigma_U)   X <- pmax(X, 0)   U <- pmax(U, 0)    if (is.null(a)) {     # generate A     prop_score_0 <- 1/(1 + exp(-cbind(1, X, U) %*% para_set$alpha_A))     A <- rbinom(N, 1, prop_score_0)   } else {     A <- rep(a, N)   }     # generate Z   Z <- cbind(1, X, U) %*% para_set$mu_Z + rnorm(N, 0, para_set$sigma_Z)    # generate W   W <- cbind(1, X, U) %*% para_set$mu_W + rnorm(N, 0, para_set$sigma_W)     #generate Y   T0 <- rexp(N, rate = cbind(1, A, X, U) %*% para_set$mu_T0)    C <- rexp(N, rate = para_set$mu_C)   C <- pmin(C, para_set$admin_C)   if (is.null(a)) {     df <- data.frame(X, U, A, Z, W, T0 = pmin(T0, C), Delta = (T0 <= C))   } else {     df <- data.frame(X, U, A, Z, W, T0 = T0, Delta = rep(1, N))   }   return(df) }  #### Simple example ####  set.seed(4356) data <- data_gen(N=500, para_set=para_set) data$A <- factor(data$A)  adj <- adjustedsurv(data=data,                     variable=\"A\",                     ev_time=\"T0\",                     event=\"Delta\",                     method=\"prox_iptw\",                     adjust_vars=\"X\",                     treatment_proxy=\"Z\",                     outcome_proxy=\"W\",                     conf_int=TRUE) plot(adj, iso_reg=TRUE)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_amato.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjusted Survival Curves for Categorical Confounders using the Method by Amato (1988) — surv_strat_amato","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Amato (1988) — surv_strat_amato","text":"page explains details estimating confounder-adjusted survival curves using weighted average stratified Kaplan-Meier estimates using method described Amato (1988) (method=\"strat_amato\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, adjust_vars argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_amato.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Amato (1988) — surv_strat_amato","text":"adjust_vars [required] single string character vector specifying column names data survival curves adjusted . variables specified can integers, factors characters. categorical variables can used method. See details. reference data.frame used reference population weighting survival curves NULL (default). NULL survival curves weighted reference full sample supplied using data, regardless variable level. data.frame supplied needs include variables specified adjust_vars.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_amato.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Amato (1988) — surv_strat_amato","text":"Type Adjustment: survival curves adjusted calculating weighted version Kaplan-Meier estimator, based stratification covariates. works categorical confounders. See information. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Bootstrap confidence intervals can however calculated supported models. See ?adjustedsurv information bootstrapping. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method dependencies. one older adjustment methods described literature. works categorical confounders. adjustments continuous confounders desired, user needs explicitly categorize continuous confounders. recommended use one methods implemented package case. method works exactly described Amato (1988). number people risk number events stratum point time reweighted combined single estimate treatment. reference data used calculate weights pooled sample (data) default, external reference data can supplied. detailed description can found original article. character vector supplied adjust_vars argument, every possible combination variables specified adjust_vars used strata. might lead problems strata little data . contrast stratification based methods however, method allows estimation adjusted survival curves last point time least one individual risk pooled sample.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_amato.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Amato (1988) — surv_strat_amato","text":"Adds following additional objects output adjustedsurv function: Pjs: weights used stratum.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_amato.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Amato (1988) — surv_strat_amato","text":"David . Amato (1988). \"Generalized Kaplan-Meier Estimator Heterogenous Populations\". : Communications Statistics: Theory Methods 17.1, pp. 263-286","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_amato.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Amato (1988) — surv_strat_amato","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_amato.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Amato (1988) — surv_strat_amato","text":"","code":"library(adjustedCurves) library(survival)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # adjust survival curves for some categorical confounders adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"strat_amato\",                         adjust_vars=c(\"x1\", \"x3\"),                         conf_int=FALSE)  # plot the curves plot(adjsurv)"},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_cupples.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjusted Survival Curves for Categorical Confounders using the Method by Cupples et al. (1995) — surv_strat_cupples","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Cupples et al. (1995) — surv_strat_cupples","text":"page explains details estimating confounder-adjusted survival curves using weighted average stratified Kaplan-Meier estimates using method described Cupples et al. (1995) (method=\"strat_cupples\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, adjust_vars argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_cupples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Cupples et al. (1995) — surv_strat_cupples","text":"adjust_vars [required] single string character vector specifying column names data survival curves adjusted . variables specified can integers, factors characters. categorical variables can used method. See details. reference data.frame used reference population weighting survival curves NULL (default). NULL survival curves weighted reference full sample supplied using data, regardless variable level. data.frame supplied needs include variables specified adjust_vars.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_cupples.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Cupples et al. (1995) — surv_strat_cupples","text":"Type Adjustment: survival curves adjusted taking weighted average stratified Kaplan-Meier estimates. works categorical confounders. See information. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. Bootstrap confidence intervals can however calculated supported models. See ?adjustedsurv information bootstrapping. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies survival package. one older adjustment methods described literature. works categorical confounders. adjustments continuous confounders desired, user needs explicitly categorize continuous confounders. recommended use one methods implemented package case. method works exactly described Cupples et al. (1995). First, stratified Kaplan-Meier estimates possible combination supplied variables (variable + adjust_vars) calculated. example dichotomous variable levels \"Treatment\" \"Control\" supplied conjunction single dichotomous confounder \"Sex\" levels \"male\" \"female\", method calculate four Kaplan-Meier curves (Treatment + male, Treatment + female, Control + male, Control + female). Next simple weighted average survival curves taken per level variable, weights number occurrences confounder level reference data. reference data pooled sample default, external reference data can used. detailed description can found original article. character vector supplied adjust_vars argument, Kaplan-Meier estimates created combination supplied variables. sample size small /many levels variables, estimates can become unstable undefined. weighted average Kaplan-Meier curves, estimates method defined points time valid Kaplan-Meier estimate strata. Continuing example , Kaplan-Meier curve strata \"Treatment + male\" extends t = 100, impossible estimate adjusted survival curve t > 100 using method.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_cupples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Cupples et al. (1995) — surv_strat_cupples","text":"Adds additional objects output adjustedsurv function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_cupples.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Cupples et al. (1995) — surv_strat_cupples","text":". Kramar C. Com-Nougué (1990). \"Estimation des courbes de survie ajustées\". : Revue d Épidémiologie et de Santé Publique 38.2, pp. 149-152 L. Adrienne Cupples, David R. Gragnon, Ratna Ramaswamy, Ralph D’Agostino (1995). \"Age-Adjusted Survival Curves Application Framingham Study\". : Statistics Medicine 14, pp. 1731-1744","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_cupples.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Cupples et al. (1995) — surv_strat_cupples","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_cupples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Cupples et al. (1995) — surv_strat_cupples","text":"","code":"library(adjustedCurves) library(survival)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # adjust survival curves for some categorical confounders adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"strat_cupples\",                         adjust_vars=c(\"x1\", \"x3\"),                         conf_int=FALSE)  # plot the curves plot(adjsurv) #> Warning: Removed 16 rows containing missing values (`geom_step()`)."},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_nieto.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjusted Survival Curves for Categorical Confounders using the Method by Gregory (1988) and Nieto & Coresh (1996) — surv_strat_nieto","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Gregory (1988) and Nieto & Coresh (1996) — surv_strat_nieto","text":"page explains details estimating confounder-adjusted survival curves using weighted average stratified Kaplan-Meier estimates using method described Gregory (1988) Nieto & Coresh (1996) (method=\"strat_gregory_nieto\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, adjust_vars argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_nieto.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Gregory (1988) and Nieto & Coresh (1996) — surv_strat_nieto","text":"adjust_vars [required] single string character vector specifying column names data survival curves adjusted . variables specified can integers, factors characters. categorical variables can used method. See details.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_nieto.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Gregory (1988) and Nieto & Coresh (1996) — surv_strat_nieto","text":"Type Adjustment: survival curves adjusted taking weighted average stratified Kaplan-Meier estimates. works categorical confounders. See information. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: number levels variable allowed. Must factor variable. Approximate Variance: Calculations approximate variance confidence intervals available. estimator variance can found appendix Nieto & Coresh (1996). Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method additional dependencies. one older adjustment methods described literature. works categorical confounders. adjustments continuous confounders desired, user needs explicitly categorize continuous confounders. recommended use one methods implemented package case. method works exactly described Gregory (1988). Similarly method described strat_cupples, Kaplan-Meier estimates calculated strata weighted average taken. difference slightly different weighting scheme. Weights calculated using pooled sample (data). contrast stratification based methods, external reference data allowed. detailed description can found original article. character vector supplied adjust_vars argument, Kaplan-Meier estimates created combination supplied variables. sample size small /many levels variables, estimates can become unstable undefined. weighted average Kaplan-Meier curves, estimates method defined points time valid Kaplan-Meier estimate strata. example, Kaplan-Meier curve strata \"Treatment + male\" extends t = 100, impossible estimate adjusted survival curve t > 100 using method. Nieto & Coresh (1996) proposed similar method. major difference Nieto & Coresh (1996) used control group reference population, results different causal estimand. Using method Nieto & Coresh (1996) full data reference population described Gregory (1988) produces exactly results. Nieto & Coresh (1996) seemed unaware method Gregory (1988), mention article. contrast Gregory (1988) however also proposed approximate estimator variance, implemented . formulation estimator also allows use time-dependent covariates left-truncated data. however implemented .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_nieto.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Gregory (1988) and Nieto & Coresh (1996) — surv_strat_nieto","text":"Adds additional objects output adjustedsurv function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_nieto.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Gregory (1988) and Nieto & Coresh (1996) — surv_strat_nieto","text":"W. M. Gregory (1988). \"Adjusting Survival Curves Imbalances Prognostic Factors\". : British Journal Cancer 58, pp. 202-204 F. Javier Nieto Josef Coresh (1996). \"Adjusting Survival Curves Confounders: Review New Method\". : American Journal Epidemiology 143.10, pp. 1059-1068","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_nieto.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Gregory (1988) and Nieto & Coresh (1996) — surv_strat_nieto","text":"Robin Denz","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_strat_nieto.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjusted Survival Curves for Categorical Confounders using the Method by Gregory (1988) and Nieto & Coresh (1996) — surv_strat_nieto","text":"","code":"library(adjustedCurves) library(survival)  set.seed(42)  # simulate some data as example sim_dat <- sim_confounded_surv(n=50, max_t=1.2) sim_dat$group <- as.factor(sim_dat$group)  # adjust survival curves for some categorical confounders adjsurv <- adjustedsurv(data=sim_dat,                         variable=\"group\",                         ev_time=\"time\",                         event=\"event\",                         method=\"strat_nieto\",                         adjust_vars=c(\"x1\", \"x3\"),                         conf_int=FALSE)  # plot the curves plot(adjsurv) #> Warning: Removed 7 rows containing missing values (`geom_step()`)."},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_tmle.html","id":null,"dir":"Reference","previous_headings":"","what":"Targeted Maximum Likelihood Estimation for Continuously Distributed Time-To-Event Data — surv_tmle","title":"Targeted Maximum Likelihood Estimation for Continuously Distributed Time-To-Event Data — surv_tmle","text":"page explains details estimating causal survival curves competing risks setting targeted maximum likelihood estimation (method=\"tmle\" adjustedsurv function). regular arguments adjustedsurv function can used. Additionally, outcome_model argument treatment_model argument specified adjustedsurv call. arguments specific method listed .","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_tmle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Targeted Maximum Likelihood Estimation for Continuously Distributed Time-To-Event Data — surv_tmle","text":"outcome_model [required] list containing least one Cox model formula. Cox model formula, time variable always called time status variable always called status. example, use just one Cox model including variables dataset independent variables user can use list(Surv(time, status) ~ .). Cox models defined list fitted data ensemble models used provide initial predictions conditional hazard. See details documentation concrete package information. treatment_model [required] character vector specifying SuperLearner libraries used obtain estimate propensity score. example, c(\"SL.glm\", \"SL.glmnet\") used. See ?SuperLearner details. censoring_model Either NULL (default) make adjustments dependent censoring, list Cox models described outcome_model argument. difference outcome_model argument status==0 used Cox formulas. See ?formatArguments concrete package details. cv_args list arguments specifying exactly cross-validation performed. Internally passed CVArg argument formatArguments function concrete package. max_update_iter single positive integer specifying maximum iterations performed obtain estimates. Defaults 500. Internally passed MaxUpdateIter argument formatArguments function concrete package. one_step_eps single positive number specifying step size tmle updates. Defaults 0.1. Internally passed OneStepEps argument formatArguments function concrete package. min_nuisance single number 0 1 used truncating g-related denominator clever covariate. Defaults 5/sqrt(nrow(data))/log(nrow(data)). Internally passed MinNuisance argument formatArguments function concrete package. verbose Whether print estimation information doConcrete function concrete package. Defaults FALSE. return_models Whether add estimated models outcome, treatment, censoring mechanism output object. Defaults TRUE.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_tmle.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Targeted Maximum Likelihood Estimation for Continuously Distributed Time-To-Event Data — surv_tmle","text":"Type Adjustment: Requires model describing treatment assignment mechanism outcome mechanism, also allows model censoring mechanism. See details concrete package. Doubly-Robust: Estimates Doubly-Robust. Categorical groups: function currently allows two levels variable. Approximate Variance: Calculations approximate variance confidence intervals available. Allowed Time Values: Allows continuous integer time. Bounded Estimates: Estimates guaranteed bounded 0 1 probability range. Monotone Function: Estimates guaranteed monotone. Dependencies: method relies concrete package, data.table package respective dependencies. : function implements Targeted Maximum Likelihood Estimation (TMLE) continuously distributed time--event data described Rytgaard et al. (2023) Rytgaard van der Laan (2022). TMLE method similar AIPTW methods included package. also relies outcome model treatment model (additional optional censoring model) obtain counterfactual survival probability estimates. contrast AIPTW methods, however, estimator uses iterative approach obtain estimates update targets entire survival curve. consequence, resulting estimates guaranteed lie 0/1 probability bounds also guaranteed non-increasing time. Simulation studies theoretical results indicate good performance method terms bias standard errors. See cited literature detailed rigorous explanations method. Instead relying single model obtain propensity score initial conditional hazards estimates, estimator relies SuperLearner framework conjunction cross-validation . cross-validation performed may controlled cv_args argument. resulting models can inspected output object return_models set TRUE. Implementation: Internally, function simply calls multiple functions concrete package correct order appropriate arguments. wrapper function limited sense allow dynamic interventions time-varying variables, supported concrete package. recommended use concrete package directly user wants use features specific settings required. Speed Considerations: method computationally expensive. medium large datasets considering many different points time, usually take long time execute. speed important, recommend using methods. Alternatively, user may adjust times arguments target fewer points time.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_tmle.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Targeted Maximum Likelihood Estimation for Continuously Distributed Time-To-Event Data — surv_tmle","text":"previous version package (<= 0.9.1) included function name, removed version 0.10.0. old version implemented TMLE estimator applicable discrete-time survival data based survtmle package, removed CRAN. new version implements different estimator. Code using method version <= 0.9.1 work versions 0.10.2 higher.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_tmle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Targeted Maximum Likelihood Estimation for Continuously Distributed Time-To-Event Data — surv_tmle","text":"Adds following additional objects output adjustedsurv function: concrete_object: object returned doConcrete function.","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_tmle.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Targeted Maximum Likelihood Estimation for Continuously Distributed Time-To-Event Data — surv_tmle","text":"Helene C. W. Rytgaard Mark J. van der Laan (2023). \"Targeted Maximum Likelihood Estimation Causal Inference Survival Competing Risks Analysis\". : Lifetime Data Analysis Helene C. W. Rytgaard Mark J. van der Laan (2023). \"One-Step Targeted Maximum Likelihood Estimation Targeting Cause-Specific Absolute Risks Survival Curves\". : Biometrika Helene C. W. Rytgaard, Frank Eriksson Mark J. van der Laan (2023). \"Estimation Time-Specific Intervention Effects Continuously Distributed Time--Event Outcomes Targeted Maximum Likelihood Estimation\". : Biometrics David Chen, Helene C. W. Rytgaard Edwin Fong Jens M. Tarp Maya L. Petersen Mark J. van der Laan Thomas . Gerds (2023). \"concrete: R Package Continuous-Time, Competing Risks Targeted Maximum Likelihood Estimation\". Available <https://github.com/imbroglio-dc/concrete> CRAN","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_tmle.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Targeted Maximum Likelihood Estimation for Continuously Distributed Time-To-Event Data — surv_tmle","text":"wrapper function written Robin Denz, real estimation functions contained concrete package, written David Chen. See ?doConcrete information.","code":""},{"path":[]},{"path":"https://robindenz1.github.io/adjustedCurves/reference/surv_tmle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Targeted Maximum Likelihood Estimation for Continuously Distributed Time-To-Event Data — surv_tmle","text":"","code":"library(adjustedCurves)  data <- sim_confounded_surv(n=100) data$group <- factor(data$group)  # for a single point in time using only one model for both # the treatment mechanism and outcome mechanism out <- adjustedsurv(data=data,                     variable=\"group\",                     ev_time=\"time\",                     event=\"event\",                     treatment_model=c(\"SL.glm\"),                     outcome_model=list(Surv(time, status) ~ .),                     times=c(0.5),                     conf_int=TRUE,                     method=\"tmle\")  ## using multiple models for both the treatment assignment and ## outcome mechanism out <- adjustedsurv(data=data,                     variable=\"group\",                     ev_time=\"time\",                     event=\"event\",                     treatment_model=c(\"SL.glm\", \"SL.mean\"),                     outcome_model=list(Surv(time, status) ~ x1 + x3,                                        Surv(time, status) ~ x2 + x4 + x5),                     times=c(0.5),                     conf_int=TRUE,                     method=\"tmle\")  ## with corrections for covariate dependent censoring out <- adjustedsurv(data=data,                     variable=\"group\",                     ev_time=\"time\",                     event=\"event\",                     treatment_model=c(\"SL.glm\", \"SL.mean\"),                     outcome_model=list(Surv(time, status) ~ x1 + x3,                                        Surv(time, status) ~ x2 + x4 + x5),                     censoring_model=list(Surv(time, status==0) ~ x6 + x1),                     times=c(0.5),                     conf_int=TRUE,                     method=\"tmle\")"},{"path":"https://robindenz1.github.io/adjustedCurves/news/index.html","id":"adjustedcurves-090","dir":"Changelog","previous_headings":"","what":"adjustedCurves 0.9.0","title":"adjustedCurves 0.9.0","text":"CRAN release: 2022-09-22 first release package","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/news/index.html","id":"adjustedcurves-091","dir":"Changelog","previous_headings":"","what":"adjustedCurves 0.9.1","title":"adjustedCurves 0.9.1","text":"CRAN release: 2022-11-22 Include CRAN installation instructions Updated code tests run updated versions mice ggplot2 packages Updated documentation package man page include features supported moment","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/news/index.html","id":"adjustedcurves-0100","dir":"Changelog","previous_headings":"","what":"adjustedCurves 0.10.0","title":"adjustedCurves 0.10.0","text":"CRAN release: 2023-02-16 Removed support tmle, ostmle methods Changed citation information manuscript published Changed print method equal summary method Fixed issues unit-tests require packages “Suggests” ","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/news/index.html","id":"adjustedcurves-0101","dir":"Changelog","previous_headings":"","what":"adjustedCurves 0.10.1","title":"adjustedCurves 0.10.1","text":"CRAN release: 2023-04-20 Fixed small issues unit tests caused changes WeightIt package Made small documentation updates","code":""},{"path":"https://robindenz1.github.io/adjustedCurves/news/index.html","id":"adjustedcurves-0102","dir":"Changelog","previous_headings":"","what":"adjustedCurves 0.10.2","title":"adjustedCurves 0.10.2","text":"Changed examples usage WeightIt suggested Noah Greifer Added new methods surv_tmle cif_tmle, based concrete package Added new instrumental variable based method surv_iv_2SRIF Added arguments iso_reg force_bounds adjustedsurv adjustedcif functions Added new methods surv_prox_iptw, surv_prox_aiptw based code Andrew Ying Added new vignette overview implemented features method Added better support multiple imputation variable, ev_time event contain missings Added ratio argument adjusted_rmst() adjusted_rmtl() functions Added adjusted_curve_ratio() function Added plot_curve_ratio() function","code":""}]
